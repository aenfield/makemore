{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd018cd0-773b-4f47-b7e2-0458928c7937",
   "metadata": {},
   "source": [
    "# Quickstart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537a96cb-f91f-4172-b346-cf883ffc7a73",
   "metadata": {},
   "source": [
    "With code from https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a345c48e-953d-448a-b748-89d1c45fdc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import sys\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0b97c4f-b8fa-441e-8bee-2845a0e6b753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.11.11 (main, Feb 12 2025, 15:06:01) [Clang 19.1.6 ]\n",
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "print(sys.version)\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d36d0a7e-01ac-4177-b307-45186f504b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root='data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19f250fc-87d2-4416-8487-1c075f970295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f'Shape of X [N, C, H, W]: {X.shape}')\n",
    "    print(f'Shape of y: {y.shape} {y.dtype}')\n",
    "    break # exit after first batch - all batches are the same size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3cb420-0ca4-4615-af9f-e9532d38e1ee",
   "metadata": {},
   "source": [
    "Cool... looks like this new current_accelerator.is_available call returns true for both CUDA and MPS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e5dba2d-092d-4ea2-aebc-872aa8a5d093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73f1f8c2-4598-4c55-8c03-7c658d258752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = 'cpu' # to run with CPU uncomment and then run the code below (could be reorganize so only the stuff that has to run after the device change, like the model creation, is after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d18d654-7d71-432f-9a41-c874a92c3f30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56d61d31-74b4-4a1d-be73-a207d39794ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78b6eac9-e685-41cd-af66-8d4d9995bd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # backprop\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f'loss: {loss:>7f} [{current:>5d}/{size:>5d}]')\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f'Test error: \\n Accuracy: {(100 * correct):>0.1f}%, avg loss: {test_loss:>8f} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d6c1b6d-9689-4e3e-be61-2dd3218913e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "------------------\n",
      "loss: 2.305091 [   64/60000]\n",
      "loss: 2.298038 [ 6464/60000]\n",
      "loss: 2.275595 [12864/60000]\n",
      "loss: 2.266529 [19264/60000]\n",
      "loss: 2.256486 [25664/60000]\n",
      "loss: 2.223460 [32064/60000]\n",
      "loss: 2.219633 [38464/60000]\n",
      "loss: 2.190681 [44864/60000]\n",
      "loss: 2.184609 [51264/60000]\n",
      "loss: 2.157253 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 53.7%, avg loss: 2.147785 \n",
      "\n",
      "Epoch 2\n",
      "------------------\n",
      "loss: 2.153378 [   64/60000]\n",
      "loss: 2.146364 [ 6464/60000]\n",
      "loss: 2.089663 [12864/60000]\n",
      "loss: 2.109696 [19264/60000]\n",
      "loss: 2.054691 [25664/60000]\n",
      "loss: 1.993927 [32064/60000]\n",
      "loss: 2.012046 [38464/60000]\n",
      "loss: 1.935872 [44864/60000]\n",
      "loss: 1.942367 [51264/60000]\n",
      "loss: 1.872168 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 61.0%, avg loss: 1.866343 \n",
      "\n",
      "Epoch 3\n",
      "------------------\n",
      "loss: 1.896574 [   64/60000]\n",
      "loss: 1.865302 [ 6464/60000]\n",
      "loss: 1.753935 [12864/60000]\n",
      "loss: 1.798329 [19264/60000]\n",
      "loss: 1.679188 [25664/60000]\n",
      "loss: 1.634563 [32064/60000]\n",
      "loss: 1.646075 [38464/60000]\n",
      "loss: 1.557871 [44864/60000]\n",
      "loss: 1.577613 [51264/60000]\n",
      "loss: 1.470891 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 61.4%, avg loss: 1.489886 \n",
      "\n",
      "Epoch 4\n",
      "------------------\n",
      "loss: 1.557411 [   64/60000]\n",
      "loss: 1.517499 [ 6464/60000]\n",
      "loss: 1.378475 [12864/60000]\n",
      "loss: 1.452857 [19264/60000]\n",
      "loss: 1.327028 [25664/60000]\n",
      "loss: 1.324742 [32064/60000]\n",
      "loss: 1.332958 [38464/60000]\n",
      "loss: 1.270524 [44864/60000]\n",
      "loss: 1.294558 [51264/60000]\n",
      "loss: 1.197397 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 63.8%, avg loss: 1.224672 \n",
      "\n",
      "Epoch 5\n",
      "------------------\n",
      "loss: 1.302471 [   64/60000]\n",
      "loss: 1.277554 [ 6464/60000]\n",
      "loss: 1.122700 [12864/60000]\n",
      "loss: 1.231978 [19264/60000]\n",
      "loss: 1.107575 [25664/60000]\n",
      "loss: 1.126046 [32064/60000]\n",
      "loss: 1.147005 [38464/60000]\n",
      "loss: 1.096389 [44864/60000]\n",
      "loss: 1.121095 [51264/60000]\n",
      "loss: 1.042182 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 65.1%, avg loss: 1.064461 \n",
      "\n",
      "Epoch 6\n",
      "------------------\n",
      "loss: 1.136857 [   64/60000]\n",
      "loss: 1.129793 [ 6464/60000]\n",
      "loss: 0.957540 [12864/60000]\n",
      "loss: 1.096154 [19264/60000]\n",
      "loss: 0.977111 [25664/60000]\n",
      "loss: 0.996492 [32064/60000]\n",
      "loss: 1.034744 [38464/60000]\n",
      "loss: 0.989040 [44864/60000]\n",
      "loss: 1.010836 [51264/60000]\n",
      "loss: 0.946866 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 66.6%, avg loss: 0.963091 \n",
      "\n",
      "Epoch 7\n",
      "------------------\n",
      "loss: 1.024436 [   64/60000]\n",
      "loss: 1.035121 [ 6464/60000]\n",
      "loss: 0.846315 [12864/60000]\n",
      "loss: 1.006318 [19264/60000]\n",
      "loss: 0.895568 [25664/60000]\n",
      "loss: 0.906875 [32064/60000]\n",
      "loss: 0.961912 [38464/60000]\n",
      "loss: 0.920297 [44864/60000]\n",
      "loss: 0.935666 [51264/60000]\n",
      "loss: 0.883086 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 68.0%, avg loss: 0.894410 \n",
      "\n",
      "Epoch 8\n",
      "------------------\n",
      "loss: 0.942209 [   64/60000]\n",
      "loss: 0.969627 [ 6464/60000]\n",
      "loss: 0.767261 [12864/60000]\n",
      "loss: 0.943085 [19264/60000]\n",
      "loss: 0.840771 [25664/60000]\n",
      "loss: 0.842114 [32064/60000]\n",
      "loss: 0.910283 [38464/60000]\n",
      "loss: 0.874499 [44864/60000]\n",
      "loss: 0.881842 [51264/60000]\n",
      "loss: 0.837049 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 68.9%, avg loss: 0.844936 \n",
      "\n",
      "Epoch 9\n",
      "------------------\n",
      "loss: 0.878809 [   64/60000]\n",
      "loss: 0.920647 [ 6464/60000]\n",
      "loss: 0.708628 [12864/60000]\n",
      "loss: 0.896538 [19264/60000]\n",
      "loss: 0.801345 [25664/60000]\n",
      "loss: 0.793569 [32064/60000]\n",
      "loss: 0.870945 [38464/60000]\n",
      "loss: 0.842434 [44864/60000]\n",
      "loss: 0.841782 [51264/60000]\n",
      "loss: 0.801680 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 70.2%, avg loss: 0.807347 \n",
      "\n",
      "Epoch 10\n",
      "------------------\n",
      "loss: 0.827635 [   64/60000]\n",
      "loss: 0.881759 [ 6464/60000]\n",
      "loss: 0.663230 [12864/60000]\n",
      "loss: 0.860892 [19264/60000]\n",
      "loss: 0.771334 [25664/60000]\n",
      "loss: 0.756128 [32064/60000]\n",
      "loss: 0.839056 [38464/60000]\n",
      "loss: 0.818527 [44864/60000]\n",
      "loss: 0.810303 [51264/60000]\n",
      "loss: 0.773131 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 71.2%, avg loss: 0.777315 \n",
      "\n",
      "Epoch 11\n",
      "------------------\n",
      "loss: 0.785029 [   64/60000]\n",
      "loss: 0.849350 [ 6464/60000]\n",
      "loss: 0.626879 [12864/60000]\n",
      "loss: 0.832638 [19264/60000]\n",
      "loss: 0.747248 [25664/60000]\n",
      "loss: 0.726476 [32064/60000]\n",
      "loss: 0.811678 [38464/60000]\n",
      "loss: 0.799623 [44864/60000]\n",
      "loss: 0.784827 [51264/60000]\n",
      "loss: 0.748977 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 72.5%, avg loss: 0.752379 \n",
      "\n",
      "Epoch 12\n",
      "------------------\n",
      "loss: 0.748363 [   64/60000]\n",
      "loss: 0.821165 [ 6464/60000]\n",
      "loss: 0.596683 [12864/60000]\n",
      "loss: 0.809627 [19264/60000]\n",
      "loss: 0.726800 [25664/60000]\n",
      "loss: 0.702578 [32064/60000]\n",
      "loss: 0.787431 [38464/60000]\n",
      "loss: 0.783857 [44864/60000]\n",
      "loss: 0.763441 [51264/60000]\n",
      "loss: 0.728087 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 73.6%, avg loss: 0.730864 \n",
      "\n",
      "Epoch 13\n",
      "------------------\n",
      "loss: 0.716258 [   64/60000]\n",
      "loss: 0.795902 [ 6464/60000]\n",
      "loss: 0.570906 [12864/60000]\n",
      "loss: 0.790210 [19264/60000]\n",
      "loss: 0.708924 [25664/60000]\n",
      "loss: 0.683060 [32064/60000]\n",
      "loss: 0.765218 [38464/60000]\n",
      "loss: 0.770057 [44864/60000]\n",
      "loss: 0.745024 [51264/60000]\n",
      "loss: 0.709796 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 74.3%, avg loss: 0.711818 \n",
      "\n",
      "Epoch 14\n",
      "------------------\n",
      "loss: 0.687816 [   64/60000]\n",
      "loss: 0.772968 [ 6464/60000]\n",
      "loss: 0.548524 [12864/60000]\n",
      "loss: 0.773461 [19264/60000]\n",
      "loss: 0.693275 [25664/60000]\n",
      "loss: 0.666672 [32064/60000]\n",
      "loss: 0.744639 [38464/60000]\n",
      "loss: 0.757636 [44864/60000]\n",
      "loss: 0.729004 [51264/60000]\n",
      "loss: 0.693256 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 75.1%, avg loss: 0.694682 \n",
      "\n",
      "Epoch 15\n",
      "------------------\n",
      "loss: 0.662377 [   64/60000]\n",
      "loss: 0.752029 [ 6464/60000]\n",
      "loss: 0.528870 [12864/60000]\n",
      "loss: 0.758569 [19264/60000]\n",
      "loss: 0.679539 [25664/60000]\n",
      "loss: 0.652711 [32064/60000]\n",
      "loss: 0.725482 [38464/60000]\n",
      "loss: 0.746369 [44864/60000]\n",
      "loss: 0.714857 [51264/60000]\n",
      "loss: 0.678221 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 75.9%, avg loss: 0.679086 \n",
      "\n",
      "Epoch 16\n",
      "------------------\n",
      "loss: 0.639524 [   64/60000]\n",
      "loss: 0.732772 [ 6464/60000]\n",
      "loss: 0.511423 [12864/60000]\n",
      "loss: 0.745102 [19264/60000]\n",
      "loss: 0.667301 [25664/60000]\n",
      "loss: 0.640731 [32064/60000]\n",
      "loss: 0.707678 [38464/60000]\n",
      "loss: 0.736097 [44864/60000]\n",
      "loss: 0.702467 [51264/60000]\n",
      "loss: 0.664454 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 76.8%, avg loss: 0.664804 \n",
      "\n",
      "Epoch 17\n",
      "------------------\n",
      "loss: 0.618943 [   64/60000]\n",
      "loss: 0.715011 [ 6464/60000]\n",
      "loss: 0.495833 [12864/60000]\n",
      "loss: 0.732746 [19264/60000]\n",
      "loss: 0.656457 [25664/60000]\n",
      "loss: 0.630323 [32064/60000]\n",
      "loss: 0.691113 [38464/60000]\n",
      "loss: 0.726826 [44864/60000]\n",
      "loss: 0.691608 [51264/60000]\n",
      "loss: 0.651781 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 77.3%, avg loss: 0.651678 \n",
      "\n",
      "Epoch 18\n",
      "------------------\n",
      "loss: 0.600382 [   64/60000]\n",
      "loss: 0.698635 [ 6464/60000]\n",
      "loss: 0.481811 [12864/60000]\n",
      "loss: 0.721281 [19264/60000]\n",
      "loss: 0.646755 [25664/60000]\n",
      "loss: 0.621167 [32064/60000]\n",
      "loss: 0.675780 [38464/60000]\n",
      "loss: 0.718581 [44864/60000]\n",
      "loss: 0.682118 [51264/60000]\n",
      "loss: 0.640036 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 77.8%, avg loss: 0.639606 \n",
      "\n",
      "Epoch 19\n",
      "------------------\n",
      "loss: 0.583590 [   64/60000]\n",
      "loss: 0.683466 [ 6464/60000]\n",
      "loss: 0.469187 [12864/60000]\n",
      "loss: 0.710600 [19264/60000]\n",
      "loss: 0.638022 [25664/60000]\n",
      "loss: 0.613095 [32064/60000]\n",
      "loss: 0.661602 [38464/60000]\n",
      "loss: 0.711333 [44864/60000]\n",
      "loss: 0.673812 [51264/60000]\n",
      "loss: 0.629061 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 78.1%, avg loss: 0.628486 \n",
      "\n",
      "Epoch 20\n",
      "------------------\n",
      "loss: 0.568359 [   64/60000]\n",
      "loss: 0.669443 [ 6464/60000]\n",
      "loss: 0.457789 [12864/60000]\n",
      "loss: 0.700546 [19264/60000]\n",
      "loss: 0.630081 [25664/60000]\n",
      "loss: 0.605895 [32064/60000]\n",
      "loss: 0.648438 [38464/60000]\n",
      "loss: 0.705021 [44864/60000]\n",
      "loss: 0.666651 [51264/60000]\n",
      "loss: 0.618744 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 78.6%, avg loss: 0.618238 \n",
      "\n",
      "Epoch 21\n",
      "------------------\n",
      "loss: 0.554459 [   64/60000]\n",
      "loss: 0.656463 [ 6464/60000]\n",
      "loss: 0.447398 [12864/60000]\n",
      "loss: 0.691089 [19264/60000]\n",
      "loss: 0.622728 [25664/60000]\n",
      "loss: 0.599211 [32064/60000]\n",
      "loss: 0.636321 [38464/60000]\n",
      "loss: 0.699645 [44864/60000]\n",
      "loss: 0.660482 [51264/60000]\n",
      "loss: 0.609036 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 78.8%, avg loss: 0.608778 \n",
      "\n",
      "Epoch 22\n",
      "------------------\n",
      "loss: 0.541722 [   64/60000]\n",
      "loss: 0.644412 [ 6464/60000]\n",
      "loss: 0.437865 [12864/60000]\n",
      "loss: 0.682179 [19264/60000]\n",
      "loss: 0.615912 [25664/60000]\n",
      "loss: 0.593120 [32064/60000]\n",
      "loss: 0.625168 [38464/60000]\n",
      "loss: 0.695245 [44864/60000]\n",
      "loss: 0.655253 [51264/60000]\n",
      "loss: 0.599836 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 79.2%, avg loss: 0.600031 \n",
      "\n",
      "Epoch 23\n",
      "------------------\n",
      "loss: 0.530003 [   64/60000]\n",
      "loss: 0.633191 [ 6464/60000]\n",
      "loss: 0.429049 [12864/60000]\n",
      "loss: 0.673654 [19264/60000]\n",
      "loss: 0.609426 [25664/60000]\n",
      "loss: 0.587514 [32064/60000]\n",
      "loss: 0.614817 [38464/60000]\n",
      "loss: 0.691666 [44864/60000]\n",
      "loss: 0.650827 [51264/60000]\n",
      "loss: 0.591042 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 79.4%, avg loss: 0.591915 \n",
      "\n",
      "Epoch 24\n",
      "------------------\n",
      "loss: 0.519175 [   64/60000]\n",
      "loss: 0.622782 [ 6464/60000]\n",
      "loss: 0.420901 [12864/60000]\n",
      "loss: 0.665439 [19264/60000]\n",
      "loss: 0.603162 [25664/60000]\n",
      "loss: 0.582303 [32064/60000]\n",
      "loss: 0.605233 [38464/60000]\n",
      "loss: 0.688706 [44864/60000]\n",
      "loss: 0.647090 [51264/60000]\n",
      "loss: 0.582570 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 79.6%, avg loss: 0.584377 \n",
      "\n",
      "Epoch 25\n",
      "------------------\n",
      "loss: 0.508940 [   64/60000]\n",
      "loss: 0.613076 [ 6464/60000]\n",
      "loss: 0.413340 [12864/60000]\n",
      "loss: 0.657668 [19264/60000]\n",
      "loss: 0.597162 [25664/60000]\n",
      "loss: 0.577268 [32064/60000]\n",
      "loss: 0.596383 [38464/60000]\n",
      "loss: 0.686486 [44864/60000]\n",
      "loss: 0.643849 [51264/60000]\n",
      "loss: 0.574399 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 80.0%, avg loss: 0.577407 \n",
      "\n",
      "Done!\n",
      "Execution time: 54.191 seconds\n"
     ]
    }
   ],
   "source": [
    "# epochs = 5\n",
    "epochs = 25\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f'Epoch {t + 1}\\n------------------')\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print('Done!')\n",
    "\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "print(f'Execution time: {end_time - start_time:.3f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ee1c6a-bff2-40ae-96c7-cd3314410f22",
   "metadata": {},
   "source": [
    "Running 25 epochs on the 5080 gives final test accuracy 79.9%, and avg loss 0.577765. It took 53.7 seconds. Running the same number of epochs on the Ryzen 7 9800X3D took 72.9 seconds (36% faster, 19.2s), for the same 79.9% test accuracy with an effectively same average test loss of 0.575010. And - kudos to Apple's silicon, at least for this relatively small model - running the same 25 epochs on a Macbook Pro M3 w/ 18GB of RAM using the CPU build of pytorch 2.6 via mps, took 53.2 seconds - about the same as the 5080 (actually 0.5s faster, small sample size of 1); the accuracy was 80.1% and a test loss of 0.578824. (A second MPS run took 54.2s.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec38ba11-a0f0-4180-bc27-526897c0282c",
   "metadata": {},
   "source": [
    "**TODO** There's a bit more on the quickstart page for saving and loading model weights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10765cf2-7d5d-4351-a78d-a81666ac83dd",
   "metadata": {},
   "source": [
    "**TODO** From a quick chat w/ ChatGPT, it sounds like 30-40% increase is in the normal range for small models (without a ton of parameters) and/or with simpler models (with fewer layers), both of which I think apply here. Some top-of-ChatGPT-mind things I can do to see about increasing performance more include:\n",
    "\n",
    "- Try larger batch sizes, which can better leverage GPU parallelism, weighing against 'model convergence and generalization performance' considerations.\n",
    "- Consider more complex model architectures which if done right will give better model performance while showing a bigger difference between GPU and CPU performance (because there's more that can be parallelized).\n",
    "- Sometimes 'preloading datasets into GPU memory' can 'minimize CPU/GPU data transfer'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b909009-88b3-46b1-a086-37f2e1398221",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
