{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84c10dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146b59dd",
   "metadata": {},
   "source": [
    "Goal: (like the first lecture/notebook) generate _more_ rows of text that are like the ones fed in first. Here, do this by picking a character that is likely, based on the three previous characters.\n",
    "\n",
    "\"We're maximizing the probability of the word, with respect to the parameters of the neural net. The parameters are the weights and biases of the output layer that does a softmax, the hidden layer, and the (character) embedding look up table layer called C.\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe9ce69",
   "metadata": {},
   "source": [
    "# Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b98401c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start w/ the words (names)\n",
    "words = open('names.txt', 'r').read().splitlines()\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d3e05f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d3c9699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
     ]
    }
   ],
   "source": [
    "# build the vocab of characters and mapping from/to integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "print(itos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b32e03",
   "metadata": {},
   "source": [
    "# Build the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d94c313f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the dataset\n",
    "block_size = 3 # context length of how many chars to predict the next one\n",
    "X, Y = [], []\n",
    "\n",
    "for w in words:\n",
    "#for w in words[:5]:\n",
    "    #print(w)\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "        ix = stoi[ch]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        #print(''.join(itos[i] for i in context), '-->', itos[ix], context)\n",
    "        context = context[1:] + [ix] # crop first char and append current label\n",
    "        \n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b8d3bdf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([228146, 3]), torch.int64, torch.Size([228146]), torch.int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X.dtype, Y.shape, Y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0974b379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "228146"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013ec49b",
   "metadata": {},
   "source": [
    "The X dataset is a row per each combination of three characters - including three '.' chars that indicate the start (or end) of the word - in each word in the input, with the actual data in the row an array of integers. The Y dataset is the integer of the _next_ character after the three. So, with the single input row 'emma', we generate five dataset rows, starting with '...'->'e' and ending with 'mma'->'.'. When we work w/ just the first five words, we get 32 rows/combinations of three characters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8ca1b4",
   "metadata": {},
   "source": [
    "Here's where I updated things to create a training, dev/validation, and test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4eb05a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "def build_dataset(words):\n",
    "    block_size = 3 # context length of how many chars to predict the next one\n",
    "    X, Y = [], []\n",
    "\n",
    "    for w in words:\n",
    "    #for w in words[:5]:\n",
    "        #print(w)\n",
    "        context = [0] * block_size\n",
    "        for ch in w + '.':\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            #print(''.join(itos[i] for i in context), '-->', itos[ix], context)\n",
    "            context = context[1:] + [ix] # crop first char and append current label\n",
    "\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)    \n",
    "    print(X.shape, Y.shape)\n",
    "    return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words)) # 80% for training\n",
    "n2 = int(0.9*len(words)) # 90% - 10% for dev/validation, 10% for test\n",
    "\n",
    "Xtr, Ytr = build_dataset(words[:n1])\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])\n",
    "Xte, Yte = build_dataset(words[n2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "fb9f2f8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25626"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training words\n",
    "n1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "34fc18ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3203"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dev/validation words\n",
    "n2 - n1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4430229c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3204"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test words\n",
    "len(words) - n2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d509bb4",
   "metadata": {},
   "source": [
    "# Build the embedding layer C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9df612db",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dims = 2\n",
    "\n",
    "C = torch.randn(27, embedding_dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280cffdd",
   "metadata": {},
   "source": [
    "One way to think about the embedding layer is to think of indexing into an array that maps character indexes into two-dimensional floats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1f8e2ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.6858, -0.7519])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b804b3",
   "metadata": {},
   "source": [
    "Another way to think of the embedding layer is that it's just another layer in the neural net, but one with no bias weights and without a non-linearity (like tanh). Conceptually here we one-hot encode the character we want to provide as input and then matmul that one-hot encoded input with the C layer. The one-hot encoded input has all zeros except for a one in the spot that matches the index we care about - 5 in this example - and so we 'pull out' only the values from C in that row. Ultimately we get the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9b22ecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.6858, -0.7519])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.one_hot(torch.tensor(5), num_classes=27).float() @ C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31886f67",
   "metadata": {},
   "source": [
    "Indexing is faster, so we'll do that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a63008a",
   "metadata": {},
   "source": [
    "We want to embed not just a single character, but instead the three chars we have as input. PyTorch indexing is powerful and accepts a lot of different things, including lists, and even multi-dimensional arrays/tensors. X is our input data - it's a tensor with many rows -when we test w/ just five words of input, 32 rows - and each row having three numbers, one for each character. We want a mapping between ALL of these rows and characters to the floating point numbers that represent/embed each character. Ultimately, with 32 rows and three characters each, we want an output that's 32 rows by 3 characters by 2 floats. PyTorch indexing is powerful, so to get this, all we have to do is index into C with the full X array (which again has a shape of 32, 3). PyTorch will pick out the appropriate 2D embedding values and return a tensor of shape 32, 3, 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f73932a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[X] # this embeds ALL of the dataset's characters in C\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccc68195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.6255, -1.2843],\n",
       "         [-0.6255, -1.2843],\n",
       "         [-0.6255, -1.2843]],\n",
       "\n",
       "        [[-0.6255, -1.2843],\n",
       "         [-0.6255, -1.2843],\n",
       "         [-0.6858, -0.7519]],\n",
       "\n",
       "        [[-0.6255, -1.2843],\n",
       "         [-0.6858, -0.7519],\n",
       "         [ 0.3411,  1.0509]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b391cc34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[2, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ad183e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.6858, -0.7519])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb[2, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4695088a",
   "metadata": {},
   "source": [
    "# Building the hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9065070b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many floating point inputs to the hidden layer?\n",
    "# for three char inputs with two floats per char, it's 6\n",
    "input_chars = block_size * embedding_dims\n",
    "input_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee2e5e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_neurons = 100\n",
    "\n",
    "W1 = torch.randn((input_chars, hidden_neurons)) # 6, 100\n",
    "b1 = torch.randn(hidden_neurons) # 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be37474",
   "metadata": {},
   "source": [
    "We want to do emb @ W1 + b. We can't, right now, because embd is 32, 3, 2 while W1 is 6, 100. We want to combine the 3, 2 part into a single dimension of size 6, so we'll have 32x6, which we can then matmul with 6x100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36828f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one inefficient way is via cat\n",
    "emb[:, 0, :].shape # single 32 by 2 embeddings for the first char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef37ee0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all three chars then are as follows, which gives us 32,6 as we want\n",
    "torch.cat([emb[:, 0, :], emb[:, 1, :], emb[:, 2, :]], 1).shape # concat on dim 1, not zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78f8b262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the above doesn't generalize because it hardcodes block size of three\n",
    "# i could use 'unbind' to 'remove a tensor dimension'\n",
    "# unbind gives a list of tensors like the hard-codet just above\n",
    "torch.cat(torch.unbind(emb, 1), 1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608d626e",
   "metadata": {},
   "source": [
    "But, both of the above are using new memory. Instead, we can use 'view' to just change the metadata on the underlying data - each tensor has underlying storage that's just a 1D set of data - and get a diff view without having to do anything with new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ebab720a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(18)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43dde976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1],\n",
       "        [ 2,  3],\n",
       "        [ 4,  5],\n",
       "        [ 6,  7],\n",
       "        [ 8,  9],\n",
       "        [10, 11],\n",
       "        [12, 13],\n",
       "        [14, 15],\n",
       "        [16, 17]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.view(9, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9bd96d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1],\n",
       "         [ 2,  3],\n",
       "         [ 4,  5]],\n",
       "\n",
       "        [[ 6,  7],\n",
       "         [ 8,  9],\n",
       "         [10, 11]],\n",
       "\n",
       "        [[12, 13],\n",
       "         [14, 15],\n",
       "         [16, 17]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.view(3, 3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5226b19f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "77279558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6255, -1.2843, -0.6255, -1.2843, -0.6255, -1.2843],\n",
       "        [-0.6255, -1.2843, -0.6255, -1.2843, -0.6858, -0.7519],\n",
       "        [-0.6255, -1.2843, -0.6858, -0.7519,  0.3411,  1.0509],\n",
       "        [-0.6858, -0.7519,  0.3411,  1.0509,  0.3411,  1.0509],\n",
       "        [ 0.3411,  1.0509,  0.3411,  1.0509, -0.7718,  0.8061],\n",
       "        [-0.6255, -1.2843, -0.6255, -1.2843, -0.6255, -1.2843],\n",
       "        [-0.6255, -1.2843, -0.6255, -1.2843,  1.3296, -0.3574],\n",
       "        [-0.6255, -1.2843,  1.3296, -0.3574,  0.3403, -0.5097],\n",
       "        [ 1.3296, -0.3574,  0.3403, -0.5097, -1.2017, -0.3589],\n",
       "        [ 0.3403, -0.5097, -1.2017, -0.3589, -0.8617, -0.7880],\n",
       "        [-1.2017, -0.3589, -0.8617, -0.7880, -1.2017, -0.3589],\n",
       "        [-0.8617, -0.7880, -1.2017, -0.3589, -0.7718,  0.8061],\n",
       "        [-0.6255, -1.2843, -0.6255, -1.2843, -0.6255, -1.2843],\n",
       "        [-0.6255, -1.2843, -0.6255, -1.2843, -0.7718,  0.8061],\n",
       "        [-0.6255, -1.2843, -0.7718,  0.8061, -0.8617, -0.7880],\n",
       "        [-0.7718,  0.8061, -0.8617, -0.7880, -0.7718,  0.8061],\n",
       "        [-0.6255, -1.2843, -0.6255, -1.2843, -0.6255, -1.2843],\n",
       "        [-0.6255, -1.2843, -0.6255, -1.2843, -1.2017, -0.3589],\n",
       "        [-0.6255, -1.2843, -1.2017, -0.3589, -0.1746,  0.5505],\n",
       "        [-1.2017, -0.3589, -0.1746,  0.5505, -0.7718,  0.8061],\n",
       "        [-0.1746,  0.5505, -0.7718,  0.8061, -0.9532,  0.1686],\n",
       "        [-0.7718,  0.8061, -0.9532,  0.1686, -0.6858, -0.7519],\n",
       "        [-0.9532,  0.1686, -0.6858, -0.7519,  0.3403, -0.5097],\n",
       "        [-0.6858, -0.7519,  0.3403, -0.5097,  0.3403, -0.5097],\n",
       "        [ 0.3403, -0.5097,  0.3403, -0.5097, -0.7718,  0.8061],\n",
       "        [-0.6255, -1.2843, -0.6255, -1.2843, -0.6255, -1.2843],\n",
       "        [-0.6255, -1.2843, -0.6255, -1.2843, -0.1746,  0.5505],\n",
       "        [-0.6255, -1.2843, -0.1746,  0.5505,  1.3296, -0.3574],\n",
       "        [-0.1746,  0.5505,  1.3296, -0.3574, -0.7200,  2.1354],\n",
       "        [ 1.3296, -0.3574, -0.7200,  2.1354,  0.8053, -0.4749],\n",
       "        [-0.7200,  2.1354,  0.8053, -0.4749, -1.2017, -0.3589],\n",
       "        [ 0.8053, -0.4749, -1.2017, -0.3589, -0.7718,  0.8061]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.view(32, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a9506cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view and unbind give the same result\n",
    "emb.view(32, 6) == torch.cat(torch.unbind(emb, 1), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa3fee4",
   "metadata": {},
   "source": [
    "The above does rely on the fact that 'view', when asked for a 32x6 from our 32x3x2, combines each of the 3x2 into a single 6. (Or rather, that the underlying data for the 3x2 is a 1D sequence of six values.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2bce8c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.6885,  1.7984, -0.5017,  ...,  2.0045,  1.2657,  7.6324],\n",
       "        [-4.2666,  2.1013, -0.4891,  ...,  2.0728,  1.0189,  6.6183],\n",
       "        [-2.0902,  2.6800, -2.1972,  ...,  3.2927,  2.4481,  2.0328],\n",
       "        ...,\n",
       "        [ 2.1487,  0.6642,  1.8126,  ...,  1.7950, -0.6022,  4.3396],\n",
       "        [-1.9477,  1.6876,  1.3532,  ...,  0.5476, -3.8667, -4.3770],\n",
       "        [-0.6151,  2.1599,  0.9927,  ...,  0.7803, -1.6662,  4.7585]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ultimately, we can do our matmul to get the hidden layer vals\n",
    "h = emb.view(32, 6) @ W1 + b1\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d270d07b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98a62efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = emb.view(-1, 6) @ W1 + b1 # -1 is same as len(emb), -1 sets the dim to fit the underlying data\n",
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ba8241a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e2e4081e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9998,  0.9466, -0.4634,  ...,  0.9643,  0.8526,  1.0000],\n",
       "        [-0.9996,  0.9705, -0.4535,  ...,  0.9688,  0.7694,  1.0000],\n",
       "        [-0.9699,  0.9906, -0.9756,  ...,  0.9972,  0.9852,  0.9663],\n",
       "        ...,\n",
       "        [ 0.9732,  0.5812,  0.9481,  ...,  0.9463, -0.5386,  0.9997],\n",
       "        [-0.9601,  0.9338,  0.8748,  ...,  0.4987, -0.9991, -0.9997],\n",
       "        [-0.5477,  0.9737,  0.7585,  ...,  0.6529, -0.9310,  0.9999]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = torch.tanh(emb.view(-1, input_chars) @ W1 + b1)\n",
    "h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c31bd62",
   "metadata": {},
   "source": [
    "Also, he talked about confirming that b1 is broadcast to each row of the result of the matmul. So, I think it's that we have 32 input rows of six values each, and our W1 tensor is 6x100. \n",
    "\n",
    "First, I want to remember that we have 100 hidden neurons, each of which is connected to six input neurons. For each of the 100 hidden neurons we have six weights, one for each of the inputs. This is what makes W1 6,100. We also have a single 100 length bias vector - each value applies to one hidden neuron and is the same/doesn't change or depend upon the number of connected input neurons. Ultimately, the calc for the hidden layer is, per hidden layer neuron, a set of six (normal) multiplications each of the floating point input value multiplied by the specific weight for the combination of that neuron AND that input value, the sum of which is then added to the single bias value for that neuron.    \n",
    "\n",
    "The matmul is 32,6 @ 6,100 -> 32,100. We know the matmul takes the six values in the first row and multiplies them by the six values in the first column, and then adds the result and stores it as the value of the first row and column of the ultimate 32,100 tensor. It multiplies the same six input values from the first row by the six values in each of the remaining 99 columns to fill out the 100 columns in the first of 32 rows. Then, finally, it does the same for the remaining 31 rows in the input tensor, generating 100 values each time, to get the fill out the full 32 rows of the 32,100 result. Here, we're doing 32*100 calcs -> 3200 total calcs. Our bias vector is just 100 values. We want it to be broadcast to each of the calcs we do for each of the 32 input rows. PyTorch will do this, because we start with 32,100 and are adding a 100. PyTorch lines up the 100 w/ the right-most dimension, I think, and then fills in the missing dim with '1', making a 1,100 tensor, which adds to each row the 32,100 matmul result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8b6e4957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 100])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fb4a92",
   "metadata": {},
   "source": [
    "# Building the final output softmax/probability layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3fd77385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final layer is 100,27 - 100 input neurons from the hidden layer\n",
    "# mapping to 27 output neurons, one for each character\n",
    "W2 = torch.randn((hidden_neurons, 27)) # 100, 27\n",
    "b2 = torch.randn(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f7623235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and since we have a 32,100 input, matmul with 100,27 -> 32,27\n",
    "logits = h @ W2 + b2\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c15f3199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logits are log counts, so first exponentiate to get 'fake counts'\n",
    "counts = logits.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9b882478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# then normalize to get probabilities\n",
    "prob = counts / counts.sum(1, keepdims=True)\n",
    "prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e105c708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob[17].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "426e70e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13,  1,  0, 15, 12,  9, 22,  9,  1,  0,  1, 22,  1,  0,  9, 19,\n",
       "         1,  2,  5, 12, 12,  1,  0, 19, 15, 16,  8,  9,  1,  0])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# actual error, based on ground truth Y (next char in seq)\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0a0aee",
   "metadata": {},
   "source": [
    "Ultimately, we want to index into the probabilities (one for each of the 27 chars) our model generated and pull out the specific probability for the ground truth/actual character we want the model to choose. We want this probability to be as high as possible, since high probabilities mean the model is more likely to pick the correct character. (Note that for many - all? - chars it's impossible to get a probability of 1 because in the actual data it's likely not always the case that, for even a single character, that the next character is always the same.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "727a2c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.7152e-10, 6.8770e-10, 1.3817e-02, 3.5121e-08, 9.6131e-11, 6.3133e-10,\n",
       "        2.5597e-07, 1.1481e-06, 3.1222e-03, 1.3037e-13, 5.9067e-08, 1.2573e-06,\n",
       "        1.5142e-10, 1.1750e-10, 2.7128e-01, 9.8952e-01, 3.0114e-17, 2.3178e-12,\n",
       "        6.5133e-12, 4.6180e-08, 4.4640e-03, 3.3532e-10, 6.0546e-07, 1.3365e-16,\n",
       "        2.1070e-04, 3.8987e-13, 5.2856e-14, 3.2494e-04, 8.0134e-10, 2.8131e-09,\n",
       "        1.7699e-08, 5.5911e-05])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first param - range of 32 - indexes into prob once for each of the rows in prob\n",
    "# second param - Y - is a matching length (we have one ground truth for each input)\n",
    "# and the value in Y is the index into the 27 probabilities\n",
    "# ultimately this gives us the probability for the correct next char for each input row\n",
    "prob[torch.arange(32), Y]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b475d36",
   "metadata": {},
   "source": [
    "Many of the probabilities are horrible - likely close to zero. But we haven't trained the model yet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033e5455",
   "metadata": {},
   "source": [
    "Finally, we want to get a single score from all of the input rows and ground truth values we've tried. Our single score is negative of the average of the log probability of each of the values. This creates the negative log likelihood loss.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0f8b5f73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(18.1133)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = -prob[torch.arange(32), Y].log().mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeefc0df",
   "metadata": {},
   "source": [
    "# Cleaned up and pulled together first cut at a model that minimizes the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6a098dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "karpathy_seed = 2147483647"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d9d18583",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dims = 2\n",
    "hidden_neurons = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "940ecb46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([228146, 3]), torch.Size([228146]))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(block_size) # don't set here because it affects the X, Y data\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "be02469b",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(karpathy_seed)\n",
    "C = torch.randn((27, embedding_dims), generator=g) # 27,2\n",
    "W1 = torch.randn((block_size*embedding_dims, hidden_neurons), generator=g) # 6, 100\n",
    "b1 = torch.randn(hidden_neurons, generator=g)\n",
    "W2 = torch.randn((hidden_neurons, 27), generator=g)\n",
    "b2 = torch.randn(27, generator=g)\n",
    "parameters = [C, W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "60baa771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3481"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many total parameters are we finding?\n",
    "sum(p.nelement() for p in parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6104a7a9",
   "metadata": {},
   "source": [
    "The cross_entropy fuinction used below replaces the manual calc of probabilities and the calc of the loss function - it just needs logits (log counts) and the ground truth. Besides being canned and so easier to read/search for/understand/without roll-your-own bugs, it's more efficient - doesn't create new tensors, uses 'fused kernels', and simpler/direct 'clustered' backward pass math. It also is also better behaved numerically because it avoids very large logits by shifting down, avoiding floating point inf values.\n",
    "\n",
    "I also added in minibatches. We can - and we did when we started - do each iteration - each forward/backward pass - using _all_ of the 200K+ rows. This gives us a gradient that's accurate in that it reflects all the data, but it takes a long time to do each iteration since our tensors have a lot of dimensions that have 200K+ rows. An alternative is to use 'minibatches' - for each iteration, randomly sample a much smaller subset of rows - the minibatch - and do the forward/backward gradient calculation using only this data. This gives gradients that can jump around and that are likely to be further from the gradient calculated from all data, but they still push us in mostly the same/correct direction, AND calculating with 32 input rows vs 200K+ is MUCH faster. (Also, I'd guess that since we're randomly sampling the variation in the gradients will average out to something close to the gradient from all the data.)\n",
    "\n",
    "Also, I think if I recall correctly - I thought about this in the pool at the Elua - that there's a gradient value per mathematical node in the graph of all the calcs. This matches the idea that the number of inputs doesn't change the number of gradient values, since the number of gradient values is defined by the number of nodes in the neural net and how the nodes are connected. I think. I could rewatch the micrograd talk now that I want to make sure this is correct/understand it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "bc299833",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "a3a34e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to try diff learning rates - we want more granularity at\n",
    "# small rates and less at the top, so instead of just using linspace\n",
    "# directly, we'll use linspace to get a linea set of numbers and then\n",
    "# use those numbers as exponents, to get the difference in granularity\n",
    "# we want (this is to get the best rate to train normally - diff from\n",
    "# 'learning rate decay' where we finish things out with a smaller \n",
    "# learning rate than we use normally)\n",
    "lre = torch.linspace(-3, 0, 1000)\n",
    "lrs = 10**lre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "a6e3a5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1344239711761475\n"
     ]
    }
   ],
   "source": [
    "lri = []\n",
    "lossi = []\n",
    "\n",
    "for i in range(1000):\n",
    "    \n",
    "    # if using minibatches/not training each iteration on the full 200K+ dataset\n",
    "    minibatch_size = 64\n",
    "    ix = torch.randint(0, X.shape[0], (minibatch_size,))\n",
    "\n",
    "    # forward pass\n",
    "    emb = C[X[ix]] # 32, 3, 2 # w/ minibatch\n",
    "    # emb = C[X] # 32, 3, 2 - w/o minibatch\n",
    "    h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # 32, 100\n",
    "    logits = h @ W2 + b2 # 32, 27\n",
    "    loss = F.cross_entropy(logits, Y[ix]) # with minibatch\n",
    "    #loss = F.cross_entropy(logits, Y) # w/o minibatch \n",
    "    #print(loss.item())\n",
    "    \n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "    \n",
    "    # update\n",
    "    #lr = lrs[i] # pull from our changing learning rate array, starts low and gets bigger\n",
    "    lr = 0.1\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "        \n",
    "    # track stats\n",
    "    lri.append(lre[i])\n",
    "    lossi.append(loss.item())\n",
    "        \n",
    "print(loss.item()) # loss for just the last minibatch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0442c6cd",
   "metadata": {},
   "source": [
    "The original loss was very low (I think I remember < 1), but it's because our input data when we start is only 32 rows and we have ~3500 params, so we crazy overfit. (We can't overfit to a loss of zero because in some cases - like with the first char of the word, we have many diff input values - of [0, 0, 0] - that map to different output values.) When we pull in the full set of data and get 200K+ input rows, the loss doesn't go as low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "2768d3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([228146, 3, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.3062076568603516"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what's the loss on the whole dataset? formulas are the same, just\n",
    "# the data fed to the first layer and the number of Y vals matches\n",
    "emb = C[X] # no longer a 32 row minibatch\n",
    "print(emb.size())\n",
    "h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # 32, 100\n",
    "logits = h @ W2 + b2 # 32, 27\n",
    "loss_full_dataset = F.cross_entropy(logits, Y) \n",
    "loss_full_dataset.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "927dd6b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2c3351fd0>]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAGdCAYAAABO2DpVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABuaElEQVR4nO3dd3wUZf4H8M9sekISILQAoQtIlV5VQMCC7eyeIop6oljvzoJnwVMP9U5/lruzH3axi4oioICgdJDea+g9CaTu7vz+CLt5Znb6zm42m8/79UI3s7MzTza7O9/9Pt/neSRZlmUQERERucBT3Q0gIiKi+MHAgoiIiFzDwIKIiIhcw8CCiIiIXMPAgoiIiFzDwIKIiIhcw8CCiIiIXMPAgoiIiFyTGO0T+v1+7N27F5mZmZAkKdqnJyIiIgdkWUZRURGaNm0Kj0c/LxH1wGLv3r3Iy8uL9mmJiIjIBfn5+WjevLnu/VEPLDIzMwFUNiwrKyvapyciIiIHCgsLkZeXF7yO64l6YBHo/sjKymJgQUREVMOYlTGweJOIiIhcw8CCiIiIXGM7sCgqKsK9996Lli1bIi0tDQMHDsSSJUsi0TYiIiKqYWwHFrfccgtmzpyJ999/H6tXr8bIkSMxfPhw7NmzJxLtIyIiohpEkmVZtrpzSUkJMjMzMXXqVIwaNSq4/YwzzsCFF16Ip556yvQYhYWFyM7ORkFBAYs3iYiIagir129bo0K8Xi98Ph9SU1MV29PS0jB//nzNx5SVlaGsrEzRMCIiIopPtrpCMjMzMWDAADz55JPYu3cvfD4fPvjgAyxatAj79u3TfMykSZOQnZ0d/MfJsYiIiOKXra4QANi6dSvGjh2LX375BQkJCejZsyfat2+P5cuXY926dSH7a2Us8vLy2BVCRERUg0SkKwQA2rZti7lz5+LkyZMoLCxEbm4urr76arRu3Vpz/5SUFKSkpNg9DREREdVAjuexyMjIQG5uLo4dO4Yff/wRl1xyiZvtIiIiohrIdsbixx9/hCzL6NChA7Zs2YL7778fHTp0wE033RSJ9hEREVENYjtjUVBQgPHjx6Njx4644YYbMHjwYMyYMQNJSUmRaB8RERHVILaLN8MVK/NYbDl4ArM3HMToAS2RmpRQbe0gIiKqCSJWvBkvhr8wFwBwvKQc95/bsZpbQ0REFB9q/SJkK3Ydr+4mEBERxY1aH1gQERGRexhYEBERkWsYWBAREZFrGFgQERGRaxhYEBERkWtqTWAR5ek6iIiIaqVaEVh8uGgn+jw9C+v3FYbcJ0mV//f5ZWw7dIIBCBERURhqRWDxt6/W4PCJcjzw+aqQ+yRURhb3f7YSw56fiylL8qPdPCIiorhRKwKLAL9BNuLLFXsAAC/N2hyt5hAREcWduAosft1yGGc9Nxu/bTmseb8n0O9hoNTrc7tZREREtUZcBRbXvbUIu44W449vLdK830JcgbIKv8utIiIiqj3iKrAwYyGuQBkzFkRERI7VrsDCQsrCz0EhREREjsVtYHG8uDxkm5WuECIiInIubgOLv329JmSbm3HFa3O34s6PlsPHFAcREVFQ3AYWv+86HrLNSleIVc/8sAHfrdqHuZsOunZMIiKimi5uAwuPxm/miUBXSHE5iz2JiIgC4jew0MhOSAadIckJzp4Ko2MSERHVNrUqsDCKARIcpjNksMaCiIgoIG4DC60wQXPbqY0MEIiIiMIXv4GFVsKCvRZEREQRFbeBhd0aC6e4yjoREVGVuA0stLITWiNFiIiIyD1xe6nVylgYrW7qNPPA7hUiIqIqcRtYuDkZlhF2hRAREVWJ28BCa/RotIINIiKi2iquAgsxmNAu3tTHxAMREVH44iywkITbofdHImHBgISIiKhKXAUWYuCg1e3BjhAiIqLIirPAQhJuh95vNCrEaeqBwQoREVGV+AoshNuaNRbsCiEiIoqouAoszGosrOYXZI4hJSIiciTOAouq25o1FoY9IVXBhM/PwIKIiMiJuAosFDUWp/5fWFoR3GZ1bguzuELMaOhlNwpKKnD3xyswe8NB44MRERHFkTgLLKpuB7pFxn+4vOp+i10hfpOuECs9JS/M2IhvVu7FTe8ssXROIiKieBBfgYVwO7Dg2LzNh6vut1i8aRpYiOfUOei+glJrJyMiIoojcRVYeDxi8abzUSFudIWwSoOIiGqj+AosTCIHra6QXzYdgt8vK7o37GQsiIiIqIqtwMLr9eKRRx5B69atkZaWhjZt2uDvf/87/H5/pNpni9N5LD5fvlvxs98kZWGlxoIjVomIqDZKtLPzs88+i9deew3vvvsuOnfujKVLl+Kmm25CdnY27rnnnki10TLxWm5nddPlO48pfjbrCjHLaBAREdVWtgKLBQsW4JJLLsGoUaMAAK1atcLHH3+MpUuXRqRxdokXfEmSUOb1Ke7XnjQLKCrzKh5rJ3B4be42DG7XADl1Uuw1loiIKA7Z6goZPHgwfvrpJ2zatAkAsHLlSsyfPx8XXHCB7mPKyspQWFio+BcpYjzgkYCpv+9V3K9XgVFU6lVkKex0hazfV4jxHy3X35mIiKgWsZWxePDBB1FQUICOHTsiISEBPp8PTz/9NK699lrdx0yaNAlPPPFE2A21QgwIJEnCvuPKIZ96XSGFJRWKn01HhajKNxduO2qjlURERPHLVsbik08+wQcffICPPvoIy5cvx7vvvot//etfePfdd3UfM2HCBBQUFAT/5efnh91oPWIXhkcK7dLQy1iEBhbhF29y7AgREdVGtjIW999/Px566CFcc801AICuXbti586dmDRpEsaMGaP5mJSUFKSkRKf+QMw0SJBC55jQiSwKVIGF2VohDBmIiIi02cpYFBcXw+NRPiQhISFmhptmpyUFb8uQQ7o09Kb0Pq4KLMwyEhwVQkREpM1WxuKiiy7C008/jRYtWqBz585YsWIFXnjhBYwdOzZS7bOlSXYq9hdW1lX4ZcCnCgD0RoWoMxTudIUQERHVPrYCi1deeQWPPvoo7rjjDhw8eBBNmzbFbbfdhsceeyxS7bNFvN7LshxaY2FxSm91QGJ4Ir1dGHwQEVEtZCuwyMzMxIsvvogXX3wxQs0Jj6yYiyL04v7p0t24olce+raub/k4mvezyoKIiEhTXK0Vop7kSms+iqteX2DhOMb3MxtBRESkLa4CC+VCYuYBgh4uQkZERORMXAUWYiChVWNhldlwUyvHZfBBRES1UVwFFrKqK8SsVkL/OOHdT0REVFvFWWBRddvvj2RXCCMLIiIiLXEVWIgBwa6jxSitqFzdNCvV1uAXRVfIf+dswZB/zsbBImHdEfXEWxrDWJ1mS4iIiGqyuAosxEv5nuMl+GzZbgBAgt7MWDrETMdz0zdix5FivPLTFs3zAPprkBAREdU2cRVY6HVhJKimITddC0TjOF5h2vLQibcYWhAREQFxFljo9T4kqH7Lh75YZXgcrcBDlrVvA8xYEBERBcRZYKGTsVBlFAJdJHpMJ8hS/ezRyFhEssKi3OtnDQcREcWkuAos9AICj80aC62LtjJjEfmUxeETZdhXUKK5vcvEH3H7B8vdPykREVGY7A2XiHF6NRaJNgMLrUXIxCGm0egK6f3ULADA6okjkZlatRz8l8t3o9zrx/S1+yNwViIiovDEVcZCv8bC+agQt9ti1+5jyqwFe0CIiCiWxVlgoTcqxG5gUXmcqb/vEY4den+AVo1FOMTfg4EEERHVJHEVWOhlGtTDTU2Pc+pA90z5XfP+kK4Ql/tCFPUcqjJQxhlERBTL4iqw0JtqWz3c1IxWgCLr3Abcr7FQnIuRBBER1SBxFVjoZixsphS0ikCNRoWYTZBVUu7Dom1HTCfm0jo+AwsiIqpJ4iqw0LsI2x1u6teaIEscFaK6z+zof3p/Ka5+YyH+M3uLyZ6hx+eCZ0REVJPEWWARueGmyvMofy4q8+IL1aRb4i7zNh8GALy/cKel8xvN8skMBhERxbK4Ciz01wpxYbip0QRZAP7y2Url7hr7WG2FmKUwW8KdiIgolsRVYKF3CbYbWPiEBcfsnMeM1VIP5agQ9bkZaBARUeyKq8BCqzYCsD/PhNenVWMh3HZ4bZccjB9hwoKIiGqSuAos9C7CtmssNFc3FYs3I3u1V/4essF9REREsSW+Agud7Xa7Qrwmw0IjfXFX1lhE9lxERERuiqvAQq/Q0W5XiGbGwsJ5zDiqsWBgQURENUitCCwSE8IPLETOayysUdZzqLtCGGkQEVHsiqvAQn91U3u/pnaNhfnjhj0/B4WlFbr37y0oxZ7jJbr3V51LfzIuIiKiWFY7AgubgzG0aiysjArZdugkpizeZXjsp75bZ3p+o3MxYUFERLEssbob4CbdGguX57GYuW6/7n3/+H4DVuYX6LaluNxnen6jdUmIiIhiWXxlLHS22x1uqpmxEC7wL/9svObHtNX7cLioXPO+oye1tytPpnlT82ciIqJYEleBhWtTehsUb1rNIOjVUqzeU4Cth04YPlYcblpa4cOEL1dh1roDls5LRERUneImsCit8Omvbmp35k2DGovjxfrFmaITZV7d+75esSdkm98vY8vBE5BlWfF7/O/X7fh4cT5ueW9pZTuYsiAiohgWN4HFzFPf6JvVTQu5T+wKaVAnxfRYmsNNT23aV1DqrIECrTDnb1+vxvAX5uLNedsU3R17jikzH1wrhIiIYlncBBaBrod+reuH3CcWb6Ykmv/KWhmLQDfLkZNlTptYRSOD8vHifADA/83crOhu4cybRERUk8RNYBG48GvVU4gZi2QLgYVWxiKwTWuBMruMOmZkVU5C3RZ2hRARUSyLn8DCXxVYDD+9seI+MWORnGAlY+EPKeAMBC5ms3KGS5aVwYPT6cOJiIiqQ9wEFr5TU094PBLeGN0LX94xMHif3YzFvM2H0f2JGYptge4RswXKrDCrJRVzFiEZC/E2gw4iIooxcTNBlu/URdYjVQYXudmpwfsSJHuBxc4jxaHHP3WBdyODIBl0hsjB/8D0fLJsfWEzIiKiaIibjEWwK+TUlTZRWB/EbleI5vHlKGUsZBjWWEBR2MmMBRERxZb4CSwCGQtPILCounqLGQIrGQstgaJNo8mzrDJLMojxglEgE6mw4tjJckz4cjWW7zoWoTMQEVG8snWVbdWqFSRJCvk3fvz4SLXPskBXSDBjIaw8JtYsJMVAxsKM2F51ICP+FKmMxcRv1+Ljxbtw2X9/i8jxiYgoftmqsViyZAl8vqpFtNasWYMRI0bgyiuvdL1hdomjQgBlACFef63MY6ElEFC4krEwSFnIkK1nLCIU42w+YDzlOBERkR5bgUXDhg0VPz/zzDNo27Ytzj77bFcb5URgVIh06qotzmchXn+ddoUEAoolO446erxIMqm4NMpKKFc+1T/GL5sOoVm9NLRtWMdBC4mIiJxxXGNRXl6ODz74AGPHjjW9UEZD1QRZlT+LNRbisEynxZveU2t5fLZst/NGWlA5j4XRcFNZ87Zo9e4C3PC/xTjn+bnO2uDoUURERGEMN/36669x/Phx3HjjjYb7lZWVoaysahrswsJCp6c05FfVWIjBjvjN3mnGwueXsX6fedtb1E/HrqOhw1VFpvNYKIabWttPtGZvgfEJTHB+DCIicspxxuLtt9/G+eefj6ZNmxruN2nSJGRnZwf/5eXlOT2locA3e4/GlN7iN/twAgsry68Papfj6PgBRpd09cqnesWbX2msnkpERBQNjq6yO3fuxKxZs3DLLbeY7jthwgQUFBQE/+Xn5zs5pSl1xkIUqL8AgKYaq59a4ZNlS8uvWwk+jCbIAvQzESFTWmjss/tYMRZvD68OhAkLIiJyylFgMXnyZDRq1AijRo0y3TclJQVZWVmKf5GglbFo16iycLFT06pznpFXV/cY1/VroXuf3y/DQsygGdio2ZnSW+T1+5VTevtD9zl2ssL0/Ga4NDsRETllu8bC7/dj8uTJGDNmDBITY2dG8MC3eTGrMP2eM1Hu8yPBI+H8Lk0woG2O7nDTl645A2lJCfhw0S7N+70Wu0ISPOaxmniUwyfK8MwPG4I/q7s7RH5VIKEVADz4xSrT85thxoKIiJyyHRnMmjULu3btwtixYyPRHseq5rGo2paY4EHiqQ2vXt8LALBur3YBZt/W9bFhX5Hh8bXqN9SsDDoRMxYTv1mL71btC/4sQ7/Owuv3GxZ2yrKMdRYKTM0wriAiIqdsBxYjR46MyVEDVYuQGV/8tRIKCyecgybZqdh68KTu47x+2VI3h5XgQ6Q1gkTv+Q3JWKj2c2tS0Fj8+xIRUc0QN2uF+FQzb+rRCjyanFoJ1WjEiF+WFXNj6LFUYyF0hqi7ZmTZJGMhTvetkbFwA8MKIiJyKnaKJMLkt5qxMLjbKLDw+mVLE4FZmStMkoDF248iKy1R85x68YFPVX+hrrFwbRkTRhZERORQ3GQsAt0EZl0RRsGB0aycPr9sabSE2VBSANhfUIqrXl+A816cp3NO7fP4/LJyrRK5cpbNe6aswO5jxa6N5mBcQURETsVNxkK9uqkeo3sNu0L8+qM1FMe3kLHYV1AavK01ikTvPF6frMhK+GXgon/PBwDsOFKMT/7U3/zkFrDGgoiInIqjjEXoqBAtackJuvcZrXzq9cuWlim3UropBjBedUUm9DMGmw8W4X+/bhf2q9pz68ETHCZKRETVLm4CC6ujQnKz09CifrrmfUYZizKvH9PX7DdviM06jDkbD4Xcf7ioLGQbAIx9Z6niZ3VNhVaQ4gTjEyIicip+AguLo0IA4P5zO2huN1v5VG/yLJGVjIV6xVK1P761yMJRlF0WJ8q86PXULEuPMz+uK4chIqJaKG4Ci8DF0Mp6HnrrhThdoExkpcbC69LwDXUAUO7V6FZxECVwSm8iInIqbgILo9VN1Xq1rIes1NC6VVcCCws5C6/PpS4LC9d/JzEMMxZERORU/AQWFkeFBNw4qHXItkSPZCnjILppUCvFz5YyFj53rtxWikmt7KPGwIKIiJyKm8DC6qgQI5IkmdZZqD1+UWcM69io6hgWHlPhVleIhX0Wbz+KE2VeV85HRERkJm4CC6ujQsw46Q4Re1+snN7n0ugNK9mI695ahD++udCV8xEREZmJm8BCa9l0QzoXZaO5LPRVndPKtN8VLnWFWO2yWLW7wOZx2RdCRETOxE9gYWO4KaDfjaDuCrFyOJsLmrpWvBmpGScYVhARkVNxE1jYGRViRJ1xMLrITr6pT+U5JTFjYX4Ot4aburboWMhxnR14+pr9eOq7dabzdBARUfyKm8DCb3NUiN6187r+LSztd/Pg1hjaobJoU1zuw8pw02h3hUTruOM+WIa35m/Hd6v2utsgIiKqMeImsKjKWIR3nDuGtMOmp8433e++Ee2DtyWbGYtoFm/aOp5fxsRv1uKgzpTiVu0XFlkjIqLaJW4CC79Lo0IA85Ehwzo2Qp2Uqgm2xDNaObtb81i4nbH4ce1+vPPbjrCPw44QIqLaK44Ci8r/Wy/edH75U5+i+mos3L2EHz5Z7spx3G4XERHVHHETWAS7QlzIWJhRF3iKP1o5v3ujQmIT4woiotor7gILyxmLMC5+RhkLK/a6VIPgJDOQf7QYFT4/Nu4vwtZDJ1xpBxERUUDoSlw1lGxzVEg41IGE+KOVCbLcYjeu+HXLYVz31iJ0bJKJDfuLAADb/nFB2EN01fwcbkpEVGvFT8bi1FU2Gtd1dWChqLGI/OmD7GYsPlq8CwCCQQVQ9bwRERG5IX4Ci1NlC1a7QpLCWK1MHby0yknXvS+S3AgJIhFXMFQhIqq94qYr5LNxA+D1+ZFXP918ZwBjB7fGj2v3Y1TXXNvnUmcsbjmzDQ6fKMeITo2x+UCRzqPcZyco8PllzWxKOKNj9HBUCBFR7RU3gUXrBhm29s9OS8L0e8+ytK8kKS/i6qRIalICJl7cGQCw5WD0CiLtLBZWoTMSJSIZC8YVRES1Vtx0hUSS+pu+UbFjrHaFlOsEFpHILjCuICKqvRhYWKAe6WE0vDSqxZs2Rl9UeP2aI1Yik7FgaEFEVFsxsLAgJGNhFD1Ec7ipjX31Fj6LSMaCcQURUa3FwELHeZ2bAABuGtQqJFaImYyFjSt4udePb1eGrjoaiSknIlEQSkRENUPcFG+67YWru+PaHS0woE0OPly4C2J+wOh6Hs0aCzvX7xnr9od9DKs4PxYRUe3FwEJHenIizm7fsPIHVbBQYbDsuRTFnIWdC/hT09brHINdIURE5B52hVigDhWMlj1XZyzuHX4a7hvePuw2ZKaExoBudDlEZlQIIwsiotqKgYUF6mDBa5ixULp3eHu0blg1x8YFXZs4akNyYuifyo2YIBIhADMWRES1FwMLC9TFmnYyFoBy+OWky7o5akNiQuiB520+5OhYosh0hTCyICKqrRhYWKC+pPsMihvMaiycFncmekL/VG/O2+7sYIJADPDx4l2Y/Gvo8bYeOoH/ztmC4nKv7WMSEVHtw+JNC9QTS1UYVU2aBA5OSzu1MhZukGVg2c5jmPDlas37z3l+LgCgsMSLh87vaOmY4YwK8fllvDhrE/q1zsHg0xo4PxAREVULZiwsCC3etFZjcceQtiH3G82BYcTqqq12+WUZl7/6m+l+a/YUWD5mOMWbXyzfjVd+3oLr317k+BhERFR9GFhYoS7eNKyxqNr5Ao2VU512hSRpdIW4wWqNRWaq9eRWOF0hu48WO38wERFVOwYWFoRkLGyMCgm9v2qPJBvdG5HKWFgNAupoDHfVPyaLLIiIaisGFhaoayy8RsWbkvZtrW1GRaBq1R1YZKYmWT+mw7YQEVHNZzuw2LNnD66//nrk5OQgPT0dZ5xxBpYtWxaJtsUMdYCgt6CXel+tegpxk50iRzGuGDOgpfUHmrj2zYWW9tuwvxAFJRWW9g0rYRHVOdGJiMhttgKLY8eOYdCgQUhKSsIPP/yAdevW4fnnn0fdunUj1LzYYK94s2pvzYyFw3EhYtbE42L2Ys/xEkv7/bb1CEa9PM/SvkZ1Gz6/jIJi/QCFYQURUc1ma7jps88+i7y8PEyePDm4rVWrVm63KeY47grRuEw6/UIuxhIJ1fStfvcxa0FIQEm5D/sKStCmYZ3gtmvfWIjFO45i9l+HoHWDjJDHMGFBRFSz2cpYfPPNN+jduzeuvPJKNGrUCD169MCbb75p+JiysjIUFhYq/tU06mtdhUHGQvG4Uw8Uv8A7HW4qPi5S9RZuCfy6F7w8D8Oen4slO44G71t86vbXK/ZoPjaai7gREZH7bAUW27Ztw6uvvorTTjsNP/74I8aNG4e7774b7733nu5jJk2ahOzs7OC/vLy8sBsdbepYwHDmTWFnrUuk08umJ0JdIZEQGBWy/fBJAMC0VftC9on14IiIiJyxFVj4/X707NkT//jHP9CjRw/cdtttuPXWW/Hqq6/qPmbChAkoKCgI/svPzw+70dFnoytEvH0qGDAbKWKpBTHQFWKVleJNvcAixn81IiIyYSuwyM3NRadOnRTbTj/9dOzatUv3MSkpKcjKylL8q2nUF7s/9GhmaV/t4aZVG7PTrA/hrFkZC/N9nHYJERFRbLMVWAwaNAgbN25UbNu0aRNatnRv+GMsEq/jr13fC38Z2V53X8WokFP/V19ov7lzEIZ0aIh3bupjvQ3CXyrWMxbqUSFazdWLjWL7NyMiIjO2Aov77rsPCxcuxD/+8Q9s2bIFH330Ed544w2MHz8+Uu2LCWKwcF6XJkhJTNDfV5Gx0L5MdmteF+/c1Ben51rP3ojf8O0sSPbL/UMt7+sWdcJCqyCTXSFERPHJVmDRp08ffPXVV/j444/RpUsXPPnkk3jxxRdx3XXXRap9McHOxU7SuR1+G4SuEIsNyqufhhY56S62Qp84jbc6Q6OdsWAEQUQUj2wvm37hhRfiwgsvjERbYpadS6DZzJsiOxdXxTwWMTgRuxhMfLF8Ny7o2iT4c6DpfqHoVT9jwYCDiKgmi8FLVOyxd7EznnlTZKcG0+MgYxFN6u6Pm99dGrJPhbB4W6wXoBIRkTMMLFxmq9vEccYi9i7KRiuaBn5NcY0VjwSs2n08ONeFel+gMsPxxzcX4p4pK1xtKxERRQ4DCwsc11i4mLEQg5DEWAwsDO4LtF1cY+VwUTku/vevGPqvObqP23igCL9tPYKpv+91qZVERBRpDCwsqJNivRRFMfPmqduyzmXXasYi0SMpgpBY7EYwmrsi0NpyIbDYeeSkzr5Vv5t4TL+dpWCJiKjaMLCw4MVrzkCbBhl4+doepvtGYlRIndRE5Voh1VhjodflYbSiKTS6QnwWZtES5+4wmu2UiIhiBwMLCzo2ycLPfx2Ci7s3Nd3XzqgQqyZe1Nl05s1zOzd25VxmxHVS/H4Zq3YfR5nXZ/iYQBaiwluVsdCLE/SeP6P1WYiIKHYwsHCZG+uCiBb/7Rxc2qOZIpjQqrF47vLu4Z/MAjFz8N6CHbj437/iL5+uNO4KCWYshMBCJ1AQfzPx1/T6ra0oS0RUU8myjCMnyqq7GWFjYOEyrSm9w9EoMxWA+agQKUp/STGwmPzbDgDAd6v26daRiBRdIXqBheJXY8aCiGqPBz5fhV5PzcLPGw5Ud1PCwsDCZVIkiixgPo9FtOa2EEd2NK+XFrxtlLF4dc5WFJd7lRkLxUydVbe1pv8GIltjUe5lNoSIqt9ny3YDAF6atbmaWxIeBhYuU4wKcTGykEwyFtEaKCJmHZrVTRO2G1+cv1251yCw0H6MGHBEKmOx53gJOj76A/7y6cqIHJ+IyK5wPu28Jp/F0cDAwmVaNQJWlhE3EysZC/ECn5Vatez7iTKv4ePKvX7FcFMxTtAbUSKOHIlUxuLd33bAL1dOQ05EFAucXjMWbTuCjo9Ox7unuqmrCwOLCHJz3QsnM2+6EdCo9Z/0E748dRFWBAcmQXKFT9atsRCPIz5lXnF/H2ssiKh2MBy+b+DeT36H1y/j8W/WutwiexhYRJCbOQRPDM28+edPV8LvlxUvfrM3QoXPrxgJougK0Un8iVkKjgohotrC6ZfCWJk6kYFFBLnZOyGZzGORkhj6p4xk78g/vl+PXzYfCv5sNuFVhc+vG4jIioyFOBLEL9xmxoKIagenn3axsjq07WXTybpA8WaSC+ucK7pCVC+eN2/orfmCikRXSMBb87crfjabcrvcJyu6PHw62QuR1+ZMnURE8cBoUceagIFFJJ261p/buQn6tq6PXi3rOT6UcuZN5X0uxC1hM0sohGYstB8rhkdi8OFljQUR1RI1PK5gYOE28fUQyDIkJ3rw6W0DwjquUcYiWiNCjJh1VVR4/YooXNbpFlEUbwrHZFcIEdUWViYcjGUMLCLIzf4u8VjqUSGxEFj8a8ZGw/srMxZVP4uBguwHFm8/iqMnlVPZKjIWEQosqv+ZIyJScly8GSMfaAwsIihSo0JiMbD4ecNBw/srayzEmomq+2TIuOr1BQCAsYNaB7dHI2NRs78XEFE8cjrcNAYuBQA4KiSi3PwjG81jEfjR6vwW1cGryliszD8evC1uP1BYGrwtjgrhcFMiqi0cjwqJkRwsA4sIcvOPLA4xVWcoAvdV9/wWRip8ft1KZ0V0zhoLIqrtavjHHQMLl8k6hYjhMlorJBBoxHZgIeum93Sn9GaNBRHVQuwKIV1O/sjd8+pqbjeusdDeHkvKfX7dab/F95AYmFVEYUrvGv7FgIjikPOukNjAwCKCnHSFvHdTX4zqmgsASE2q+vOIMYO6KyQwYqRT0ywHrYyOcq9fNwpXBhZVt5U1FgwBiKh2cD4qJDZCCwYWEeTobywBT/+hC+4+5zT8cM9Zwc1Ga4UEMhUvXdPDUTujwS/Lum8Wn8703tGosYiNtyERUZWaPo8FA4sIsnLR+u6uwbjnnNOqHiMBddOT8ecR7dG6QYbmsfS6QhpnpSq2X907z26TI8ZrUGMhdnOIbyh/DC9CtuPwSXy4aCfKvbHVLiKq+Zx+3MXKFyXOY+Ey5cyb5n/mLs2ykZ2WhJd+2gzA4IVhsAiZ3nluH9LW9PzR4vPLutN+62UsHp1atfRvrI0KGfKvOQCAwhJvTD3PRETVjRmLCLLaFSLuZ6WPTD2lt57EWFhE5BSvX7/GQqylKCyt0Hl85WNlWcaOwydjZpGexduPVHcTiCjOOP58i5GURexceeKQk0IavUc0qJMcvK1ehKwm8Pll3TeLT0j7Ldx2VHOfQLfI09PWY8i/5uC1udsU9x8qKkNJuc+dxtoQG+ENEcUTjgqhsFkJQLo2yw7eVnd9hPvlvW56UvB2enICmtdLC++AGrxGXSEWujkCGYvAcu3PTt+ALQeLcO7//YJ3ft2OPk/PQr9/zHKtvVbFSOKEiOKI83ksYiO0YGBRQ3Rplo3MlEQ0zU5FZqqyNMbui/Davi1071v39/Mw7e4zHbXRSGWNhflEWEaPV7v3k9+x8UARJn67DgBQWOq137DYeB8SUS23bGdVtraG94SweLOmSErwYMkjw+H1y0hU9YWIr8EPbu6HR75ejUmXdXN8rkgEvUbFm1ZGfFT4QvcpKNGux7CFGQciigGXv7ogeLumfywxsHCbg1dEslBkaXRRT01KqDyFKpwVfx58WgPMuX+oyRmNGxmJqNeoxsJKxkVrgqwYG4FKROQKp8WbMdITwsAiFjTMTMFtZ7VBUoIH6cnmfxJ1P5rb0W0k+ukqhFEhHkm5oqnXwnTdFRrzRWh1j/j8clSnNq/p3yyIKPY47wqJjciCgUWMmHDB6Y4f6/bQy0i8NCu8VV0hiQkexcRSPgvt1+oK0Xpchc+PBE+C9YbFxvuQiCjI8aiQGPk8Y/FmHKibnmy+k6A6RjLsLyzFpgNFAIAkVUbBSvFmmVZgofG4co39DDHlQEQxJlbm6XGKgUUNl5udirYN6zh+vNZS65GKer9cvqfynKqJu6wEFhVe7W6P0P1YeEFENVuMTTRsGwMLl0V78ZjRA1qG9XiteoRI99MlJdjPWGh1hfg1Hnf3lBX4dcth640RmuLkW0JN/2ZBRLGnpn+uMLCo4ZwEAb1a1gvetpKxSEqQ0DQ7NWQ/p9TDZa0siW61xuLXLUdw3VuLNI+xfNcxbDt0QvccNfy9TERxwnmNRWwUWTCwqOHsvo5euKo7Lu/ZPPhzswjMsmkmUZWx0Mo8qGnVTthZmGz3sWJc9t/fMOz5ubr7OJ3tjojITUWlXry3YIftzEVshBU2A4uJEydCkiTFvyZNmkSqbRQBl/VsDo9HwpQ/9cfgdg3w2vW9QvZRBytuX2+T1DUWlkaFaMxjYaNh2w6dNN2HYQURxYrHpq7Fb1vtLXIYIwkL+8NNO3fujFmzqtZkSEiwMbSPXOf0ddS/TQ76t8nROaZW94h7r1h1XYeVzMNP6w9gf0GpYg4MOxkLK81nxoKIYsnOI8UY1K66W2Gf7cAiMTGRWQoDZ+RV1i+kJ0cn4IpEhKo+5vX9W2LmugOuHV9d12Flgqzich/6T/oJyQmeYLeIncppK7UoVuOK0oqqVVQZixBRpNgdDBArGQvbNRabN29G06ZN0bp1a1xzzTXYtm2b4f5lZWUoLCxU/Itn9TOSsfzREVj2yIjqboplV/XOAwD0aVUZFImvzTYNM/BwGJN3aXHSFRJgdcn44nIvrnj1N/zzxw0A3M1Y3Pb+MmuNICIKQ0394mIrsOjXrx/ee+89/Pjjj3jzzTexf/9+DBw4EEeO6PcDTZo0CdnZ2cF/eXl5YTc61tXPSEZatDIWLpTr/HVkB7w9pjf+d2OfymMKV+FhHRohOVH5MmlRPz2s86mLN+10aaiXjNfz/oKdWLrzGP4zeysAZWChVyxq9U08d9MhazsSEYXBfvFmbKQsbAUW559/Pi6//HJ07doVw4cPx7Rp0wAA7777ru5jJkyYgIKCguC//Pz88FpMCm6kvpITPTjn9MbITE2qPKZwX0JC6Am+uXNQWOdL8tifICuguNxnvhOAVXsKFD+Lbzi94a2ssSCiWGL3E6nGdoWIMjIy0LVrV2zevFl3n5SUFGRlZSn+UXS9dM0ZSE9OwLtj+1raX3xxBuohcupUTRtudwpxtZDhphG4oKtHgYhlHXrnczLbXbQnRCOi2FZYWoFvV+5FicUvQUbsfjTGSFwRXmBRVlaG9evXIzc31632UARcckYzrJl4Ls5u39DS/mJXSMKp7MKLV5+Bni3q4n839gYAPHVpF5x5WgNH7VFP6W2leNOu9fuUtTzi76SXsajps90RUfUb9/4y3PXxCjw2dY0rx5u+Zh9u+N9iHCoqs/W46vw8sxVY/PWvf8XcuXOxfft2LFq0CFdccQUKCwsxZsyYSLWPTFgdBupxuJR4IGPRpmEdfHnHIAzr2BhA5UiR92/uZ3xOnVM6WYTMTXrnq+nz8xNR9QvMPfHZst1hH0uWZYz7YDl+2XQI//h+veG+fr+MlburuoCr8/PM1nDT3bt349prr8Xhw4fRsGFD9O/fHwsXLkTLluGtV0GxS2stEatSkxI0ayJC5rGIQmQtnlIvsHC2VojTFhERGRM/Xg6fCM1YHDtZjo+X7MLlPZtj/mblGkk+vxzW53c4bAUWU6ZMiVQ7yKFIv2zUC4bZkaYTWIQMN41waK0OGBTnE24yY0FEsUTxUaXx+TT+o+X4besRzFp3AA3qpKgeW0O6Qqj2US8YZkdqkvaQ23CGmzrh88uKN6j4hhNvM2NBRLFE1vmsCgh0uyzfdTwkO8HAghyL9PAidRBgR2qS9svLyeqm4fD6ZUXwsjL/ePC2nxkLIqoBjAKFBI8UUkcX7do1EQOLGiqvfuWqpOecKqaMlHBrLLSou1esrG4aDq9fVkT+fxJmzpQVvSKMLIgoNhl9TDaok4wESZ2xiHCDDNheK4Riw6w/n43CEi8aZqaY7xwG9boedqhn7AweUxVYRDpj4fPJum8yZbdIRJtBRGSL4ouPQcaiQZ2U0K4QZizIrpTEhIgHFUDVPBZOpOgFFqpjRrovsMLvDzmH99RCZoo+TAdvRGY5iChSxM8X8eOpsLRC0dWRkZIYstxBddZYMGNBhpxkLLo2y0aCR0J2WpLm/equkOgUbyrPcbykAg3qpJhWXRMRVRetovODhaXo+4+f0L15dvA+CYBqsF1UhvHrYcaCDDmpsZg6fhC+umOg7v3qmTcjHVhU+PwhQcOxk+UAlN8IrGQfHvl6tattIyLSI2t88Zmx7gAAKCbDkqTQz+pkdaQRRcxYkCEnGQuzWT7Vx/T6/bbPYUf+0ZKQ4OXoqcDCzqgQWZbxwcJdqm2uNJGIKITii8+pD5t0nZWzxa6QN2/oHfaaTuFgxoIMhTMqRO+iq66xiHTG4to3F4Z0hRSVegGYjxMXVefwLSKqfcS6r8BNrcBCgqT4rK6mCTerzl+9p6dYF848FlaP6cYqgGbUMUGg/9Fq1TUQ+dErREQirz/0i4/eMH4xY6Eu5Iw2BhZkSO9FbIXeZVhdvPn173sdn8NyW1RBQ+Bn5cybxsco90W2y4aISOTTyFikJGpkLFQ1FtUcV7DGgrTddnYbbD14Ev1b57h+7HCmCXdKnWwI/GynxkJreXfmMIgoUsSMReDLkF6RubIrpHojCwYWpGnC+aeHfQy9DECSzvwWkTR97X7Fz4FvArIisDDpCtHKWDCyIKIIETMWG/YXAdD+XJUkZZaiujMW7AqhqEuqhsqib1cqu1v8wRoL68WbFRZrLHx+GaUVka8bIaL4ps6SLtt5VPNzSoIU1izJbmNgQRFzRa9mAEIrlM2Go5o5r3OTsB4PVEX9dmosNDMWGs578Rd0e2JGVIpSiSh+qYOIn9Yf1OyylSEr1gqp7hFsDCwoYs7t3ATf330mVk88V7E93P6/Qac1COvxQNUbTz3zpizLeH/BDizefjTkMRUWA4vNB0+g3OvHqt3Hw24nEdVeWnP8aGUs/H5AEj5Xq3t+HQYWFDGSJKFT0yxkpCTinZv6BLeHm7FTr+LnRLArRLXtl82H8ejUtbjq9QUhj6nQLN7UfwdL1d3RSUQ1mlbmQWtY/IJtR/DST5sNHxdNDCwoKtysWNYKTK7o1Vzx84TzOxoewy/L8Pr8itoLvyxj84Ei3cdojQqx204iIqu0PnOsTFRcneuEAAwsKErELENSmHPYi4FJh8aZmHxTHzx+USfl+Uyu6n4ZmLvpkGKbDO2sRECFhXe0OFMeMxZEFA6tzIOVVUurc8l0gIEFRYlYsFkvXXvVUyfH6tGiLoZ2aBQSSEiShMk39lE/NMgvyyE1E7LGNpGVjIX4TYEZCyISFZZW2Lroa832a+XhzFhQrSBe+MNdHEfrgq3uXvFIQOdmWbrH8PvlkMyJXzYe+aEVdKjfv+I3jHC7fKq7n5SI3LN0x1F0mzgDYyYvtvwYdYDg88umSw8A1oKPSGJgQVEhBgP1MsLMWGhcsNUZC48kIclghk+/HPoYv19GuVFXiFZgofrZp+gK0T2Uwvp9hcHVVgOe/G4dej81EwcKS60dhIiqnd5F/2BRKa54rbIgfN7mw5aPN23VPsXPpRU+S0EDu0IobtRLT8KdQ9tp3ldS7hf2CzNj4QkdVqUeKeKRgASDBdQqizdl1TbjjIWVrhCvzYzFur2FOP+leej91EzF9rfnb8ex4gq88cs202MQUWzQu55rDV93orjcZ6nGorqznZzSm1yz7JERupNfFZVWBG+Hs7AZoN0Vor6GSyYZC59fRplXVWMBkxoL28Wbprvjt62V3170PgesfIgQUWw4We7V3O7W2h0lFdYCi0ZZKa6czylmLMg1RjNqdsurCwBIDnNECKA9j4V6BIZHkgxHhsgyUO5Tzozp98OkK8Re8aYVZtPwMq4gqjnE4eviZ51bhdwl5T5LnwmD24U/iWA4mLGgqGhWNw2/3D8U2WGOCAFUM8zpTFDlkYwv2j5ZRlmFMgNxstxrmLHQLt4MLa6quk+5b0FJBV75aTN6t6qH87rkArAyLJaRBVFNcaCwTOce4/f5fIt1FxV+2fQz4aZBrap9qDsDC4qaFjnprhzHSvTvkSTDDIpfllGuChQKSioMayyW7zpmel69vs3ici+6PzEDAPDW/O3Y8cyoynYysCCKGz6hu9RvY+j59W8vsnR8v182Ld6s7iXTAQYWVAOJ3/IlvW8CJu8tWUZIxqKwpMKwu+ODhbs0tweGgCUmeBSBhfjBsu3QSc3Hmk1PXt3DxojIOq/G+3/aqn34dGm+K8f3WchYVH9YwRoLilGtG2To3uex0BVi5vCJMuw5XqLYVlBSochiiN0cYvGpSAYw4oW5OPO52fD6/IrA4uJ//4rL/vsrPl2ar9vFIgZJo99ehDKvsu7Dyph1IooNPp8YWFT+f/xHy0Nm+RVZXdwQqOzCNftMCHf1aDcwsKCwvDG6F3IykvH+zX1dPW5eff1uE49HQkZy5ciSoR0aae5j9taa/OsOvPPbDsU2dVeIGCRsP6ydcSgp92Hb4ZPYV1CKfQWlIcWby3cdxwOfr8LXK/ZoPl4MLOZtPhyyn5V1AYgoNqhnyrQyn0Rphc90H/F4Zoes/rCCXSEUppGdm2BEp8auFwslG8xB4ZGAOfcPxYb9ha5UP0tSZdfIseIK/J5/PLjdJ8vBN4heV4YYR8iyfo3F77sLQrYVllbg+9XqCXCUkQRrLIhqDvWQdPWQdi1W9gnwyRa6QmKgxoIZCwpbOC/k5EQPmtVNU2zr0iwLD19wuu5jPJKEhpkpOPO0hq68iRpnpgIANu4vxLHiqi4P8TNi26ETmo/dKKyGKkPWDSy0spO3f7AMs9YfVGxT/zrVPec/EYXaeugEpv6+x3BUGICQrk0tdjIWlfVcxvvEQE8IMxZUvfx+Gep5rL6760zD0Rluv29aN8jA/sLSkKyEovjyVFdITkYyjqim3w4wylhotfnXLUdM28a4gij2nPP8XABAoseDUd1yg9vVs/NayUaos5RGVu0uQGqi8QSDMZCwYMaCqpfXL2uOjAh3yJSdTMZpjesE2yISswW7j1UWerZtVEf3OD7ZKGPh7Pc5fKIMb8/fHrKWCBFVvxWqIejqzxD1yDMtVrIaosU7jKcHj4XhpgwsqNppvRGM3htWvsTbeWupu2ICxMKr8lPfPLJS9ZN8Xp+s23Vh9b2u3m3e5sN48rt1uP2DZdYOQETVRh1YlFrqCnG3Qps1FlRr9WtdHwBwcfem6HvqtkiSJDx2YSfcO/y0kPvsdA88Mkq/ViMgKcGDlMTQt4KYfQjcNlrnpEI13FRk+c2us98ilxYxIqLI8amLNy0EDbuOaheGO1X9YQVrLKiavDG6N37acAAjOzeBLMuYsiR0Apmxg1sDAF6ctVmx3c7cFcNPb4ynpq033CcxQdK8nosxQsWpDwyjwMLr1+8KsfpmP1xUhiMn9KYFJqJYov7cUNdYWMlY3PfJSjebFBNdIQwsqFpkpyfhsp7NHT3WTsYiWSMToeaRJM034+fLduPnDQdw/7kdgwFDmlFgYZCxsPpmf+mnzXjpp83mOxJRzAkZFaKTsagsWo9MAMBRIUQO2BkokWRhNdVEj/bE4M9O3wAAuOr1BcE6jNQk/eOVGwQWRBR/1F2cFRaHm/pkGZ4IdVrEQMKCNRZU81iZ5jrw5rKUsfBIpjUQgYlvjDMW+sWbdqbtJaKaIXQeC2sTZEXyC0iNL96cNGkSJEnCvffe61JzqLa6a1g7AMD1/VuY7qv3lvy/q7uHbNMqylTTy1iIAh8EKQaBxQ9r9uPOD5dr3qcOLJysATJv8yG8MHOTpWmCiSj6QmosdCa/iuSMujW6xmLJkiV444030K1bNzfbQ7XUfcPb44KuuWjfODPkvnFnt8Vb87aFDOVS+0OP5sFCqMB7y0pXSIJHQqemWYYjLwLnNgpUPl6svfopEPrNxcnnyui3FwMA2jbMwCVnNLN/ACJylTo7EDrzpn7GYvxHy5GblQqP5GwV48t6NMNpjTODXbZVbbJ/LLc5ylicOHEC1113Hd58803Uq1fP7TZRLeTxSDg9N0uxKFfAQ+d3xPonz6vaYONNqD7e6blZmvu8cPUZhscJfBOxkgHRUq4OLBwdpVJgsi4iij6tbOP+glJMX7NPsToyAJTpZCw27C/CtFX78Nb87SFBRcsc/QUYRanJCfhjv9AMbywUbzr6lBw/fjxGjRqF4cOHu90eIk1i5qFhZoqjY7x8bQ9cckbTkO2JHkl3kqyAQI1Fisl0unq2HdafLpyIag4xKxG4hg/91xyM+2A5VqkWG9TLWBhd+98Y3Rs//+Vs03Z4pMrPrtDt1R9Z2O4KmTJlCpYvX44lS5ZY2r+srAxlZVXj8gsLC+2ekggA8M5NfbD7WAm6NMs23VesmjinYyNsOliEkZ0a470FO0L2tfJGDHyYWCkGtSKcwOIYp/cmqjZaXbIlOpkJvVk1jQosEzwScuqYf3nySBISDVaBrk62Aov8/Hzcc889mDFjBlJTUy09ZtKkSXjiiSccNY5INKRDI0ePe2tMb/jlyjesVhBh5c1ZEWZXiFo4CYu35m9Hekoi/jyivSttCSgsrUBRqdc0e0NUm9kZ4aU3QZbhIos6mQg1jyQhSb2CI2IjY2HrU3LZsmU4ePAgevXqhcTERCQmJmLu3Ll4+eWXkZiYCJ8v9EmcMGECCgoKgv/y80NnWCSKJEmSgrUWWm86O2/EFIN5LOwItyvkZYNJtBZsPYIpBoWkog37C4NLwnd/YgYGPfMz9heUhtU2onimHvlhRF1bFVBhcAwJobVhmvtJ0JxkKxZqLGxlLM455xysXr1ase2mm25Cx44d8eCDDyIhIbT/OSUlBSkpzvrEidym9aZL1Ij69SRrvMadiOSI0WvfXAgA6NQ0C92a19Xdr6CkAue9OA8AsH3SBcEsyopdx3B+11zdxxHVRn6/jPX7C5GTUXU9M/uCoJfdKNf4Eh7gEb4IGdH7QhQL81jYCiwyMzPRpUsXxbaMjAzk5OSEbCeqTnrvLa03rI24wrUai4v/Pd+V46gVl3uDtw8WGq85cqCwKjPBqTGIjP1zxka8OmcrzulY1SVrNgReN7DwGmQsJCBB9QF2VvuG+GXTIcU2vdijxmUsiGo6rWjeTsbCrRqLbYfcXdEQAJ74di0m/7oj+HN6inF2Rfy2Jd6OgS88RDHn1TlbAQA/bTgY3GY2g6beqBCjOg0JkqKL4/u7z0ST7FT0fHKmYr+4yVhomTNnjgvNIIoOrTejhTm0gupnJLvYGneJQQVgPP04AIizD3ONEyL7jGoljO43DCxOfUTdMrg1DhSV4fTcTBSWeDX20wssDJsUFcxYUFzSG5KqFUQk2MhY5NVPR6ucdOw4Uuy0aTFhzZ4CXPhKVXdMOLWkfr+MtXsL0TE309JMp0Sx7qEvVmHt3kJ8cftAw+5P9dogahVOMhanAoNHLuwU3Kb1EaUXQNS4USFEse63h4Zh6vhBaNuwjub9WlG+uj/TzJ3DTnPUtmgzKiy7e8oKxc96i6dZ8Z/ZW3DRv+fjL5+udHwMolgyZUk+Vu8pwK9bDxvuZzZCRL9406jGQiurGrpNb82gWKixYGBBcaVp3TR0z6ure792V4i1d2LgoTHwvrXEqHdDPcmWMggJ/Q1nbziIGycvVhR8Bvz3VN/zNyv3OmonUSwRp+w2+/Zf4ZcNFxRUT/EdfJxOJqPynKHbtD6j9Gf1rP5PKAYWVKtod4VU/xvRiQc/X2V4v1HdhHpGQLMVU296ZwnmbDyEx6eutd5AohpIDAaSTCbP8/n9mnUUgSJv/XksjIs31bSyqrrHiIGPMwYWVKtofQjYDSxioAsTAPDJ0srJ5nYfK8amA0Uh91/zxkLM3XQIU3/fg51HlKNQylQzAlqt3TxQFJqxkMNaUo0otohBt1nNUIVP1sxKpCcnnLrfeY2FSOszSu8YRhmUaGHxJtUqWw+eCNlmuSvk1P/P7dwEudkbkZ2WhA37Qy/o0VTu9WPws7N17x/zv8XB2zueGRW8rQ4kvCZFaHqPI4o3pTrrfmjx+eWQbo1EjxQs+NQbFaKusUhPTkBxeeV5tQILrboLvfoOs7k1ooEZC6pVzjytYcg2K/PyA1VLnWekJGL+g8Pw6vW9XGyZM0WlFa4cR/yQMszIxMC3IaJIKimvCizM1gWp8Pnx/MyNim1pSQnB2gyrGYuMlKrv+FZrJPTqN2Jh6DgzFlSrDGqXg6njB+HIyTKMfWcpAGc1FgnCt5LqdPiEOyudWl3/IAY+s4giSlw4zOwivedYCeZtVo4cSU1OCIYGVos3M5ITEJhX02pXq17QYmctk0ip/k9GoiiSJAnd8+qiXnrVRFd2u0IC3JqFMxyHioyn7baqwnJXSPV/aBG5bfvhk1i/rxCAMmNhdpHW6nZITfIEuy6sFm+KGQur81DodbPEQsai+j8ZiaqBWJSlFVj0bV3f9BixkbGwHlgUl3sxd9MhzQ87q99yGFdQvJFlGUP/NQfnvzQPBSUVKKmw3hWitfx5WlJCcEIrvcev36eszQoUewLWB3XoZiwYWBBVD/FbgdWhXOo1RZJjYJZJO4HFXR+twJj/LcZz0zeE3CcWb972/jKs2VOgeQxmLCjeFJZWTZddUFyhKN40+/avNdFVqqLGQvvxi3ccVfycnizUWITZFRIL79Hq/2QkqgbimzdBY6x6amLoOhvqzIaVwKJvK/PMRzgO2QgsAosnvb9wZ8iHlzpj8cdTS6+rufGZVeHzI/9ozZ4SneLH8eKqOiWPRznctMLB6qWpSVU1FupaisZZKSH7A0CGsGCg1UXE9IIW1lgQVROzjMVTf+iC0xrVwYtXn1G1nyqw8FiozcipE9lFyw4X2S/e1BoFox5uKn6LE2nNWWE32Ljh7cU487nZmKtaBpqoOhwrrhpZ5fPLqhoL+10hYsaiTHV//QztwEL8IhNuxsJs/ZJoYGBBtZJ4bQ0EDLnZqQCAjk0y0bZhHcz889m4tEezkP3siHRW8lix/cDCI0kh7TJbpTHAje7bBduOAAA+WLgz/IMRhUl8D3n9MorLq4Jqs2//WqM+khM8weBAffHP0VkdWayLsPopE6iVqpeepHus6sLAgmolMd0YCBg+vrU/xgxoibfG9NZ8jJPAItL9nQUl9uex0GrRuA+WWXpsLPTfErlJXDfH65NxokzIWJh2hYTen5QgBTMW6rdLfZ3AQgxArHaFnNu5CQDg6/GDcMeQtsHtHBVCVE0aCX2dga6QVg0y8MQlXdC8XrrmY7QCi7n3D8EXtw9QVHWnJVXdtvoe795ce5l3M4UOAosTZaHdHMeLLR7Hxc8sxigUC8TXvtfvx4ky5c92JXgk3SGjddOTNBcZEwMLK8H7f/7YE+OHtgMAtMzJwAPndQzeFwsZC06QRbVSVmoSpt09GCmJHku1EoB2LUbLnAy0zMnQTV9e0as5Zq0/YHrs0xpnYuVu7ZEYRgpdmnnTKmYsKN6Iq4T6/DJOCPVFVrsIRYkeSbdOIsEjITstSVHXASiHv1spCh/VLdd2u6KJGQuqtTo3zUa7RpmW97faFSIWOJ7buTEeGXW66WOcXrALS7SLLCPF3S9DDFKo+onFjl6/jCIho+ekEDLB49HtzvBIEuqkhn6fv6JXc3xz5yB8e+dgpCaFjkiz4u5h7ZCbnYrbzm7j6PFuYsaCyCKjwEL8IBFjBEmS0LmpeTeH00RAiY0Fk9zAlUwp3ohZCa9Pxsmy8DIWCR5odncAldszhDkrhp/eCPec0x5dmmVZrq3Q8+eRHXDfiPZhH8cNDCyILLK7WFmAlUxHLBRcWeFmTwh7VSgWiO+9yhoL66NCtCR4PLo1Fh5JQlqyMiPR1WF9lZZYCCoAdoUQWWZUi6Eo8lJ9FlmZoLOm1C4Emvn+wp2Y+vueym0Oj/XThoO2lqgmigRxnRx1jYWTrhCjGgtJkhTBSpHOfDHaj7XdlGrDwILIIqOMhThbn7q7wMq3iBoSV8Avy1iw9Qge/XoN7pnyO+QwG/7x4l0utYzIGZ+qK0TMWJjNvKklwSMZ1FgAZcLqqXqrn2qJhUUPrao5LSWqZlZXHVTTGk2iVpO6Qr5btTf4c7jNVlfHE0WbV9EVIiu+JJjNvKkl0SMZ1FhIikUAxVk+zbw9pg/SkxPw3BXdbLcp2lhjQWRRosaaImq9WtbDyvzjim1WaixisStk7/ESTPhyNW4c1Cq4zS/L2H74ZPDncAMifw0JqCh+eRVdIX7V6qbOMhb6NRbKpdTLdJZV1zKoXQOsnniuo4n6oo0ZCyKLujevq3vfe2P74qz2DfHytT1Cag6sZDpi8fr69PfrMXfTIdw0eUlwm18GdgkLiNkNLNSBRCwGVJFQWFqBCV+uxsJT05lTdBw9WY4XZmzEriP6i96JNQ8VPuVaIVZf3+olAvSu/ZIkKYIJOxmLwLFrAgYWRCa+v/tMjB/aFg+e31F3n7PaN8R7Y/uiWd20kPusfBiY1Sp0ys0yb6jLpq3aF7JNlmXsPlYS/Fk9M+F/52zBQ1+s0ly9dPqa/eg68UfFNl8tCSxenLkZHy/ehWve0F41lqqUVvjw1YrdOFRkfeVePfd/thIv/7wFl736q+Z51uwpUA439ftR6hUzFtYyCuLcE4keCat0JrvzSBIeFGbJjPZw8WhhVwiRiU5Ns9CpqfULuzpI0BsVcl2/FvhwUWXxotkF9uELTsf8LYfx2tytltsRCUdOKhc9UxfNPzd9IwBgX0Ep3h3bV3Gf1nokel0hslxZRJeZmqR5f02zi8vEW/birM14be5WtMpJx5z7h4Z1rECG6PCJ0MX6bnl3KeZvOazYVlzuUxRSWy2uTEtKQPGp7EOCx6PbxeGRgCt7N8cDX6wCEL+BBTMWRC6z0hXSPa8unv5D1+DPZhlXSQIykp3NyBdJf/9unaLPOOC3rYc19g6162gx/vXjxpBvp498vQZdJ87A9W8twrq9ha601cy+ghJc9doCfL86NFPj1KYDRXj06zWOVqHVsnTHUTw9bZ3tFHpNMmPdfgDADoPuC6uMRmSpgwogdM0cqzUQYsbCaHi5RzViROu9Ew8YWBC5TJ180OoKUdeBmnWFSJLxPBpWRGJ9gS+W79bcXuGTcet7S02LM39cewD/nr0F933yu2J7IJMzf8thXPDyPMftyz9abDml/vjUtVi84yju+HC54/OpjXp5Ht5fuBPLdh5z5XhXvLYAb87bjlfnbHHleLEoyRP5y9Jb87Zpbv/njxsVP09btc9SXUxKUlWbEwzaH4gpcrNTAQBdm7k3OVYsYWBBFGFaGQt1sOHzy3jswk66x5CgX2luxY0DW2FwuwbKY0a4DmzmugNYvOOopX0XbT+C0gofPl68C5sOFLly/uPF5Tjzudno8/QsS/sfPelOVkHkZFSBFVsPnTTfqYZKSozsC7OotAJPTVtvef9r3lhoWmshLhxmNN9N4D085U/9MWZAS7x6fU/L7ahJGFgQRZhWxkKdovXLMsYObo3FfztH8xgeSX/9ASu8fr/i8f3b1McP95zp/IAWHdHo29aSlODBNyv3YsKXqzHy/34x3FeWZazbW2j6YW/34ltbRqjEukSDb/xen9/WEGWtt4yTabrnbjxkeL8Y9BsVawcCkJY5GXjiki5oXi/ddltqAgYWRBGm3RWiDiwq/98oM1XzGOpukL+ObK/4uU3DDMM2+Pyy4sPvjiHt0LFJ5EeaFJRYmwCruNyHBz5fZbjP3uMlOFnmxXsLduKCl+fhsalrDPcXn2IrwwZjccivnupYDE6WZTw3fQO+WKbd/eUWvWXDy7w+nP3PObj2zfBG1ngd/KFveW+p4f3ia009380FXZsEbyfXoNkzw1E7fkuiamSlK8S0xgJQTDXcv01O8HZGcoLuh3FAhU9WnNPqgmrh2n74BGauOxD2RFr5R4sx8JmfMfjZn/Gf2ZX1BR8vzjd8jPgbWhk2KP4NXvlps6N2WuHGpGDVkVxZvP0o/jtnK/7y2UoMfvZnHD4R/nBQLXoT0a3eXYA9x0uwaPtR61PJaxwqErPcilkQ9fv9ljOrljFnYEFErtC6hqtjDbMPO0mSFAsWiSskZqUlmdZf+PzKwCJaE+28OW87bn1vKSb/uj2s4yw4VUB3rLgCrRoYZ2cCxO6mFbuO49Ml+YYXJPFP8PzMTdhfUOqssSbEeRKcqo7AQhzZsvtYCV6P0NDnJJ0gWfz7WM06qF/lK/OP46NFOx22TF9xRdV7U2xZ0+xURXayJq33EQ7OY0EUYZpdIR7trhCRR6raLklAodCtIGYoMlMTYVZI75GUw9ysTE/ups+Whpc+TxcCqRb107F4e2VRaGmFTzHUT08gfd4wKwVDOzTS3EddY1FQUoEm2dpdU+EoKfchPbnmffSqgxm9i7vX50eilSV9dSTpvDbF4LvM69cNQIxc8p/QibK0JCd4bC0QJg7/FYPX1OQExXu9tgQWteO3JKpGWsNE1V0XWt+kxQ8kjyShsFQILBLFwMI8Y/GXke0V35yMhsRFwsYwR3qkCcGD2JXwwcKduP6tRZq1HFrP6ab9ynaUlPuCz6s6a1Rcbn1JazsCkyKFs2S8Xo3F4u1HMfadJYZTWDs/p+pnjSZ8vWIPOj/+I35af0D3OCXlPszecFD399cLGBSBhYPnzuosmkBlFtCOYkVgUbW9Y5NMxXszJTH25qKJBAYWRC4LDOtse6qgUmt100dGKYeWas28KWYYPBJQLvTjih++6ckJuoHFoHY5mPfAUDStm6aYuCdaNRZuuVUonhODiKemrdedkVSre+lkuQ/T1+wPXtR6PTUT3SbOQHG5N+RCGalJqEorfHhs6hp0fHQ61u7VnvrZjF5XyFWvL8DPGw7irikrwmihvXOK7v3kd5R5/bj5Xf1ixwe/WIWb3lmCR77WLr4Vsx1+RZbCJ9y2FiSI76F9x613bWWn2csoiYGFX5bx2bgBuKxnMzx5SRfFFwTWWBCRIy9f2wP3n9sBH97SH0Bot0dudipa5CiHmamnxgaUF38JEh4ZdToaZabg75d0VgQWyQke3aGoH97SH3n1K89ldUhcLBJjBK1ZLPcXlOLTpfnBoKPC51fUpAS8/NNmjPtgGf7x/XrIshy8IGw+cCKkK6RQ4/FuKPfKeG9BZT//Kz9FZqKrlfnHUVQam0vSf7NyLwDgc53RJWJXiBhAiBdvO6uCBuQfs57FybaZseieVzd42y8DfVrVxwtXnYGcOimKgJ6BBRE5Uj8jGeOHtgv2z1uZ2CpXoy9fzHRIEtC+cSYWPXwObhjQStGV4jFYplkk7lPTMhYirYmsvlqxBw98vgoPnVqD4cbJi3HTO0tC9guYsjhfEaxc8p9fQ2oGwr0we3VS72IAE8lJyrpOnOHqlNGRHOIqy3JwhlRx5k2xu0RcV6PMYgGs+PxaHfoM2Ass0pIS8J8/9gj+rO6C89TC4s3a8VsSVSOj7MBHt/TDyE6NFeuGBIi1GYHPpkBqV5ydsHLyrNBzfDZugG47alrGQmQ0Q+YPayrXmfh1i/k0zOqVWbcfVk6oFW7GolTnoi520TgNLKxe4iMxAiISXpy1GX2enoUpi3cptosjaMQgo6zCOGAqKffhro9XKNb+sBNk2QksHr2wk2KiK3XmS3xv1paMRc0rTSaqYYyu4QPbNcBA1VTbAeriTZEiYyFJIReo8UPbok+r+sp2KOaxqLkfcK50UUjmQ3zDzVgc1Zl11I2l4q0eQlzi3u1zWp5LwoKXTs0b8rev1+APPZoFt4vzQ9jpCnl/4Q58e6rLJSBSgYX6vad+WSlHhbB4M8Srr76Kbt26ISsrC1lZWRgwYAB++OGHSLWNKC5IkoTLeza3/TgxIFF/eKmDjtAJt0KPpxgVEuXhptFk9YJnNhdCON0Iczcdwln/nK15n6zoCons38HJLJN6ojF1hgRlwCcO+Swpt94VcvRkaFBoZ/hoeorz79zql5+HxZvGmjdvjmeeeQZLly7F0qVLMWzYMFxyySVYu3ZtpNpHFBeev6q77ccYZSwUFySdrhA1MfZwUmORmVr5YVs/I1nVFtuHiqjuT8ywtJ/ZDJhmGY0yrw9XvvYbnp2+IeQ+o+nGxeubBODOj5Zj/IfLbWYArO1rZ4il6RkttM+N2h3xeRczFla7Qsq8Ps1RQnYCRbOuFpH6Nw7tCqm6bTZDbryw9VtedNFFuOCCC9C+fXu0b98eTz/9NOrUqYOFC8Obu52IQiWohpvq8UhSyFwZWpcAj0aNxb+u7I666dbSvnP+OgSf3jYAyx8dgTOEKnj10NlwWG2LEStdJRLMv82b3f/z+oNYsuMYXp1j7yImXjiPFZfju1X7MG31PkU9gBnx2rW/oBSzNxzUvPC7G1iY7+PGN3Lx+RHbL44GMuoKmX6qzkbNznMRTjdYS/WIL+F5E5dXj2eO8z0+nw+fffYZTp48iQEDBujuV1ZWhrKyqjnlCwsLnZ6SqFZRBgtGSzEDaUnqCbeMjx34ZnlFr+a4vGcztJ7wvWl7cuqkIKdOCgBg5xHtlUMTPJLuN/3TGtXB5oMnDM9RNy3J1gU2HGYZCbP7xb+P3y8rfjYKLMRvtKXCN2OnmZ+z/jkb5V4/Xr0udAluJyt56lFfmLWOnJzoUdRCAFWZIa2J4vYXlCpmN5Uk/a6Q/YVV1xGjrhCtYcaAvYxFko0AKfB3++RP/bEi/zgu6JKruN8n/A2YsdCxevVq1KlTBykpKRg3bhy++uordOqk/41l0qRJyM7ODv7Ly8sLq8FEtYWyK0R/P48kIUM1RbTW0EAx2EhQjDixf0U7Jlz8G9Sp6hoxSpdb6be2O3+AU5JkJWOhfSFauO0IPly0U/Gcqy9m1gOLqguk08WxAueao7G095cr9uCBz1c6Oq6aun1af2r1cEqvz48LXp6HK19fEHxtiN0lt7ynHBIsQVL8XcTA6ICwdotWxiIwvFcvM2GnxuLuYadZ3lc6FfT3a5ODcWe3DQmgGmWlBG8zsNDRoUMH/P7771i4cCFuv/12jBkzBuvWrdPdf8KECSgoKAj+y883XpGQiCop57HQv/hLANJTlNXmnZtmh+wnXvTdHBVyQdeqb2hGl0YrY/ijNQxWgqT4JqlF7zp0zRsL8bev1mDl7uPBbX96XznTZJnBRUy8QDsNLLT21AuUPl26G8eFboQ1ewpw18crkH9Ue8Ko52dsxM3vLAlpT4WF9oldIX6/jC2HTmDD/iIs23kseGEX/8Zr9hRi/ubDimOIgVeFImNRFViUe/04cqIML/+0GXuPl+DJ79ah55Mzsed4iW5QZzWwyExJdHWNmNSkBKx8fCTWPnGuZtYmHtnuCklOTka7du0AAL1798aSJUvw0ksv4fXXX9fcPyUlBSkpKZr3EZG+Fjnp2HZqbgXDzyMJim/Pz1zWFRd1yw3ZTbws2L2A3zm0ne594iygRl0wVr6tRWJJay0lFT7sKzAeiunTyFiIS4WLQzkXbT+Kce8vw3+u64kEj2SYsRAzC+JIB/Uw1M0HilA3PRkNM0M/P7UyQ3oZlsr7qva/8JX5AConjHpvbN+QfV/5uXI20HmbD2GIsGCbz8KFWfwbl3p9im4tr09GSmJlxkJccP36txfptrVcyEKIE1yVeX147Ju1mLZqH75cvhs7Tq2N8of//IqDRdrLuVvtCkmxsKidXdHKxMWKsL+2yLKsqKEgovB8dEs/XHpGU8tFkR5JUiyjfk3fFpoZDvFaZKd6/7az2uAvI9tb3l+PXsZCbKqTqZqduvoN46Jz8QK3dm8Bxn+0HPM2VwUFBSXKeSqmr92PXzYfMh098c5vO4K3TwqBhZj233WkGCP+7xf0eXpWcJvZcY3qKbQCtv2nAiu9GUIrVMdTZ0QWbQ+dhEwMMk+W+RQr8gYebxTUlvv8+GVT1XMc+J3U3RtlFX4s3Fp5/h3Cgmt6QYXWMdSeurQL0pMT8Or1obUqhmpHEsIWWxmLhx9+GOeffz7y8vJQVFSEKVOmYM6cOZg+fXqk2kcUdzo0yTS8PzBplpi+NrqmeFQZCz1i3YU6JfvohZ3w5HfaXZqNs1JdmW8hp06y5vas1KTgt9FoBhZmxIvxZf/9DWVeP6at2hfctq8gdFGr48XlpgWqInEFVfF8C7eFXrTF6/qmAydw/VuLcN+IqloAKxkLMThpVjcNS3YcxQ1vL8bDo07H6P4tFY9R/8XVgcWmAyew6UAR2jeuej2Lv8PQf81BqwZVIyQCAYydpNT6fYXYduiEYtIsoPJ10jAzBUcMZmFV08pYXNy9aXDtkuv7t8S1fVvYzuYxrghlK7A4cOAARo8ejX379iE7OxvdunXD9OnTMWLEiEi1jyhuTLt7MD5atAv3Drf27d+sP7ZNgwxsO3wSF3Vvivyj5jMsGn2g3zy4NV6fuzX4je/vl3TGY1Mr56dxq3MiMcGD9OSEkFEDNwxoiY8X78Kwjo1C+turk3gh1Qp4DmgEFvd9Yq9QUswKiOcrKgsd2SAGDnuOl2DP8RLM31L1fBl1IwUu6uJxZ288hNmnumUe/XoNPl+aj14tq2ZrVceSWpmN9xfsxOETZXj0wk5oWjdN8TucKPNizZ6qUYDjPliG167vhfTkBJzQ+P20vDBzEwBgl6oepMzrQ8PMFGzYX2TpOABQYmFuipo81X0ssRVYvP3225FqB1Hc69w0W3NNED3ipFdal4xv7hqMXUeK0alpFmZvOGh6PLNUunhhumFAq2BgYURdN1E/I1l3LQ8JQIv66SEXg0ZZqVj08HAkeCT0fHKm6TmjJVDcuWaP9tLmezUCi3B8tjQfq/cU4M5h7XBS48JrkJAAENp1IQpc8I3qDFbuLsDK3VW/683vLsWwjo0wpEND/LFvC83i0PcXVq5FUlhagQ9v6W+YNVmy4xiG/HOOZtBk5sNFyjVEyrx+29Njq6f4BtyZXp1C1Y6xL0Q1kDgqRCsoqJOSiE5NswAAQzo0xI0DW+GZy/QDF7PuDL1RBUYBSWDCn49u6YdOuVn43419dPf1SJJmd0iSp2pK8rIKa6tWRkPgovPJkuiMZHv9l234besR/PHNRYpv9IHn3+wiOHdT6HDTgEDQaHfCrJ83HMRjU9fi06W7DWs4NuyrDBbN5s1wElRoKavwK0bUOGU0MqhNwwzFzwPa5ARv92xRN3g70tOy10QMLIhilPh5Zfa9SpIkTLy4M67p20J3nwFtctChcSYuOaOp5v0PntcRQGXXhMjoeta6QeWH78B2DfD9PWcqZuQMbaN2LYhY8BeLNRZbbNRMuEUMLAIBX3EYF+VgEaTX2Tf0KUt2ocIgG1Hm9eN4cblm3UkkHCwqtdydYsRoLpMPb+mnGM3xirA0ej8hyGBYEYqrmxLFKEVXiAsZ2+RED6bfe6buN6w/9muBs9o3QLO6aYrtzeulhez70a398NrcbXjyks622lBHY5IscZZDNxfNClegLVsOVUNgIUy41ePvM/Gns9oE6w2cCARJdiaJEq3aXYBVu7W7hIDKQKj/pJ8cHduJ2RqTgQU0zEzBIYPRIaK7hrXDrPUHcE2f0Ikbc7PTcOfQdnj6+/UAlO/HpFoy0ZVTDCyIYlQkCsnM0rbN61VV8b83ti9W7DqOczs3CdlvYNsGGNhWe7l3PR5JQoZGYJEsrLT6hx7N8NWKPbrH6NuqPhbvOGrrvE4F5rE4ZmPkgVu+EeoBTpR5wwoqAGDVnuP4dethDGybY76zQ6U2Fu6KpI9v7YfhL/xiad/ueXWx5olzkZFsXq8hvnPcWGwtnjGwIIpR4mdXdUywc1b7hjirfUNXj6meIRQA8upXBTNPXdoFG/YXYf0+7TWFHjivA1bsOo5th0/g48WRrX3w+mR4ff6YyqI49bevKldbvai7djdYPBGDYyu0smhaUoWJswa1axAM9lhiEYqBBVGMkiQJ743ti+Jyn+bsi7FKbyGyPq3qY5vQrfDBzf2w93iJYvrxjJREXN6zGZ6aFhpYzHtgKPLqp6N3q8ohkWaBRaJHqhxG+8s2S+2WJGWXk88vo1So+Uj0SDU+yFgapWxPdUpJ9GDKn/pj8q/b8ePaA4r7ruvXImSEiVVpyQl464beSPBI6NWyXnA7A4tQDCyIYpjbGYNoEAOL4ac3QnpyIoZ3aowLujbB/37dEdxv8GnaXSlimrlTbhbWncpe2FlyulFmCj4bNwCfLrWe1UiQJHiFyMIny4qRB9lpSbYmZIpFboykiISz2jdUzLgZDkmS0L9NDk5vkoUf185Q3FcnNRFtG2Zg66GTyEy1f/kb3qlx6PlYvhmCFShE5CoxMHhrTB+8fG0PXNy9KSRJQvfmoYujhTxeKIzrnle1v5V5C3689yzcf24H/PLAULTMybC12JpH9dXT568KLJITPYpUeCx68eozTPcpiWJg0aZBhvlOAHKzUzXXLAlXUmLoBb9OciL+d2MfXNajGT4fN9D0GP3b6NekDOvYCJmpiRh2eiPdfWorZiyIyFVGhW29W9XHf6/riRb19fvBk4RizsKSqtERWRa+YXZokqmYMl08lplbz2qN/8zeGvzZ65ODw19TEz1ItZExqQ71MrSnTBfZLbC8rGczfLlcv5hWz6w/n4XGWanoOnGG6b4DNApKh3VshJ8tTPpmRCuozEhJRMucDLxgIQgDgK7Ns/HNnYOQmx06MurtMb3h9cscIaKBzwgRucrsg/aCrrno0kw/cyFeEApLqxaxcjIRkVZbtIKNr+4YiHFnt1VsEzMWqUkJioXeYlF6BNo3dlBr033Uw5EnnN8R7RplIjPVuOD40Qs74dzOjfH4Rcohy12bZeN/N/ZRrA8i/s3Uw6H1aP2dsxwUQXdrXlezxkmSJAYVOvisEJGrwh0mmyhmLErDmwQpUeOD/5VrQ1ev7NGiXshFYu/xkuA3/NSkBKTanEI62tIi0FXTpVk2vrwjtMvgqt7NNfe/7aw2uE0I0Ob8dYjusa/o2Ryvj+4dMuIpMEqjUVbVxVzsppr/4FB0PjXjrBGtQLReeu1avry6MLAgIleF+y1OrLgvEpbdVrtxYCvTY4lfWgNdNL1b1dPcV30dKirzBteXSE3y2Kr+X/y3c6zv7JJ2jepY3jc1yYO3x/S2tK86Q3DHkLaYeHFVlkGc50MdVLbSqLP45s5B+PS2AchWXeSfu7wbWuak48lLK4/dKDM1eJ8YWEiShGcv74b6GckY1M7evBxWuosofAwsiMhViTbqGrQ0r5eOn/9yNpY/OsJwmO3jF3XCysdGas4MGiB+a/3lgaFY/PA5yNG5uCRoRA7v/LYDQGXGwmj1UFGTrFTFRVFL/VNt0Cpm7de6Pr67a7Clc4lSkxLw1KVdgj9Pu1v/GBU+GU0tdimImZrTc7PwwHkdkS5MzX5SWK3WSraqW/O66Nu6fsj2q/rkYe79Q9GuUWWNzIjTK0dg5GQkQ33YLs2yseyR4bhhQCtLv0NAvXQGFtHAwIKIXKVe8dSJNg3roH5GMp67ohuGdWyET/7UP2QfSZKQnZ5kOZNQLz0ZjbJSdWs11KNCRKmJCXhSuGgbOVke2n1z6RlNUVf4hr780RH49aFh+HTcgJB9WzfIMKxBMSJO9tS5aTa66YzC8fllzXVbtIjDfMVn6ObBlfUXdw9rF9zm5kRuLXLSMfuvQ/DTX87W/NtIkmT4N9PCrpDoYGBBRK564aozUDc9SfHt2amWORn43419FIs+qT19aeWKrvcNb294LLNMisfg23ZKksfyhbikPHRI54vX9Ai56Darm2Z76W89esHcCYMaFavFqCmJ2sd+8LyO+OL2gbjrnNMw8aJOOPO0BriuX0vNfZ1q3SADddOT8czl3QAAfxmh/Bu3bWg8pPWL2wfglsFVBahZJgWl5A4ONyUiV3Vtno0Vj46I2nLSZ7VviPV/P8/0Qqk3DPatG8xrDVISEzSnI09N8oQM4RyjU/thdSE59X5pSQmm808EulYCa4EEupCMJsTK0Ph9tIh/R/F4yYmeYD3MjYNa40YLI0icGtUtF2e2HxkSGLRpWAfvju2LrNREzN98GEM7KueU6NWyPs7Iq4f1+wuRVy/dMHgk9zCwICLXRSuoCLDy7VurTVf1bq45m6JaVmqioq4gQKy7uLZvHs7vkot+bULrBwDAbzGyUM/r0KxemunS7ac1rizcbJSVimWPDA8u9iYGJG/e0Bu3vrcUQOVQTCejXA4URmdZdC162YazT81O26OFdlFugkfCh7eEdqVR5LArhIjillvxTcPMFM3hnBW+qmAhOy0ZZ7VvGOzeUK+YaTVjcbFqobDeLZUXTHU7stOSgl0FAJBTJyU4S6gYWIzo1Bg/3nsWzjytAT69bYCjb+8nNbp5zIjFslbmxaCaj4EFEcUts4u51XUeGmammI546NJMObfCR7f2R/fm2ZqFp3puHNgqeMH/9s7BuH1IW0w4/3TFPi1zlLOWfnvnYN1Jo9TdNB2aZOL9m/vpfrvXEwh2RnXLtfU4APjyjoG4e1g7LHtkOB67qJPtx1PNw64QIqq1rGY0GtTRH/b69fhB+H3XMYzqqrzods+ri6l3Vg35lC2kLO4/t0Pwdtfm2eh6alTHGXl18Xv+cQBAm4YZ2LC/KLhfarLz74cvXNUdy3cdw5Ltx1A/IxkLth3R3O+Zy7tiWMdGITUMVrTMycCfR3Yw35HiBgMLIqq19AKLV67tgW9X7sWMdZXLbhsFFmfk1cUZeXVNz2WlJyQjRfsj+aNb+6HTYz+iXnoSmterylg0r5eGhgZtM3NZz+a4rGdz+P0yJAloPeF7zf3SkxNxqTDFNpERBhZEFLfMZ6PUjiyy05IUXQ71MsIfpqiXsOjbuj4Wbz+qWBtDLT05EasnjkRSgkexFPx7Y/u6UijL0RLkJtZYEFHcGtg2B5Mu66q53gUQmrF47MJOuLp3Hga3a6BYJj0wImH4qdkg/zyiPZISJPz3utB1R/TIOjmLN0b3wgtXdTed9yMzNQmpSQkY1TUXzeqmoV56EppkG8/w+eB5HYO/F1G0MGNBRHFLkiRc27eF/v2qn8cKkymJmYBAYPHG6F44Ue5FVmoSbh/S1ta6KHoZi7rpybisp/aiXlpy6qRgzv1DUO71aw6BFd0+pC0u79kMjbKMAxAiNzGwICLSUOGrGlFRJ7Xyo9LjkYJBht3F1iyONrUkKcFj+fwMKija2BVCRLVWqxz9KaErvFWBRbhLwQPWRoUQxQMGFkRU63x0Sz/86aw2utNvA0C5z697nxPnd6kcjnqajeXNo+1NC9ObE5lhVwgR1ToD2zXAwHYNDPcp97obWDx8weno1jzb0VwQ0TKiU2NLa5MQGWHGgohIQ9/W2mt+OJWWnIAre+cZzokRC0Z2rhz5EsuZFYptzFgQEWm49IxmSPBI6Glz+uua7qlLu6BXy3o4r3OT6m4K1VCSHOWKosLCQmRnZ6OgoABZWVnmDyAiIqJqZ/X6za4QIiIicg0DCyIiInINAwsiIiJyDQMLIiIicg0DCyIiInINAwsiIiJyDQMLIiIicg0DCyIiInINAwsiIiJyja3AYtKkSejTpw8yMzPRqFEjXHrppdi4cWOk2kZEREQ1jK3AYu7cuRg/fjwWLlyImTNnwuv1YuTIkTh58mSk2kdEREQ1SFhrhRw6dAiNGjXC3LlzcdZZZ1l6DNcKISIiqnmsXr/DWt20oKAAAFC/vv7ywmVlZSgrK1M0jIiIiOKT48BClmX8+c9/xuDBg9GlSxfd/SZNmoQnnngiZDsDDCIiopojcN026+hw3BUyfvx4TJs2DfPnz0fz5s1191NnLPbs2YNOnTo5OSURERFVs/z8fMPrvqPA4q677sLXX3+NX375Ba1bt7b1WL/fj7179yIzMxOSJNk9ta7CwkLk5eUhPz+ftRsm+FxZx+fKHj5f1vG5so7PlXWRfK5kWUZRURGaNm0Kj0d/7IetrhBZlnHXXXfhq6++wpw5c2wHFQDg8XgMI51wZWVl8YVnEZ8r6/hc2cPnyzo+V9bxubIuUs9Vdna26T62Aovx48fjo48+wtSpU5GZmYn9+/cHT5SWluaslURERBQ3bM1j8eqrr6KgoABDhgxBbm5u8N8nn3wSqfYRERFRDWK7KyRWpaSk4PHHH0dKSkp1NyXm8bmyjs+VPXy+rONzZR2fK+ti4bkKa4IsIiIiIhEXISMiIiLXMLAgIiIi1zCwICIiItcwsCAiIiLX1OjA4uKLL0aLFi2QmpqK3NxcjB49Gnv37jV8jCzLmDhxIpo2bYq0tDQMGTIEa9eujVKLq8eOHTtw8803o3Xr1khLS0Pbtm3x+OOPo7y83PBxN954IyRJUvzr379/lFpdPZw+V7XxdQUATz/9NAYOHIj09HTUrVvX0mNq4+sKcPZc1dbXFQAcO3YMo0ePRnZ2NrKzszF69GgcP37c8DG15bX13//+F61bt0Zqaip69eqFefPmGe4/d+5c9OrVC6mpqWjTpg1ee+21iLavRgcWQ4cOxaeffoqNGzfiiy++wNatW3HFFVcYPua5557DCy+8gH//+99YsmQJmjRpghEjRqCoqChKrY6+DRs2wO/34/XXX8fatWvxf//3f3jttdfw8MMPmz72vPPOw759+4L/vv/++yi0uPo4fa5q4+sKAMrLy3HllVfi9ttvt/W42va6Apw9V7X1dQUAf/zjH/H7779j+vTpmD59On7//XeMHj3a9HHx/tr65JNPcO+99+Jvf/sbVqxYgTPPPBPnn38+du3apbn/9u3bccEFF+DMM8/EihUr8PDDD+Puu+/GF198EblGynFk6tSpsiRJcnl5ueb9fr9fbtKkifzMM88Et5WWlsrZ2dnya6+9Fq1mxoTnnntObt26teE+Y8aMkS+55JLoNCiGmT1XfF3J8uTJk+Xs7GxL+9b215XV56o2v67WrVsnA5AXLlwY3LZgwQIZgLxhwwbdx9WG11bfvn3lcePGKbZ17NhRfuihhzT3f+CBB+SOHTsqtt12221y//79I9bGGp2xEB09ehQffvghBg4ciKSkJM19tm/fjv3792PkyJHBbSkpKTj77LPx22+/RaupMaGgoAD169c33W/OnDlo1KgR2rdvj1tvvRUHDx6MQutii9lzxdeVfXxdmavNr6sFCxYgOzsb/fr1C27r378/srOzTX/3eH5tlZeXY9myZYrXBACMHDlS93lZsGBByP7nnnsuli5dioqKioi0s8YHFg8++CAyMjKQk5ODXbt2YerUqbr7BtY2ady4sWJ748aNg/fVBlu3bsUrr7yCcePGGe53/vnn48MPP8TPP/+M559/HkuWLMGwYcNQVlYWpZZWPyvPFV9X9vB1ZU1tfl3t378fjRo1CtneqFEjw9893l9bhw8fhs/ns/Wa2L9/v+b+Xq8Xhw8fjkg7Yy6wmDhxYkjxjfrf0qVLg/vff//9WLFiBWbMmIGEhATccMMNplOPq5drl2XZ1SXco8XucwUAe/fuxXnnnYcrr7wSt9xyi+Hxr776aowaNQpdunTBRRddhB9++AGbNm3CtGnTIvlrRUSknyugdr+u7Kjtryu74uV1Bdh7vrR+R7PfPZ5eW0bsvia09tfa7hZba4VEw5133olrrrnGcJ9WrVoFbzdo0AANGjRA+/btcfrppyMvLw8LFy7EgAEDQh7XpEkTAJURXG5ubnD7wYMHQyK6msDuc7V3714MHToUAwYMwBtvvGH7fLm5uWjZsiU2b95s+7HVLZLPVW1/XYWrNr2u7Ii31xVg/flatWoVDhw4EHLfoUOHbP3uNfm1paVBgwZISEgIyU4YvSaaNGmiuX9iYiJycnIi0s6YCywCgYITgShML+3VunVrNGnSBDNnzkSPHj0AVPZZzZ07F88++6yzBlcjO8/Vnj17MHToUPTq1QuTJ0+Gx2M/WXXkyBHk5+crPuRqikg+V7X5deWG2vK6siveXleA9edrwIABKCgowOLFi9G3b18AwKJFi1BQUICBAwdaPl9Nfm1pSU5ORq9evTBz5kz84Q9/CG6fOXMmLrnkEs3HDBgwAN9++61i24wZM9C7d2/desSwRawsNMIWLVokv/LKK/KKFSvkHTt2yD///LM8ePBguW3btnJpaWlwvw4dOshffvll8OdnnnlGzs7Olr/88kt59erV8rXXXivn5ubKhYWF1fFrRMWePXvkdu3aycOGDZN3794t79u3L/hPJD5XRUVF8l/+8hf5t99+k7dv3y7Pnj1bHjBggNysWTM+VzJfVwE7d+6UV6xYIT/xxBNynTp15BUrVsgrVqyQi4qKgvvwdVXJ7nMly7X3dSXLsnzeeefJ3bp1kxcsWCAvWLBA7tq1q3zhhRcq9qmNr60pU6bISUlJ8ttvvy2vW7dOvvfee+WMjAx5x44dsizL8kMPPSSPHj06uP+2bdvk9PR0+b777pPXrVsnv/3223JSUpL8+eefR6yNNTawWLVqlTx06FC5fv36ckpKityqVSt53Lhx8u7duxX7AZAnT54c/Nnv98uPP/643KRJEzklJUU+66yz5NWrV0e59dE1efJkGYDmP5H4XBUXF8sjR46UGzZsKCclJcktWrSQx4wZI+/atasafoPocfJcyXLtfF3JcuXwPq3navbs2cF9+LqqZPe5kuXa+7qSZVk+cuSIfN1118mZmZlyZmamfN1118nHjh1T7FNbX1v/+c9/5JYtW8rJyclyz5495blz5wbvGzNmjHz22Wcr9p8zZ47co0cPOTk5WW7VqpX86quvRrR9XDadiIiIXBNzo0KIiIio5mJgQURERK5hYEFERESuYWBBRERErmFgQURERK5hYEFERESuYWBBRERErmFgQURERK5hYEFERESuYWBBRERErmFgQURERK5hYEFERESu+X/beqWYDk7tVQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# doesn't work unless stats stuff above is uncommented\n",
    "plt.plot(lri, lossi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817dfb4b",
   "metadata": {},
   "source": [
    "# Update for training, dev/validation, and test splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843a2a41",
   "metadata": {},
   "source": [
    "Training - say 80% - is to optimize the actual parameters of the model - the weights, etc. - as we've done above; dev/validation - 10% - is for tuning hyperparameters of the model - for ex, size of the hidden layer or size of embedding or amount of regularization; and test - 10% for the last number that we'd report.\n",
    "\n",
    "I updated the code up top where I created the X and Y datasets to do the split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c4093e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dims = 2\n",
    "hidden_neurons = 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "c0b6e120",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(karpathy_seed)\n",
    "C = torch.randn((27, embedding_dims), generator=g) # 27,2\n",
    "W1 = torch.randn((block_size*embedding_dims, hidden_neurons), generator=g) # 6, 100\n",
    "b1 = torch.randn(hidden_neurons, generator=g)\n",
    "W2 = torch.randn((hidden_neurons, 27), generator=g)\n",
    "b2 = torch.randn(27, generator=g)\n",
    "parameters = [C, W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "525ce948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3481"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many total parameters are we finding?\n",
    "sum(p.nelement() for p in parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "b84b5cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "4f92a9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5789387226104736\n"
     ]
    }
   ],
   "source": [
    "for i in range(10000):\n",
    "    \n",
    "    # if using minibatches/not training each iteration on the full 200K+ dataset\n",
    "    minibatch_size = 64\n",
    "    ix = torch.randint(0, Xtr.shape[0], (minibatch_size,))\n",
    "\n",
    "    # forward pass\n",
    "    emb = C[Xtr[ix]] # 32, 3, 2 # w/ minibatch\n",
    "    h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # 32, 100\n",
    "    logits = h @ W2 + b2 # 32, 27\n",
    "    loss = F.cross_entropy(logits, Ytr[ix]) # with minibatch\n",
    "    #print(loss.item())\n",
    "    \n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "    \n",
    "    # update\n",
    "    lr = 0.1\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "        \n",
    "print(loss.item()) # loss for just the last minibatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "ad5b7272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.3465025424957275"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[Xtr] \n",
    "print(emb.size())\n",
    "h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # 32, 100\n",
    "logits = h @ W2 + b2 # 32, 27\n",
    "loss_full_dataset = F.cross_entropy(logits, Ytr) \n",
    "loss_full_dataset.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "4aa1d949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([22655, 3, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.3444454669952393"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[Xdev] \n",
    "print(emb.size())\n",
    "h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # 32, 100\n",
    "logits = h @ W2 + b2 # 32, 27\n",
    "loss_full_dataset = F.cross_entropy(logits, Ydev) \n",
    "loss_full_dataset.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a32ff6a",
   "metadata": {},
   "source": [
    "Since the loss (on all of) the training and (all of the) test data is about the same, this means we're _not_ overfitting on the training data. When we don't overfit on the training data, that's typically because the model isn't powerful enough (to learn the training data) - it doesn't have enough parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2a383b",
   "metadata": {},
   "source": [
    "The last 15m of the video has him doing some additional optimization, including increasing the size of the hidden layer, increasing a bit the size of the minibatch (to avoid thrashing). He didn't see much improvement here, so he also talked about increasing the size of the embedding layer - figuring that it might be the bottleneck in the network because increasing the hidden layer from 100 to 300 didn't change much. As part of this he also wrote code that drew a visualization of the embedding - since we start w/ this at 2 floating point numbers, we can visualize them on a plane. The video shows how the network's learned to cluster vowels (since they can be used in similar spots in a word). It also learns to put a few characters away from all others, when they're odd - it does this w/ 'q' and the '.' special character. When he increased the embedding size to 10 and reduced the hidden layer down to I think 200 or so, he saw that the training loss started to tend lower than than test loss, supporting the idea that the embedding layer was holding back the scores. He finished up by adding a learning rate decay. He ended up w/ a best test loss of 2.17, and finished up in the last few mins w/ laying out all the different parts that could be further optimized to potentially improve on this number (including using more than three characters as input). And in the very last minute or two how to sample from the model to get new names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "27e9fecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ameyah.\n",
      "zabhen.\n",
      "hekanniyandya.\n",
      "anberier.\n",
      "hil.\n",
      "saz.\n",
      "chen.\n",
      "diolan.\n",
      "mar.\n",
      "havieieya.\n",
      "wasminledethominra.\n",
      "pax.\n",
      "tosolimiuh.\n",
      "riceeyo.\n",
      "ashoni.\n",
      "ansa.\n",
      "bunander.\n",
      "jaxalikr.\n",
      "bina.\n",
      "edbyo.\n",
      "jahgyszectaniiye.\n",
      "caidara.\n",
      "ail.\n",
      "maswaya.\n",
      "kamiyahvayahah.\n",
      "sinley.\n",
      "anialah.\n",
      "ella.\n",
      "dowiej.\n",
      "cadie.\n"
     ]
    }
   ],
   "source": [
    "# sample from the model\n",
    "g = torch.Generator().manual_seed(karpathy_seed + 15)\n",
    "\n",
    "for _ in range(30):\n",
    "    out = []\n",
    "    context = [0] * block_size # start with ...\n",
    "    while True:\n",
    "        emb = C[torch.tensor([context])] # (1,block_size,d)\n",
    "        h = torch.tanh(emb.view(1, -1) @ W1 + b1)\n",
    "        logits = h @ W2 + b2\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "        context = context[1:] + [ix]\n",
    "        out.append(ix)\n",
    "        if ix == 0:\n",
    "            break\n",
    "        \n",
    "    print(''.join(itos[i] for i in out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cc5b08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
