{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39383302",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99e2ffa",
   "metadata": {},
   "source": [
    "Goal: (like the first lecture/notebook) generate _more_ rows of text that are like the ones fed in first. Here, do this by picking a character that is likely, based on the three previous characters.\n",
    "\n",
    "\"We're maximizing the probability of the word, with respect to the parameters of the neural net. The parameters are the weights and biases of the output layer that does a softmax, the hidden layer, and the (character) embedding look up table layer called C.\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0f81a4",
   "metadata": {},
   "source": [
    "# Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffc6b2ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start w/ the words (names)\n",
    "words = open('names.txt', 'r').read().splitlines()\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cf35094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cb06ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
     ]
    }
   ],
   "source": [
    "# build the vocab of characters and mapping from/to integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "print(itos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a4fc89",
   "metadata": {},
   "source": [
    "# Build the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ba73712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma\n",
      "... --> e [0, 0, 0]\n",
      "..e --> m [0, 0, 5]\n",
      ".em --> m [0, 5, 13]\n",
      "emm --> a [5, 13, 13]\n",
      "mma --> . [13, 13, 1]\n",
      "olivia\n",
      "... --> o [0, 0, 0]\n",
      "..o --> l [0, 0, 15]\n",
      ".ol --> i [0, 15, 12]\n",
      "oli --> v [15, 12, 9]\n",
      "liv --> i [12, 9, 22]\n",
      "ivi --> a [9, 22, 9]\n",
      "via --> . [22, 9, 1]\n",
      "ava\n",
      "... --> a [0, 0, 0]\n",
      "..a --> v [0, 0, 1]\n",
      ".av --> a [0, 1, 22]\n",
      "ava --> . [1, 22, 1]\n",
      "isabella\n",
      "... --> i [0, 0, 0]\n",
      "..i --> s [0, 0, 9]\n",
      ".is --> a [0, 9, 19]\n",
      "isa --> b [9, 19, 1]\n",
      "sab --> e [19, 1, 2]\n",
      "abe --> l [1, 2, 5]\n",
      "bel --> l [2, 5, 12]\n",
      "ell --> a [5, 12, 12]\n",
      "lla --> . [12, 12, 1]\n",
      "sophia\n",
      "... --> s [0, 0, 0]\n",
      "..s --> o [0, 0, 19]\n",
      ".so --> p [0, 19, 15]\n",
      "sop --> h [19, 15, 16]\n",
      "oph --> i [15, 16, 8]\n",
      "phi --> a [16, 8, 9]\n",
      "hia --> . [8, 9, 1]\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "block_size = 3 # context length of how many chars to predict the next one\n",
    "X, Y = [], []\n",
    "\n",
    "for w in words[:5]:\n",
    "    print(w)\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "        ix = stoi[ch]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        print(''.join(itos[i] for i in context), '-->', itos[ix], context)\n",
    "        context = context[1:] + [ix] # crop first char and append current label\n",
    "        \n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b420f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3]), torch.int64, torch.Size([32]), torch.int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X.dtype, Y.shape, Y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d6a14565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897dead9",
   "metadata": {},
   "source": [
    "The X dataset is a row per each combination of three characters - including three '.' chars that indicate the start (or end) of the word - in each word in the input, with the actual data in the row an array of integers. The Y dataset is the integer of the _next_ character after the three. So, with the single input row 'emma', we generate five dataset rows, starting with '...'->'e' and ending with 'mma'->'.'. When we work w/ just the first five words, we get 32 rows/combinations of three characters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69948f9",
   "metadata": {},
   "source": [
    "# Build the embedding layer C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "681b0003",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dims = 2\n",
    "\n",
    "C = torch.randn(27, embedding_dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd2afcb",
   "metadata": {},
   "source": [
    "One way to think about the embedding layer is to think of indexing into an array that maps character indexes into two-dimensional floats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4795e421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.0411,  0.3832])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7975510",
   "metadata": {},
   "source": [
    "Another way to think of the embedding layer is that it's just another layer in the neural net, but one with no bias weights and without a non-linearity (like tanh). Conceptually here we one-hot encode the character we want to provide as input and then matmul that one-hot encoded input with the C layer. The one-hot encoded input has all zeros except for a one in the spot that matches the index we care about - 5 in this example - and so we 'pull out' only the values from C in that row. Ultimately we get the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e6d277c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.0411,  0.3832])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.one_hot(torch.tensor(5), num_classes=27).float() @ C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed274c6",
   "metadata": {},
   "source": [
    "Indexing is faster, so we'll do that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf62117a",
   "metadata": {},
   "source": [
    "We want to embed not just a single character, but instead the three chars we have as input. PyTorch indexing is powerful and accepts a lot of different things, including lists, and even multi-dimensional arrays/tensors. X is our input data - it's a tensor with many rows -when we test w/ just five words of input, 32 rows - and each row having three numbers, one for each character. We want a mapping between ALL of these rows and characters to the floating point numbers that represent/embed each character. Ultimately, with 32 rows and three characters each, we want an output that's 32 rows by 3 characters by 2 floats. PyTorch indexing is powerful, so to get this, all we have to do is index into C with the full X array (which again has a shape of 32, 3). PyTorch will pick out the appropriate 2D embedding values and return a tensor of shape 32, 3, 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "26832068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[X] # this embeds ALL of the dataset's characters in C\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7a0b9d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.9123, -0.8199],\n",
       "         [ 0.9123, -0.8199],\n",
       "         [ 0.9123, -0.8199]],\n",
       "\n",
       "        [[ 0.9123, -0.8199],\n",
       "         [ 0.9123, -0.8199],\n",
       "         [-1.0411,  0.3832]],\n",
       "\n",
       "        [[ 0.9123, -0.8199],\n",
       "         [-1.0411,  0.3832],\n",
       "         [-0.7880, -0.3084]]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b3e2591f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[2, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2faa1218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.0411,  0.3832])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb[2, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0677aa",
   "metadata": {},
   "source": [
    "# Building the hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4e024391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many floating point inputs to the hidden layer?\n",
    "# for three char inputs with two floats per char, it's 6\n",
    "input_chars = block_size * embedding_dims\n",
    "input_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9cc96626",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_neurons = 100\n",
    "\n",
    "W1 = torch.randn((input_chars, hidden_neurons)) # 6, 100\n",
    "b1 = torch.randn(hidden_neurons) # 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e11216",
   "metadata": {},
   "source": [
    "We want to do emb @ W1 + b. We can't, right now, because embd is 32, 3, 2 while W1 is 6, 100. We want to combine the 3, 2 part into a single dimension of size 6, so we'll have 32x6, which we can then matmul with 6x100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8678f883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one inefficient way is via cat\n",
    "emb[:, 0, :].shape # single 32 by 2 embeddings for the first char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "15646e03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all three chars then are as follows, which gives us 32,6 as we want\n",
    "torch.cat([emb[:, 0, :], emb[:, 1, :], emb[:, 2, :]], 1).shape # concat on dim 1, not zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4ec07dbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the above doesn't generalize because it hardcodes block size of three\n",
    "# i could use 'unbind' to 'remove a tensor dimension'\n",
    "# unbind gives a list of tensors like the hard-codet just above\n",
    "torch.cat(torch.unbind(emb, 1), 1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fa7bb2",
   "metadata": {},
   "source": [
    "But, both of the above are using new memory. Instead, we can use 'view' to just change the metadata on the underlying data - each tensor has underlying storage that's just a 1D set of data - and get a diff view without having to do anything with new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "19748376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(18)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cd1d79b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1],\n",
       "        [ 2,  3],\n",
       "        [ 4,  5],\n",
       "        [ 6,  7],\n",
       "        [ 8,  9],\n",
       "        [10, 11],\n",
       "        [12, 13],\n",
       "        [14, 15],\n",
       "        [16, 17]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.view(9, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b8b74d2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1],\n",
       "         [ 2,  3],\n",
       "         [ 4,  5]],\n",
       "\n",
       "        [[ 6,  7],\n",
       "         [ 8,  9],\n",
       "         [10, 11]],\n",
       "\n",
       "        [[12, 13],\n",
       "         [14, 15],\n",
       "         [16, 17]]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.view(3, 3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "20f5226a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7405d6c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9123, -0.8199,  0.9123, -0.8199,  0.9123, -0.8199],\n",
       "        [ 0.9123, -0.8199,  0.9123, -0.8199, -1.0411,  0.3832],\n",
       "        [ 0.9123, -0.8199, -1.0411,  0.3832, -0.7880, -0.3084],\n",
       "        [-1.0411,  0.3832, -0.7880, -0.3084, -0.7880, -0.3084],\n",
       "        [-0.7880, -0.3084, -0.7880, -0.3084, -1.9219,  0.5264],\n",
       "        [ 0.9123, -0.8199,  0.9123, -0.8199,  0.9123, -0.8199],\n",
       "        [ 0.9123, -0.8199,  0.9123, -0.8199, -0.5661, -0.2186],\n",
       "        [ 0.9123, -0.8199, -0.5661, -0.2186, -0.6146,  1.3284],\n",
       "        [-0.5661, -0.2186, -0.6146,  1.3284, -0.5162, -0.2247],\n",
       "        [-0.6146,  1.3284, -0.5162, -0.2247, -0.4924,  0.8374],\n",
       "        [-0.5162, -0.2247, -0.4924,  0.8374, -0.5162, -0.2247],\n",
       "        [-0.4924,  0.8374, -0.5162, -0.2247, -1.9219,  0.5264],\n",
       "        [ 0.9123, -0.8199,  0.9123, -0.8199,  0.9123, -0.8199],\n",
       "        [ 0.9123, -0.8199,  0.9123, -0.8199, -1.9219,  0.5264],\n",
       "        [ 0.9123, -0.8199, -1.9219,  0.5264, -0.4924,  0.8374],\n",
       "        [-1.9219,  0.5264, -0.4924,  0.8374, -1.9219,  0.5264],\n",
       "        [ 0.9123, -0.8199,  0.9123, -0.8199,  0.9123, -0.8199],\n",
       "        [ 0.9123, -0.8199,  0.9123, -0.8199, -0.5162, -0.2247],\n",
       "        [ 0.9123, -0.8199, -0.5162, -0.2247,  0.3945,  0.2065],\n",
       "        [-0.5162, -0.2247,  0.3945,  0.2065, -1.9219,  0.5264],\n",
       "        [ 0.3945,  0.2065, -1.9219,  0.5264, -0.6751,  1.1986],\n",
       "        [-1.9219,  0.5264, -0.6751,  1.1986, -1.0411,  0.3832],\n",
       "        [-0.6751,  1.1986, -1.0411,  0.3832, -0.6146,  1.3284],\n",
       "        [-1.0411,  0.3832, -0.6146,  1.3284, -0.6146,  1.3284],\n",
       "        [-0.6146,  1.3284, -0.6146,  1.3284, -1.9219,  0.5264],\n",
       "        [ 0.9123, -0.8199,  0.9123, -0.8199,  0.9123, -0.8199],\n",
       "        [ 0.9123, -0.8199,  0.9123, -0.8199,  0.3945,  0.2065],\n",
       "        [ 0.9123, -0.8199,  0.3945,  0.2065, -0.5661, -0.2186],\n",
       "        [ 0.3945,  0.2065, -0.5661, -0.2186, -1.3049,  1.2063],\n",
       "        [-0.5661, -0.2186, -1.3049,  1.2063,  0.1194, -1.4669],\n",
       "        [-1.3049,  1.2063,  0.1194, -1.4669, -0.5162, -0.2247],\n",
       "        [ 0.1194, -1.4669, -0.5162, -0.2247, -1.9219,  0.5264]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.view(32, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7e8f1a2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view and unbind give the same result\n",
    "emb.view(32, 6) == torch.cat(torch.unbind(emb, 1), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8309dc",
   "metadata": {},
   "source": [
    "The above does rely on the fact that 'view', when asked for a 32x6 from our 32x3x2, combines each of the 3x2 into a single 6. (Or rather, that the underlying data for the 3x2 is a 1D sequence of six values.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5faa8802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0488, -1.6588, -3.3078,  ..., -1.4160,  0.2018, -2.7426],\n",
       "        [ 1.5453,  1.8850, -4.2101,  ..., -5.3272,  1.9020, -0.6278],\n",
       "        [-0.5530,  2.6476, -4.3544,  ..., -0.2253,  0.6588, -1.0174],\n",
       "        ...,\n",
       "        [-2.1331,  1.0629, -3.1943,  ...,  1.9976, -1.9862, -2.4230],\n",
       "        [ 0.7523,  2.3426,  1.6436,  ...,  0.4643, -0.9482, -0.9842],\n",
       "        [ 0.6252,  5.3815, -4.5769,  ..., -4.7524,  0.1618, -1.8924]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ultimately, we can do our matmul to get the hidden layer vals\n",
    "h = emb.view(32, 6) @ W1 + b1\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0a42e00f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1a3718d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = emb.view(-1, 6) @ W1 + b1 # -1 is same as len(emb), -1 sets the dim to fit the underlying data\n",
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "36e13a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "18571068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0488, -0.9301, -0.9973,  ..., -0.8888,  0.1991, -0.9917],\n",
       "        [ 0.9130,  0.9549, -0.9996,  ..., -1.0000,  0.9564, -0.5565],\n",
       "        [-0.5028,  0.9900, -0.9997,  ..., -0.2215,  0.5776, -0.7688],\n",
       "        ...,\n",
       "        [-0.9723,  0.7868, -0.9966,  ...,  0.9639, -0.9630, -0.9844],\n",
       "        [ 0.6365,  0.9817,  0.9280,  ...,  0.4335, -0.7390, -0.7549],\n",
       "        [ 0.5547,  1.0000, -0.9998,  ..., -0.9999,  0.1604, -0.9556]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = torch.tanh(emb.view(-1, input_chars) @ W1 + b1)\n",
    "h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b207495",
   "metadata": {},
   "source": [
    "Also, he talked about confirming that b1 is broadcast to each row of the result of the matmul. So, I think it's that we have 32 input rows of six values each, and our W1 tensor is 6x100. \n",
    "\n",
    "First, I want to remember that we have 100 hidden neurons, each of which is connected to six input neurons. For each of the 100 hidden neurons we have six weights, one for each of the inputs. This is what makes W1 6,100. We also have a single 100 length bias vector - each value applies to one hidden neuron and is the same/doesn't change or depend upon the number of connected input neurons. Ultimately, the calc for the hidden layer is, per hidden layer neuron, a set of six (normal) multiplications each of the floating point input value multiplied by the specific weight for the combination of that neuron AND that input value, the sum of which is then added to the single bias value for that neuron.    \n",
    "\n",
    "The matmul is 32,6 @ 6,100 -> 32,100. We know the matmul takes the six values in the first row and multiplies them by the six values in the first column, and then adds the result and stores it as the value of the first row and column of the ultimate 32,100 tensor. It multiplies the same six input values from the first row by the six values in each of the remaining 99 columns to fill out the 100 columns in the first of 32 rows. Then, finally, it does the same for the remaining 31 rows in the input tensor, generating 100 values each time, to get the fill out the full 32 rows of the 32,100 result. Here, we're doing 32*100 calcs -> 3200 total calcs. Our bias vector is just 100 values. We want it to be broadcast to each of the calcs we do for each of the 32 input rows. PyTorch will do this, because we start with 32,100 and are adding a 100. PyTorch lines up the 100 w/ the right-most dimension, I think, and then fills in the missing dim with '1', making a 1,100 tensor, which adds to each row the 32,100 matmul result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4bb9b8c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 100])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c44af7",
   "metadata": {},
   "source": [
    "# Building the final output softmax/probability layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7305093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final layer is 100,27 - 100 input neurons from the hidden layer\n",
    "# mapping to 27 output neurons, one for each character\n",
    "W2 = torch.randn((hidden_neurons, 27)) # 100, 27\n",
    "b2 = torch.randn(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c37806aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and since we have a 32,100 input, matmul with 100,27 -> 32,27\n",
    "logits = h @ W2 + b2\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c83a70a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logits are log counts, so first exponentiate to get 'fake counts'\n",
    "counts = logits.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "94c07d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# then normalize to get probabilities\n",
    "prob = counts / counts.sum(1, keepdims=True)\n",
    "prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d27ac26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob[17].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "16c8d342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13,  1,  0, 15, 12,  9, 22,  9,  1,  0,  1, 22,  1,  0,  9, 19,\n",
       "         1,  2,  5, 12, 12,  1,  0, 19, 15, 16,  8,  9,  1,  0])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# actual error, based on ground truth Y (next char in seq)\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9a9e21",
   "metadata": {},
   "source": [
    "Ultimately, we want to index into the probabilities (one for each of the 27 chars) our model generated and pull out the specific probability for the ground truth/actual character we want the model to choose. We want this probability to be as high as possible, since high probabilities mean the model is more likely to pick the correct character. (Note that for many - all? - chars it's impossible to get a probability of 1 because in the actual data it's likely not always the case that, for even a single character, that the next character is always the same.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b000e22d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.9640e-12, 2.4226e-03, 9.4587e-03, 1.9986e-12, 7.8846e-06, 4.0592e-12,\n",
       "        3.2841e-06, 1.0013e-13, 7.7810e-05, 8.3004e-03, 7.2752e-09, 2.5784e-07,\n",
       "        9.9989e-01, 2.3777e-14, 1.1788e-06, 6.0504e-05, 1.5758e-19, 1.1390e-14,\n",
       "        9.9686e-01, 3.8572e-09, 2.4290e-05, 2.9828e-03, 5.4854e-02, 3.5183e-09,\n",
       "        5.0137e-09, 6.2990e-12, 6.9787e-08, 1.9089e-05, 2.5970e-08, 1.2333e-10,\n",
       "        1.8736e-15, 4.0650e-05])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first param - range of 32 - indexes into prob once for each of the rows in prob\n",
    "# second param - Y - is a matching length (we have one ground truth for each input)\n",
    "# and the value in Y is the index into the 27 probabilities\n",
    "# ultimately this gives us the probability for the correct next char for each input row\n",
    "prob[torch.arange(32), Y]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ee8f70",
   "metadata": {},
   "source": [
    "Many of the probabilities are horrible - likely close to zero. But we haven't trained the model yet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579b2747",
   "metadata": {},
   "source": [
    "Finally, we want to get a single score from all of the input rows and ground truth values we've tried. Our single score is negative of the average of the log probability of each of the values. This creates the negative log likelihood loss.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "473f227b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(16.8043)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = -prob[torch.arange(32), Y].log().mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2f1fac",
   "metadata": {},
   "source": [
    "# Cleaned up and pulled together first cut at a model that minimizes the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6e259b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "karpathy_seed = 2147483647"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "011a0b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dims = 2\n",
    "hidden_neurons = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4cae0459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3]), torch.Size([32]))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(block_size) # don't set here because it affects the X, Y data\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1e161038",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(karpathy_seed)\n",
    "C = torch.randn((27, embedding_dims), generator=g) # 27,2\n",
    "W1 = torch.randn((block_size*embedding_dims, hidden_neurons), generator=g) # 6, 100\n",
    "b1 = torch.randn(hidden_neurons, generator=g)\n",
    "W2 = torch.randn((hidden_neurons, 27), generator=g)\n",
    "b2 = torch.randn(27, generator=g)\n",
    "parameters = [C, W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c0e722fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3481"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many total parameters are we finding?\n",
    "sum(p.nelement() for p in parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e722c887",
   "metadata": {},
   "source": [
    "The cross_entropy fuinction used below replaces the manual calc of probabilities and the calc of the loss function - it just needs logits (log counts) and the ground truth. Besides being canned and so easier to read/search for/understand/without roll-your-own bugs, it's more efficient - doesn't create new tensors, uses 'fused kernels', and simpler/direct 'clustered' backward pass math. It also is also better behaved numerically because it avoids very large logits by shifting down, avoiding floating point inf values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cf221f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "00a7e689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25440800189971924"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for _ in range(1000):\n",
    "    # forward pass\n",
    "    emb = C[X] # 32, 3, 2\n",
    "    h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # 32, 100\n",
    "    logits = h @ W2 + b2 # 32, 27\n",
    "    loss = F.cross_entropy(logits, Y) \n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "    # update\n",
    "    for p in parameters:\n",
    "        p.data += -0.1 * p.grad\n",
    "        \n",
    "loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a24d8d9",
   "metadata": {},
   "source": [
    "This is a very low loss, but it's because our input data when we start is only 32 rows and we have ~3500 params, so we crazy overfit. (We can't overfit to a loss of zero because in some cases - like with the first ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7b8e21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
