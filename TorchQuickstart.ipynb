{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd018cd0-773b-4f47-b7e2-0458928c7937",
   "metadata": {},
   "source": [
    "# Quickstart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537a96cb-f91f-4172-b346-cf883ffc7a73",
   "metadata": {},
   "source": [
    "With code from https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a345c48e-953d-448a-b748-89d1c45fdc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import sys\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0b97c4f-b8fa-441e-8bee-2845a0e6b753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.11.11 (main, Mar 11 2025, 17:28:32) [Clang 20.1.0 ]\n",
      "2.7.0.dev20250218+cu128\n"
     ]
    }
   ],
   "source": [
    "print(sys.version)\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d36d0a7e-01ac-4177-b307-45186f504b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root='data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19f250fc-87d2-4416-8487-1c075f970295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f'Shape of X [N, C, H, W]: {X.shape}')\n",
    "    print(f'Shape of y: {y.shape} {y.dtype}')\n",
    "    break # exit after first batch - all batches are the same size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3cb420-0ca4-4615-af9f-e9532d38e1ee",
   "metadata": {},
   "source": [
    "Cool... looks like this new current_accelerator.is_available call returns true for both CUDA and MPS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e5dba2d-092d-4ea2-aebc-872aa8a5d093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73f1f8c2-4598-4c55-8c03-7c658d258752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = 'cpu' # to run with CPU uncomment and then run the code below (could be reorganize so only the stuff that has to run after the device change, like the model creation, is after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d18d654-7d71-432f-9a41-c874a92c3f30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56d61d31-74b4-4a1d-be73-a207d39794ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78b6eac9-e685-41cd-af66-8d4d9995bd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # backprop\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f'loss: {loss:>7f} [{current:>5d}/{size:>5d}]')\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f'Test error: \\n Accuracy: {(100 * correct):>0.1f}%, avg loss: {test_loss:>8f} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d6c1b6d-9689-4e3e-be61-2dd3218913e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "------------------\n",
      "loss: 2.323086 [   64/60000]\n",
      "loss: 2.294036 [ 6464/60000]\n",
      "loss: 2.285366 [12864/60000]\n",
      "loss: 2.268813 [19264/60000]\n",
      "loss: 2.243323 [25664/60000]\n",
      "loss: 2.244003 [32064/60000]\n",
      "loss: 2.236463 [38464/60000]\n",
      "loss: 2.215095 [44864/60000]\n",
      "loss: 2.207709 [51264/60000]\n",
      "loss: 2.175890 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 43.7%, avg loss: 2.172597 \n",
      "\n",
      "Epoch 2\n",
      "------------------\n",
      "loss: 2.188961 [   64/60000]\n",
      "loss: 2.165818 [ 6464/60000]\n",
      "loss: 2.122739 [12864/60000]\n",
      "loss: 2.129645 [19264/60000]\n",
      "loss: 2.074983 [25664/60000]\n",
      "loss: 2.035289 [32064/60000]\n",
      "loss: 2.052623 [38464/60000]\n",
      "loss: 1.982457 [44864/60000]\n",
      "loss: 1.986841 [51264/60000]\n",
      "loss: 1.912437 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 55.6%, avg loss: 1.914276 \n",
      "\n",
      "Epoch 3\n",
      "------------------\n",
      "loss: 1.947489 [   64/60000]\n",
      "loss: 1.908700 [ 6464/60000]\n",
      "loss: 1.806847 [12864/60000]\n",
      "loss: 1.841117 [19264/60000]\n",
      "loss: 1.733965 [25664/60000]\n",
      "loss: 1.688758 [32064/60000]\n",
      "loss: 1.705179 [38464/60000]\n",
      "loss: 1.608982 [44864/60000]\n",
      "loss: 1.635209 [51264/60000]\n",
      "loss: 1.526876 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 61.5%, avg loss: 1.550502 \n",
      "\n",
      "Epoch 4\n",
      "------------------\n",
      "loss: 1.614553 [   64/60000]\n",
      "loss: 1.575891 [ 6464/60000]\n",
      "loss: 1.435630 [12864/60000]\n",
      "loss: 1.497994 [19264/60000]\n",
      "loss: 1.389216 [25664/60000]\n",
      "loss: 1.384199 [32064/60000]\n",
      "loss: 1.386260 [38464/60000]\n",
      "loss: 1.315162 [44864/60000]\n",
      "loss: 1.352346 [51264/60000]\n",
      "loss: 1.250993 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 62.1%, avg loss: 1.280968 \n",
      "\n",
      "Epoch 5\n",
      "------------------\n",
      "loss: 1.358885 [   64/60000]\n",
      "loss: 1.338910 [ 6464/60000]\n",
      "loss: 1.177044 [12864/60000]\n",
      "loss: 1.271366 [19264/60000]\n",
      "loss: 1.157966 [25664/60000]\n",
      "loss: 1.183663 [32064/60000]\n",
      "loss: 1.189380 [38464/60000]\n",
      "loss: 1.131542 [44864/60000]\n",
      "loss: 1.174993 [51264/60000]\n",
      "loss: 1.092184 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 63.5%, avg loss: 1.113632 \n",
      "\n",
      "Epoch 6\n",
      "------------------\n",
      "loss: 1.186703 [   64/60000]\n",
      "loss: 1.189713 [ 6464/60000]\n",
      "loss: 1.007244 [12864/60000]\n",
      "loss: 1.131447 [19264/60000]\n",
      "loss: 1.013888 [25664/60000]\n",
      "loss: 1.047720 [32064/60000]\n",
      "loss: 1.068311 [38464/60000]\n",
      "loss: 1.013607 [44864/60000]\n",
      "loss: 1.058072 [51264/60000]\n",
      "loss: 0.993576 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 64.9%, avg loss: 1.005441 \n",
      "\n",
      "Epoch 7\n",
      "------------------\n",
      "loss: 1.065887 [   64/60000]\n",
      "loss: 1.093763 [ 6464/60000]\n",
      "loss: 0.890974 [12864/60000]\n",
      "loss: 1.037946 [19264/60000]\n",
      "loss: 0.922279 [25664/60000]\n",
      "loss: 0.950839 [32064/60000]\n",
      "loss: 0.989065 [38464/60000]\n",
      "loss: 0.935793 [44864/60000]\n",
      "loss: 0.975132 [51264/60000]\n",
      "loss: 0.927388 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 66.3%, avg loss: 0.930948 \n",
      "\n",
      "Epoch 8\n",
      "------------------\n",
      "loss: 0.976126 [   64/60000]\n",
      "loss: 1.027001 [ 6464/60000]\n",
      "loss: 0.807638 [12864/60000]\n",
      "loss: 0.970581 [19264/60000]\n",
      "loss: 0.860549 [25664/60000]\n",
      "loss: 0.878588 [32064/60000]\n",
      "loss: 0.933155 [38464/60000]\n",
      "loss: 0.882676 [44864/60000]\n",
      "loss: 0.913806 [51264/60000]\n",
      "loss: 0.879037 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 67.4%, avg loss: 0.876303 \n",
      "\n",
      "Epoch 9\n",
      "------------------\n",
      "loss: 0.906190 [   64/60000]\n",
      "loss: 0.976320 [ 6464/60000]\n",
      "loss: 0.744448 [12864/60000]\n",
      "loss: 0.918781 [19264/60000]\n",
      "loss: 0.816010 [25664/60000]\n",
      "loss: 0.822977 [32064/60000]\n",
      "loss: 0.890313 [38464/60000]\n",
      "loss: 0.844603 [44864/60000]\n",
      "loss: 0.866769 [51264/60000]\n",
      "loss: 0.841082 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 68.9%, avg loss: 0.834144 \n",
      "\n",
      "Epoch 10\n",
      "------------------\n",
      "loss: 0.850030 [   64/60000]\n",
      "loss: 0.935031 [ 6464/60000]\n",
      "loss: 0.694715 [12864/60000]\n",
      "loss: 0.877558 [19264/60000]\n",
      "loss: 0.781610 [25664/60000]\n",
      "loss: 0.779600 [32064/60000]\n",
      "loss: 0.855351 [38464/60000]\n",
      "loss: 0.816119 [44864/60000]\n",
      "loss: 0.829681 [51264/60000]\n",
      "loss: 0.809875 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 70.3%, avg loss: 0.800270 \n",
      "\n",
      "Epoch 11\n",
      "------------------\n",
      "loss: 0.803484 [   64/60000]\n",
      "loss: 0.899568 [ 6464/60000]\n",
      "loss: 0.654256 [12864/60000]\n",
      "loss: 0.844168 [19264/60000]\n",
      "loss: 0.753760 [25664/60000]\n",
      "loss: 0.745164 [32064/60000]\n",
      "loss: 0.825044 [38464/60000]\n",
      "loss: 0.793628 [44864/60000]\n",
      "loss: 0.799798 [51264/60000]\n",
      "loss: 0.783281 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 71.6%, avg loss: 0.772067 \n",
      "\n",
      "Epoch 12\n",
      "------------------\n",
      "loss: 0.763769 [   64/60000]\n",
      "loss: 0.868091 [ 6464/60000]\n",
      "loss: 0.620506 [12864/60000]\n",
      "loss: 0.816691 [19264/60000]\n",
      "loss: 0.730340 [25664/60000]\n",
      "loss: 0.717308 [32064/60000]\n",
      "loss: 0.798196 [38464/60000]\n",
      "loss: 0.774899 [44864/60000]\n",
      "loss: 0.774940 [51264/60000]\n",
      "loss: 0.759980 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 72.8%, avg loss: 0.747860 \n",
      "\n",
      "Epoch 13\n",
      "------------------\n",
      "loss: 0.729139 [   64/60000]\n",
      "loss: 0.839593 [ 6464/60000]\n",
      "loss: 0.591692 [12864/60000]\n",
      "loss: 0.793566 [19264/60000]\n",
      "loss: 0.710266 [25664/60000]\n",
      "loss: 0.694525 [32064/60000]\n",
      "loss: 0.773982 [38464/60000]\n",
      "loss: 0.758551 [44864/60000]\n",
      "loss: 0.753748 [51264/60000]\n",
      "loss: 0.739185 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 74.0%, avg loss: 0.726552 \n",
      "\n",
      "Epoch 14\n",
      "------------------\n",
      "loss: 0.698477 [   64/60000]\n",
      "loss: 0.813424 [ 6464/60000]\n",
      "loss: 0.566629 [12864/60000]\n",
      "loss: 0.773833 [19264/60000]\n",
      "loss: 0.692506 [25664/60000]\n",
      "loss: 0.675433 [32064/60000]\n",
      "loss: 0.751777 [38464/60000]\n",
      "loss: 0.743907 [44864/60000]\n",
      "loss: 0.735287 [51264/60000]\n",
      "loss: 0.720243 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 74.9%, avg loss: 0.707465 \n",
      "\n",
      "Epoch 15\n",
      "------------------\n",
      "loss: 0.671259 [   64/60000]\n",
      "loss: 0.789109 [ 6464/60000]\n",
      "loss: 0.544673 [12864/60000]\n",
      "loss: 0.756664 [19264/60000]\n",
      "loss: 0.676829 [25664/60000]\n",
      "loss: 0.659254 [32064/60000]\n",
      "loss: 0.731050 [38464/60000]\n",
      "loss: 0.730698 [44864/60000]\n",
      "loss: 0.719074 [51264/60000]\n",
      "loss: 0.702939 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 75.7%, avg loss: 0.690161 \n",
      "\n",
      "Epoch 16\n",
      "------------------\n",
      "loss: 0.646808 [   64/60000]\n",
      "loss: 0.766614 [ 6464/60000]\n",
      "loss: 0.525390 [12864/60000]\n",
      "loss: 0.741347 [19264/60000]\n",
      "loss: 0.662976 [25664/60000]\n",
      "loss: 0.645466 [32064/60000]\n",
      "loss: 0.711644 [38464/60000]\n",
      "loss: 0.718663 [44864/60000]\n",
      "loss: 0.704765 [51264/60000]\n",
      "loss: 0.686981 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 76.4%, avg loss: 0.674350 \n",
      "\n",
      "Epoch 17\n",
      "------------------\n",
      "loss: 0.624728 [   64/60000]\n",
      "loss: 0.745798 [ 6464/60000]\n",
      "loss: 0.508269 [12864/60000]\n",
      "loss: 0.727372 [19264/60000]\n",
      "loss: 0.650669 [25664/60000]\n",
      "loss: 0.633634 [32064/60000]\n",
      "loss: 0.693499 [38464/60000]\n",
      "loss: 0.707669 [44864/60000]\n",
      "loss: 0.692112 [51264/60000]\n",
      "loss: 0.672105 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 77.1%, avg loss: 0.659866 \n",
      "\n",
      "Epoch 18\n",
      "------------------\n",
      "loss: 0.604752 [   64/60000]\n",
      "loss: 0.726755 [ 6464/60000]\n",
      "loss: 0.492964 [12864/60000]\n",
      "loss: 0.714501 [19264/60000]\n",
      "loss: 0.639777 [25664/60000]\n",
      "loss: 0.623484 [32064/60000]\n",
      "loss: 0.676501 [38464/60000]\n",
      "loss: 0.697760 [44864/60000]\n",
      "loss: 0.681073 [51264/60000]\n",
      "loss: 0.658283 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 77.7%, avg loss: 0.646567 \n",
      "\n",
      "Epoch 19\n",
      "------------------\n",
      "loss: 0.586657 [   64/60000]\n",
      "loss: 0.709257 [ 6464/60000]\n",
      "loss: 0.479125 [12864/60000]\n",
      "loss: 0.702492 [19264/60000]\n",
      "loss: 0.629943 [25664/60000]\n",
      "loss: 0.614649 [32064/60000]\n",
      "loss: 0.660727 [38464/60000]\n",
      "loss: 0.688976 [44864/60000]\n",
      "loss: 0.671449 [51264/60000]\n",
      "loss: 0.645297 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 78.2%, avg loss: 0.634349 \n",
      "\n",
      "Epoch 20\n",
      "------------------\n",
      "loss: 0.570199 [   64/60000]\n",
      "loss: 0.693235 [ 6464/60000]\n",
      "loss: 0.466604 [12864/60000]\n",
      "loss: 0.691312 [19264/60000]\n",
      "loss: 0.620945 [25664/60000]\n",
      "loss: 0.606824 [32064/60000]\n",
      "loss: 0.646037 [38464/60000]\n",
      "loss: 0.681289 [44864/60000]\n",
      "loss: 0.663029 [51264/60000]\n",
      "loss: 0.633052 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 78.6%, avg loss: 0.623113 \n",
      "\n",
      "Epoch 21\n",
      "------------------\n",
      "loss: 0.555277 [   64/60000]\n",
      "loss: 0.678507 [ 6464/60000]\n",
      "loss: 0.455180 [12864/60000]\n",
      "loss: 0.680783 [19264/60000]\n",
      "loss: 0.612645 [25664/60000]\n",
      "loss: 0.599748 [32064/60000]\n",
      "loss: 0.632275 [38464/60000]\n",
      "loss: 0.674598 [44864/60000]\n",
      "loss: 0.655756 [51264/60000]\n",
      "loss: 0.621526 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 78.9%, avg loss: 0.612775 \n",
      "\n",
      "Epoch 22\n",
      "------------------\n",
      "loss: 0.541553 [   64/60000]\n",
      "loss: 0.664920 [ 6464/60000]\n",
      "loss: 0.444788 [12864/60000]\n",
      "loss: 0.670812 [19264/60000]\n",
      "loss: 0.605145 [25664/60000]\n",
      "loss: 0.593326 [32064/60000]\n",
      "loss: 0.619464 [38464/60000]\n",
      "loss: 0.669028 [44864/60000]\n",
      "loss: 0.649490 [51264/60000]\n",
      "loss: 0.610641 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 79.2%, avg loss: 0.603271 \n",
      "\n",
      "Epoch 23\n",
      "------------------\n",
      "loss: 0.528808 [   64/60000]\n",
      "loss: 0.652366 [ 6464/60000]\n",
      "loss: 0.435370 [12864/60000]\n",
      "loss: 0.661413 [19264/60000]\n",
      "loss: 0.598189 [25664/60000]\n",
      "loss: 0.587517 [32064/60000]\n",
      "loss: 0.607699 [38464/60000]\n",
      "loss: 0.664496 [44864/60000]\n",
      "loss: 0.644123 [51264/60000]\n",
      "loss: 0.600264 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 79.5%, avg loss: 0.594535 \n",
      "\n",
      "Epoch 24\n",
      "------------------\n",
      "loss: 0.517017 [   64/60000]\n",
      "loss: 0.640782 [ 6464/60000]\n",
      "loss: 0.426761 [12864/60000]\n",
      "loss: 0.652546 [19264/60000]\n",
      "loss: 0.591691 [25664/60000]\n",
      "loss: 0.582075 [32064/60000]\n",
      "loss: 0.596796 [38464/60000]\n",
      "loss: 0.660923 [44864/60000]\n",
      "loss: 0.639531 [51264/60000]\n",
      "loss: 0.590248 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 79.8%, avg loss: 0.586479 \n",
      "\n",
      "Epoch 25\n",
      "------------------\n",
      "loss: 0.506092 [   64/60000]\n",
      "loss: 0.630123 [ 6464/60000]\n",
      "loss: 0.418812 [12864/60000]\n",
      "loss: 0.644129 [19264/60000]\n",
      "loss: 0.585442 [25664/60000]\n",
      "loss: 0.576913 [32064/60000]\n",
      "loss: 0.586704 [38464/60000]\n",
      "loss: 0.658172 [44864/60000]\n",
      "loss: 0.635555 [51264/60000]\n",
      "loss: 0.580586 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 80.0%, avg loss: 0.579033 \n",
      "\n",
      "Epoch 26\n",
      "------------------\n",
      "loss: 0.495885 [   64/60000]\n",
      "loss: 0.620278 [ 6464/60000]\n",
      "loss: 0.411434 [12864/60000]\n",
      "loss: 0.636114 [19264/60000]\n",
      "loss: 0.579389 [25664/60000]\n",
      "loss: 0.571971 [32064/60000]\n",
      "loss: 0.577326 [38464/60000]\n",
      "loss: 0.656121 [44864/60000]\n",
      "loss: 0.632014 [51264/60000]\n",
      "loss: 0.571299 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 80.1%, avg loss: 0.572137 \n",
      "\n",
      "Epoch 27\n",
      "------------------\n",
      "loss: 0.486328 [   64/60000]\n",
      "loss: 0.611144 [ 6464/60000]\n",
      "loss: 0.404568 [12864/60000]\n",
      "loss: 0.628433 [19264/60000]\n",
      "loss: 0.573465 [25664/60000]\n",
      "loss: 0.567120 [32064/60000]\n",
      "loss: 0.568675 [38464/60000]\n",
      "loss: 0.654672 [44864/60000]\n",
      "loss: 0.628823 [51264/60000]\n",
      "loss: 0.562377 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 80.3%, avg loss: 0.565742 \n",
      "\n",
      "Epoch 28\n",
      "------------------\n",
      "loss: 0.477393 [   64/60000]\n",
      "loss: 0.602658 [ 6464/60000]\n",
      "loss: 0.398186 [12864/60000]\n",
      "loss: 0.621104 [19264/60000]\n",
      "loss: 0.567603 [25664/60000]\n",
      "loss: 0.562334 [32064/60000]\n",
      "loss: 0.560670 [38464/60000]\n",
      "loss: 0.653766 [44864/60000]\n",
      "loss: 0.626002 [51264/60000]\n",
      "loss: 0.553694 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 80.5%, avg loss: 0.559796 \n",
      "\n",
      "Epoch 29\n",
      "------------------\n",
      "loss: 0.468985 [   64/60000]\n",
      "loss: 0.594813 [ 6464/60000]\n",
      "loss: 0.392256 [12864/60000]\n",
      "loss: 0.614123 [19264/60000]\n",
      "loss: 0.561790 [25664/60000]\n",
      "loss: 0.557608 [32064/60000]\n",
      "loss: 0.553217 [38464/60000]\n",
      "loss: 0.653313 [44864/60000]\n",
      "loss: 0.623405 [51264/60000]\n",
      "loss: 0.545291 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 80.6%, avg loss: 0.554252 \n",
      "\n",
      "Epoch 30\n",
      "------------------\n",
      "loss: 0.461039 [   64/60000]\n",
      "loss: 0.587523 [ 6464/60000]\n",
      "loss: 0.386754 [12864/60000]\n",
      "loss: 0.607488 [19264/60000]\n",
      "loss: 0.556049 [25664/60000]\n",
      "loss: 0.552873 [32064/60000]\n",
      "loss: 0.546254 [38464/60000]\n",
      "loss: 0.653253 [44864/60000]\n",
      "loss: 0.621048 [51264/60000]\n",
      "loss: 0.537132 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 80.8%, avg loss: 0.549082 \n",
      "\n",
      "Epoch 31\n",
      "------------------\n",
      "loss: 0.453494 [   64/60000]\n",
      "loss: 0.580745 [ 6464/60000]\n",
      "loss: 0.381631 [12864/60000]\n",
      "loss: 0.601159 [19264/60000]\n",
      "loss: 0.550378 [25664/60000]\n",
      "loss: 0.548173 [32064/60000]\n",
      "loss: 0.539730 [38464/60000]\n",
      "loss: 0.653449 [44864/60000]\n",
      "loss: 0.618855 [51264/60000]\n",
      "loss: 0.529266 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 81.0%, avg loss: 0.544249 \n",
      "\n",
      "Epoch 32\n",
      "------------------\n",
      "loss: 0.446337 [   64/60000]\n",
      "loss: 0.574469 [ 6464/60000]\n",
      "loss: 0.376868 [12864/60000]\n",
      "loss: 0.595054 [19264/60000]\n",
      "loss: 0.544769 [25664/60000]\n",
      "loss: 0.543514 [32064/60000]\n",
      "loss: 0.533667 [38464/60000]\n",
      "loss: 0.653827 [44864/60000]\n",
      "loss: 0.616772 [51264/60000]\n",
      "loss: 0.521671 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 81.0%, avg loss: 0.539723 \n",
      "\n",
      "Epoch 33\n",
      "------------------\n",
      "loss: 0.439546 [   64/60000]\n",
      "loss: 0.568642 [ 6464/60000]\n",
      "loss: 0.372392 [12864/60000]\n",
      "loss: 0.589248 [19264/60000]\n",
      "loss: 0.539289 [25664/60000]\n",
      "loss: 0.538882 [32064/60000]\n",
      "loss: 0.527998 [38464/60000]\n",
      "loss: 0.654289 [44864/60000]\n",
      "loss: 0.614761 [51264/60000]\n",
      "loss: 0.514431 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 81.1%, avg loss: 0.535482 \n",
      "\n",
      "Epoch 34\n",
      "------------------\n",
      "loss: 0.433103 [   64/60000]\n",
      "loss: 0.563251 [ 6464/60000]\n",
      "loss: 0.368156 [12864/60000]\n",
      "loss: 0.583730 [19264/60000]\n",
      "loss: 0.533964 [25664/60000]\n",
      "loss: 0.534315 [32064/60000]\n",
      "loss: 0.522628 [38464/60000]\n",
      "loss: 0.654854 [44864/60000]\n",
      "loss: 0.612819 [51264/60000]\n",
      "loss: 0.507513 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 81.2%, avg loss: 0.531497 \n",
      "\n",
      "Epoch 35\n",
      "------------------\n",
      "loss: 0.426961 [   64/60000]\n",
      "loss: 0.558189 [ 6464/60000]\n",
      "loss: 0.364207 [12864/60000]\n",
      "loss: 0.578459 [19264/60000]\n",
      "loss: 0.528718 [25664/60000]\n",
      "loss: 0.529837 [32064/60000]\n",
      "loss: 0.517559 [38464/60000]\n",
      "loss: 0.655409 [44864/60000]\n",
      "loss: 0.610962 [51264/60000]\n",
      "loss: 0.500862 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 81.5%, avg loss: 0.527747 \n",
      "\n",
      "Epoch 36\n",
      "------------------\n",
      "loss: 0.421115 [   64/60000]\n",
      "loss: 0.553458 [ 6464/60000]\n",
      "loss: 0.360494 [12864/60000]\n",
      "loss: 0.573422 [19264/60000]\n",
      "loss: 0.523620 [25664/60000]\n",
      "loss: 0.525378 [32064/60000]\n",
      "loss: 0.512715 [38464/60000]\n",
      "loss: 0.655917 [44864/60000]\n",
      "loss: 0.609072 [51264/60000]\n",
      "loss: 0.494461 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 81.6%, avg loss: 0.524209 \n",
      "\n",
      "Epoch 37\n",
      "------------------\n",
      "loss: 0.415375 [   64/60000]\n",
      "loss: 0.548991 [ 6464/60000]\n",
      "loss: 0.356960 [12864/60000]\n",
      "loss: 0.568628 [19264/60000]\n",
      "loss: 0.518639 [25664/60000]\n",
      "loss: 0.521096 [32064/60000]\n",
      "loss: 0.508140 [38464/60000]\n",
      "loss: 0.656265 [44864/60000]\n",
      "loss: 0.607220 [51264/60000]\n",
      "loss: 0.488357 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 81.6%, avg loss: 0.520866 \n",
      "\n",
      "Epoch 38\n",
      "------------------\n",
      "loss: 0.409898 [   64/60000]\n",
      "loss: 0.544838 [ 6464/60000]\n",
      "loss: 0.353597 [12864/60000]\n",
      "loss: 0.564012 [19264/60000]\n",
      "loss: 0.513811 [25664/60000]\n",
      "loss: 0.516955 [32064/60000]\n",
      "loss: 0.503800 [38464/60000]\n",
      "loss: 0.656482 [44864/60000]\n",
      "loss: 0.605352 [51264/60000]\n",
      "loss: 0.482527 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 81.7%, avg loss: 0.517709 \n",
      "\n",
      "Epoch 39\n",
      "------------------\n",
      "loss: 0.404685 [   64/60000]\n",
      "loss: 0.540918 [ 6464/60000]\n",
      "loss: 0.350468 [12864/60000]\n",
      "loss: 0.559531 [19264/60000]\n",
      "loss: 0.509221 [25664/60000]\n",
      "loss: 0.512949 [32064/60000]\n",
      "loss: 0.499694 [38464/60000]\n",
      "loss: 0.656618 [44864/60000]\n",
      "loss: 0.603489 [51264/60000]\n",
      "loss: 0.476922 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 81.8%, avg loss: 0.514721 \n",
      "\n",
      "Epoch 40\n",
      "------------------\n",
      "loss: 0.399636 [   64/60000]\n",
      "loss: 0.537192 [ 6464/60000]\n",
      "loss: 0.347554 [12864/60000]\n",
      "loss: 0.555223 [19264/60000]\n",
      "loss: 0.504738 [25664/60000]\n",
      "loss: 0.509086 [32064/60000]\n",
      "loss: 0.495811 [38464/60000]\n",
      "loss: 0.656577 [44864/60000]\n",
      "loss: 0.601661 [51264/60000]\n",
      "loss: 0.471606 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 81.8%, avg loss: 0.511883 \n",
      "\n",
      "Epoch 41\n",
      "------------------\n",
      "loss: 0.394785 [   64/60000]\n",
      "loss: 0.533662 [ 6464/60000]\n",
      "loss: 0.344777 [12864/60000]\n",
      "loss: 0.551043 [19264/60000]\n",
      "loss: 0.500351 [25664/60000]\n",
      "loss: 0.505279 [32064/60000]\n",
      "loss: 0.492097 [38464/60000]\n",
      "loss: 0.656448 [44864/60000]\n",
      "loss: 0.599813 [51264/60000]\n",
      "loss: 0.466572 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 81.9%, avg loss: 0.509186 \n",
      "\n",
      "Epoch 42\n",
      "------------------\n",
      "loss: 0.390137 [   64/60000]\n",
      "loss: 0.530314 [ 6464/60000]\n",
      "loss: 0.342119 [12864/60000]\n",
      "loss: 0.547053 [19264/60000]\n",
      "loss: 0.496109 [25664/60000]\n",
      "loss: 0.501567 [32064/60000]\n",
      "loss: 0.488524 [38464/60000]\n",
      "loss: 0.656250 [44864/60000]\n",
      "loss: 0.598025 [51264/60000]\n",
      "loss: 0.461866 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 82.0%, avg loss: 0.506617 \n",
      "\n",
      "Epoch 43\n",
      "------------------\n",
      "loss: 0.385674 [   64/60000]\n",
      "loss: 0.527150 [ 6464/60000]\n",
      "loss: 0.339568 [12864/60000]\n",
      "loss: 0.543244 [19264/60000]\n",
      "loss: 0.492002 [25664/60000]\n",
      "loss: 0.498026 [32064/60000]\n",
      "loss: 0.485152 [38464/60000]\n",
      "loss: 0.655997 [44864/60000]\n",
      "loss: 0.596311 [51264/60000]\n",
      "loss: 0.457399 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 82.1%, avg loss: 0.504163 \n",
      "\n",
      "Epoch 44\n",
      "------------------\n",
      "loss: 0.381364 [   64/60000]\n",
      "loss: 0.524124 [ 6464/60000]\n",
      "loss: 0.337067 [12864/60000]\n",
      "loss: 0.539604 [19264/60000]\n",
      "loss: 0.487995 [25664/60000]\n",
      "loss: 0.494667 [32064/60000]\n",
      "loss: 0.481969 [38464/60000]\n",
      "loss: 0.655612 [44864/60000]\n",
      "loss: 0.594581 [51264/60000]\n",
      "loss: 0.453129 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 82.2%, avg loss: 0.501815 \n",
      "\n",
      "Epoch 45\n",
      "------------------\n",
      "loss: 0.377166 [   64/60000]\n",
      "loss: 0.521200 [ 6464/60000]\n",
      "loss: 0.334644 [12864/60000]\n",
      "loss: 0.536081 [19264/60000]\n",
      "loss: 0.484124 [25664/60000]\n",
      "loss: 0.491418 [32064/60000]\n",
      "loss: 0.478870 [38464/60000]\n",
      "loss: 0.655078 [44864/60000]\n",
      "loss: 0.592866 [51264/60000]\n",
      "loss: 0.449112 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 82.3%, avg loss: 0.499568 \n",
      "\n",
      "Epoch 46\n",
      "------------------\n",
      "loss: 0.373101 [   64/60000]\n",
      "loss: 0.518415 [ 6464/60000]\n",
      "loss: 0.332316 [12864/60000]\n",
      "loss: 0.532694 [19264/60000]\n",
      "loss: 0.480359 [25664/60000]\n",
      "loss: 0.488267 [32064/60000]\n",
      "loss: 0.475937 [38464/60000]\n",
      "loss: 0.654445 [44864/60000]\n",
      "loss: 0.591189 [51264/60000]\n",
      "loss: 0.445354 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 82.5%, avg loss: 0.497409 \n",
      "\n",
      "Epoch 47\n",
      "------------------\n",
      "loss: 0.369180 [   64/60000]\n",
      "loss: 0.515754 [ 6464/60000]\n",
      "loss: 0.330084 [12864/60000]\n",
      "loss: 0.529468 [19264/60000]\n",
      "loss: 0.476725 [25664/60000]\n",
      "loss: 0.485198 [32064/60000]\n",
      "loss: 0.473132 [38464/60000]\n",
      "loss: 0.653669 [44864/60000]\n",
      "loss: 0.589527 [51264/60000]\n",
      "loss: 0.441808 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 82.5%, avg loss: 0.495329 \n",
      "\n",
      "Epoch 48\n",
      "------------------\n",
      "loss: 0.365423 [   64/60000]\n",
      "loss: 0.513170 [ 6464/60000]\n",
      "loss: 0.327908 [12864/60000]\n",
      "loss: 0.526393 [19264/60000]\n",
      "loss: 0.473224 [25664/60000]\n",
      "loss: 0.482182 [32064/60000]\n",
      "loss: 0.470503 [38464/60000]\n",
      "loss: 0.652820 [44864/60000]\n",
      "loss: 0.587874 [51264/60000]\n",
      "loss: 0.438466 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 82.5%, avg loss: 0.493326 \n",
      "\n",
      "Epoch 49\n",
      "------------------\n",
      "loss: 0.361752 [   64/60000]\n",
      "loss: 0.510673 [ 6464/60000]\n",
      "loss: 0.325775 [12864/60000]\n",
      "loss: 0.523418 [19264/60000]\n",
      "loss: 0.469832 [25664/60000]\n",
      "loss: 0.479312 [32064/60000]\n",
      "loss: 0.467963 [38464/60000]\n",
      "loss: 0.651813 [44864/60000]\n",
      "loss: 0.586214 [51264/60000]\n",
      "loss: 0.435322 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 82.6%, avg loss: 0.491387 \n",
      "\n",
      "Epoch 50\n",
      "------------------\n",
      "loss: 0.358146 [   64/60000]\n",
      "loss: 0.508252 [ 6464/60000]\n",
      "loss: 0.323712 [12864/60000]\n",
      "loss: 0.520567 [19264/60000]\n",
      "loss: 0.466460 [25664/60000]\n",
      "loss: 0.476573 [32064/60000]\n",
      "loss: 0.465514 [38464/60000]\n",
      "loss: 0.650739 [44864/60000]\n",
      "loss: 0.584637 [51264/60000]\n",
      "loss: 0.432375 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 82.6%, avg loss: 0.489511 \n",
      "\n",
      "Epoch 51\n",
      "------------------\n",
      "loss: 0.354612 [   64/60000]\n",
      "loss: 0.505936 [ 6464/60000]\n",
      "loss: 0.321745 [12864/60000]\n",
      "loss: 0.517821 [19264/60000]\n",
      "loss: 0.463129 [25664/60000]\n",
      "loss: 0.473960 [32064/60000]\n",
      "loss: 0.463133 [38464/60000]\n",
      "loss: 0.649531 [44864/60000]\n",
      "loss: 0.583037 [51264/60000]\n",
      "loss: 0.429626 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 82.7%, avg loss: 0.487693 \n",
      "\n",
      "Epoch 52\n",
      "------------------\n",
      "loss: 0.351250 [   64/60000]\n",
      "loss: 0.503693 [ 6464/60000]\n",
      "loss: 0.319807 [12864/60000]\n",
      "loss: 0.515207 [19264/60000]\n",
      "loss: 0.459920 [25664/60000]\n",
      "loss: 0.471499 [32064/60000]\n",
      "loss: 0.460813 [38464/60000]\n",
      "loss: 0.648329 [44864/60000]\n",
      "loss: 0.581492 [51264/60000]\n",
      "loss: 0.427060 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 82.7%, avg loss: 0.485936 \n",
      "\n",
      "Epoch 53\n",
      "------------------\n",
      "loss: 0.347949 [   64/60000]\n",
      "loss: 0.501512 [ 6464/60000]\n",
      "loss: 0.317881 [12864/60000]\n",
      "loss: 0.512681 [19264/60000]\n",
      "loss: 0.456814 [25664/60000]\n",
      "loss: 0.469145 [32064/60000]\n",
      "loss: 0.458559 [38464/60000]\n",
      "loss: 0.647099 [44864/60000]\n",
      "loss: 0.579881 [51264/60000]\n",
      "loss: 0.424644 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 82.7%, avg loss: 0.484234 \n",
      "\n",
      "Epoch 54\n",
      "------------------\n",
      "loss: 0.344808 [   64/60000]\n",
      "loss: 0.499369 [ 6464/60000]\n",
      "loss: 0.316023 [12864/60000]\n",
      "loss: 0.510252 [19264/60000]\n",
      "loss: 0.453784 [25664/60000]\n",
      "loss: 0.466868 [32064/60000]\n",
      "loss: 0.456419 [38464/60000]\n",
      "loss: 0.645754 [44864/60000]\n",
      "loss: 0.578258 [51264/60000]\n",
      "loss: 0.422367 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 82.8%, avg loss: 0.482588 \n",
      "\n",
      "Epoch 55\n",
      "------------------\n",
      "loss: 0.341737 [   64/60000]\n",
      "loss: 0.497310 [ 6464/60000]\n",
      "loss: 0.314211 [12864/60000]\n",
      "loss: 0.507982 [19264/60000]\n",
      "loss: 0.450805 [25664/60000]\n",
      "loss: 0.464643 [32064/60000]\n",
      "loss: 0.454349 [38464/60000]\n",
      "loss: 0.644426 [44864/60000]\n",
      "loss: 0.576709 [51264/60000]\n",
      "loss: 0.420161 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 82.8%, avg loss: 0.480994 \n",
      "\n",
      "Epoch 56\n",
      "------------------\n",
      "loss: 0.338722 [   64/60000]\n",
      "loss: 0.495297 [ 6464/60000]\n",
      "loss: 0.312492 [12864/60000]\n",
      "loss: 0.505839 [19264/60000]\n",
      "loss: 0.447880 [25664/60000]\n",
      "loss: 0.462480 [32064/60000]\n",
      "loss: 0.452326 [38464/60000]\n",
      "loss: 0.643050 [44864/60000]\n",
      "loss: 0.575144 [51264/60000]\n",
      "loss: 0.418149 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 82.9%, avg loss: 0.479444 \n",
      "\n",
      "Epoch 57\n",
      "------------------\n",
      "loss: 0.335792 [   64/60000]\n",
      "loss: 0.493303 [ 6464/60000]\n",
      "loss: 0.310816 [12864/60000]\n",
      "loss: 0.503783 [19264/60000]\n",
      "loss: 0.445037 [25664/60000]\n",
      "loss: 0.460383 [32064/60000]\n",
      "loss: 0.450400 [38464/60000]\n",
      "loss: 0.641601 [44864/60000]\n",
      "loss: 0.573586 [51264/60000]\n",
      "loss: 0.416240 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 83.0%, avg loss: 0.477937 \n",
      "\n",
      "Epoch 58\n",
      "------------------\n",
      "loss: 0.332912 [   64/60000]\n",
      "loss: 0.491341 [ 6464/60000]\n",
      "loss: 0.309214 [12864/60000]\n",
      "loss: 0.501784 [19264/60000]\n",
      "loss: 0.442294 [25664/60000]\n",
      "loss: 0.458344 [32064/60000]\n",
      "loss: 0.448521 [38464/60000]\n",
      "loss: 0.640110 [44864/60000]\n",
      "loss: 0.572102 [51264/60000]\n",
      "loss: 0.414419 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 83.0%, avg loss: 0.476469 \n",
      "\n",
      "Epoch 59\n",
      "------------------\n",
      "loss: 0.330083 [   64/60000]\n",
      "loss: 0.489387 [ 6464/60000]\n",
      "loss: 0.307720 [12864/60000]\n",
      "loss: 0.499818 [19264/60000]\n",
      "loss: 0.439583 [25664/60000]\n",
      "loss: 0.456390 [32064/60000]\n",
      "loss: 0.446599 [38464/60000]\n",
      "loss: 0.638549 [44864/60000]\n",
      "loss: 0.570596 [51264/60000]\n",
      "loss: 0.412671 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 83.1%, avg loss: 0.475040 \n",
      "\n",
      "Epoch 60\n",
      "------------------\n",
      "loss: 0.327311 [   64/60000]\n",
      "loss: 0.487467 [ 6464/60000]\n",
      "loss: 0.306213 [12864/60000]\n",
      "loss: 0.497918 [19264/60000]\n",
      "loss: 0.436899 [25664/60000]\n",
      "loss: 0.454502 [32064/60000]\n",
      "loss: 0.444754 [38464/60000]\n",
      "loss: 0.636991 [44864/60000]\n",
      "loss: 0.569070 [51264/60000]\n",
      "loss: 0.410986 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 83.1%, avg loss: 0.473647 \n",
      "\n",
      "Epoch 61\n",
      "------------------\n",
      "loss: 0.324579 [   64/60000]\n",
      "loss: 0.485583 [ 6464/60000]\n",
      "loss: 0.304675 [12864/60000]\n",
      "loss: 0.496083 [19264/60000]\n",
      "loss: 0.434240 [25664/60000]\n",
      "loss: 0.452647 [32064/60000]\n",
      "loss: 0.443064 [38464/60000]\n",
      "loss: 0.635398 [44864/60000]\n",
      "loss: 0.567604 [51264/60000]\n",
      "loss: 0.409376 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 83.2%, avg loss: 0.472288 \n",
      "\n",
      "Epoch 62\n",
      "------------------\n",
      "loss: 0.321919 [   64/60000]\n",
      "loss: 0.483752 [ 6464/60000]\n",
      "loss: 0.303190 [12864/60000]\n",
      "loss: 0.494300 [19264/60000]\n",
      "loss: 0.431651 [25664/60000]\n",
      "loss: 0.450860 [32064/60000]\n",
      "loss: 0.441408 [38464/60000]\n",
      "loss: 0.633744 [44864/60000]\n",
      "loss: 0.566125 [51264/60000]\n",
      "loss: 0.407835 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 83.2%, avg loss: 0.470961 \n",
      "\n",
      "Epoch 63\n",
      "------------------\n",
      "loss: 0.319306 [   64/60000]\n",
      "loss: 0.481909 [ 6464/60000]\n",
      "loss: 0.301726 [12864/60000]\n",
      "loss: 0.492506 [19264/60000]\n",
      "loss: 0.429096 [25664/60000]\n",
      "loss: 0.449074 [32064/60000]\n",
      "loss: 0.439762 [38464/60000]\n",
      "loss: 0.632070 [44864/60000]\n",
      "loss: 0.564646 [51264/60000]\n",
      "loss: 0.406384 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 83.2%, avg loss: 0.469666 \n",
      "\n",
      "Epoch 64\n",
      "------------------\n",
      "loss: 0.316760 [   64/60000]\n",
      "loss: 0.480101 [ 6464/60000]\n",
      "loss: 0.300303 [12864/60000]\n",
      "loss: 0.490776 [19264/60000]\n",
      "loss: 0.426642 [25664/60000]\n",
      "loss: 0.447373 [32064/60000]\n",
      "loss: 0.438137 [38464/60000]\n",
      "loss: 0.630368 [44864/60000]\n",
      "loss: 0.563180 [51264/60000]\n",
      "loss: 0.405005 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 83.3%, avg loss: 0.468396 \n",
      "\n",
      "Epoch 65\n",
      "------------------\n",
      "loss: 0.314294 [   64/60000]\n",
      "loss: 0.478299 [ 6464/60000]\n",
      "loss: 0.298942 [12864/60000]\n",
      "loss: 0.489108 [19264/60000]\n",
      "loss: 0.424188 [25664/60000]\n",
      "loss: 0.445691 [32064/60000]\n",
      "loss: 0.436606 [38464/60000]\n",
      "loss: 0.628584 [44864/60000]\n",
      "loss: 0.561677 [51264/60000]\n",
      "loss: 0.403665 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 83.3%, avg loss: 0.467151 \n",
      "\n",
      "Epoch 66\n",
      "------------------\n",
      "loss: 0.311888 [   64/60000]\n",
      "loss: 0.476537 [ 6464/60000]\n",
      "loss: 0.297635 [12864/60000]\n",
      "loss: 0.487491 [19264/60000]\n",
      "loss: 0.421765 [25664/60000]\n",
      "loss: 0.444068 [32064/60000]\n",
      "loss: 0.435084 [38464/60000]\n",
      "loss: 0.626769 [44864/60000]\n",
      "loss: 0.560150 [51264/60000]\n",
      "loss: 0.402358 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 83.4%, avg loss: 0.465933 \n",
      "\n",
      "Epoch 67\n",
      "------------------\n",
      "loss: 0.309557 [   64/60000]\n",
      "loss: 0.474789 [ 6464/60000]\n",
      "loss: 0.296320 [12864/60000]\n",
      "loss: 0.485943 [19264/60000]\n",
      "loss: 0.419405 [25664/60000]\n",
      "loss: 0.442547 [32064/60000]\n",
      "loss: 0.433576 [38464/60000]\n",
      "loss: 0.625069 [44864/60000]\n",
      "loss: 0.558656 [51264/60000]\n",
      "loss: 0.401112 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 83.5%, avg loss: 0.464741 \n",
      "\n",
      "Epoch 68\n",
      "------------------\n",
      "loss: 0.307318 [   64/60000]\n",
      "loss: 0.473065 [ 6464/60000]\n",
      "loss: 0.295059 [12864/60000]\n",
      "loss: 0.484396 [19264/60000]\n",
      "loss: 0.417083 [25664/60000]\n",
      "loss: 0.441092 [32064/60000]\n",
      "loss: 0.432217 [38464/60000]\n",
      "loss: 0.623351 [44864/60000]\n",
      "loss: 0.557212 [51264/60000]\n",
      "loss: 0.399939 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 83.5%, avg loss: 0.463573 \n",
      "\n",
      "Epoch 69\n",
      "------------------\n",
      "loss: 0.305122 [   64/60000]\n",
      "loss: 0.471381 [ 6464/60000]\n",
      "loss: 0.293869 [12864/60000]\n",
      "loss: 0.482881 [19264/60000]\n",
      "loss: 0.414781 [25664/60000]\n",
      "loss: 0.439602 [32064/60000]\n",
      "loss: 0.430908 [38464/60000]\n",
      "loss: 0.621696 [44864/60000]\n",
      "loss: 0.555803 [51264/60000]\n",
      "loss: 0.398849 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 83.6%, avg loss: 0.462431 \n",
      "\n",
      "Epoch 70\n",
      "------------------\n",
      "loss: 0.302968 [   64/60000]\n",
      "loss: 0.469724 [ 6464/60000]\n",
      "loss: 0.292682 [12864/60000]\n",
      "loss: 0.481357 [19264/60000]\n",
      "loss: 0.412549 [25664/60000]\n",
      "loss: 0.438219 [32064/60000]\n",
      "loss: 0.429593 [38464/60000]\n",
      "loss: 0.619991 [44864/60000]\n",
      "loss: 0.554347 [51264/60000]\n",
      "loss: 0.397781 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 83.6%, avg loss: 0.461306 \n",
      "\n",
      "Epoch 71\n",
      "------------------\n",
      "loss: 0.300872 [   64/60000]\n",
      "loss: 0.468080 [ 6464/60000]\n",
      "loss: 0.291503 [12864/60000]\n",
      "loss: 0.479890 [19264/60000]\n",
      "loss: 0.410401 [25664/60000]\n",
      "loss: 0.436854 [32064/60000]\n",
      "loss: 0.428341 [38464/60000]\n",
      "loss: 0.618361 [44864/60000]\n",
      "loss: 0.552926 [51264/60000]\n",
      "loss: 0.396715 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 83.7%, avg loss: 0.460201 \n",
      "\n",
      "Epoch 72\n",
      "------------------\n",
      "loss: 0.298814 [   64/60000]\n",
      "loss: 0.466431 [ 6464/60000]\n",
      "loss: 0.290349 [12864/60000]\n",
      "loss: 0.478447 [19264/60000]\n",
      "loss: 0.408266 [25664/60000]\n",
      "loss: 0.435515 [32064/60000]\n",
      "loss: 0.427098 [38464/60000]\n",
      "loss: 0.616717 [44864/60000]\n",
      "loss: 0.551491 [51264/60000]\n",
      "loss: 0.395653 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 83.8%, avg loss: 0.459116 \n",
      "\n",
      "Epoch 73\n",
      "------------------\n",
      "loss: 0.296875 [   64/60000]\n",
      "loss: 0.464832 [ 6464/60000]\n",
      "loss: 0.289197 [12864/60000]\n",
      "loss: 0.477030 [19264/60000]\n",
      "loss: 0.406199 [25664/60000]\n",
      "loss: 0.434162 [32064/60000]\n",
      "loss: 0.425862 [38464/60000]\n",
      "loss: 0.615125 [44864/60000]\n",
      "loss: 0.550118 [51264/60000]\n",
      "loss: 0.394632 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 83.8%, avg loss: 0.458050 \n",
      "\n",
      "Epoch 74\n",
      "------------------\n",
      "loss: 0.294966 [   64/60000]\n",
      "loss: 0.463273 [ 6464/60000]\n",
      "loss: 0.288102 [12864/60000]\n",
      "loss: 0.475667 [19264/60000]\n",
      "loss: 0.404117 [25664/60000]\n",
      "loss: 0.432847 [32064/60000]\n",
      "loss: 0.424623 [38464/60000]\n",
      "loss: 0.613522 [44864/60000]\n",
      "loss: 0.548745 [51264/60000]\n",
      "loss: 0.393627 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 83.8%, avg loss: 0.457001 \n",
      "\n",
      "Epoch 75\n",
      "------------------\n",
      "loss: 0.293090 [   64/60000]\n",
      "loss: 0.461717 [ 6464/60000]\n",
      "loss: 0.287009 [12864/60000]\n",
      "loss: 0.474306 [19264/60000]\n",
      "loss: 0.401948 [25664/60000]\n",
      "loss: 0.431551 [32064/60000]\n",
      "loss: 0.423385 [38464/60000]\n",
      "loss: 0.611939 [44864/60000]\n",
      "loss: 0.547404 [51264/60000]\n",
      "loss: 0.392711 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 83.8%, avg loss: 0.455967 \n",
      "\n",
      "Epoch 76\n",
      "------------------\n",
      "loss: 0.291313 [   64/60000]\n",
      "loss: 0.460234 [ 6464/60000]\n",
      "loss: 0.285921 [12864/60000]\n",
      "loss: 0.472973 [19264/60000]\n",
      "loss: 0.399847 [25664/60000]\n",
      "loss: 0.430265 [32064/60000]\n",
      "loss: 0.422042 [38464/60000]\n",
      "loss: 0.610349 [44864/60000]\n",
      "loss: 0.546081 [51264/60000]\n",
      "loss: 0.391840 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 83.9%, avg loss: 0.454939 \n",
      "\n",
      "Epoch 77\n",
      "------------------\n",
      "loss: 0.289578 [   64/60000]\n",
      "loss: 0.458769 [ 6464/60000]\n",
      "loss: 0.284851 [12864/60000]\n",
      "loss: 0.471634 [19264/60000]\n",
      "loss: 0.397822 [25664/60000]\n",
      "loss: 0.429102 [32064/60000]\n",
      "loss: 0.420730 [38464/60000]\n",
      "loss: 0.608858 [44864/60000]\n",
      "loss: 0.544744 [51264/60000]\n",
      "loss: 0.391038 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 83.9%, avg loss: 0.453925 \n",
      "\n",
      "Epoch 78\n",
      "------------------\n",
      "loss: 0.287910 [   64/60000]\n",
      "loss: 0.457303 [ 6464/60000]\n",
      "loss: 0.283850 [12864/60000]\n",
      "loss: 0.470340 [19264/60000]\n",
      "loss: 0.395806 [25664/60000]\n",
      "loss: 0.427932 [32064/60000]\n",
      "loss: 0.419441 [38464/60000]\n",
      "loss: 0.607374 [44864/60000]\n",
      "loss: 0.543127 [51264/60000]\n",
      "loss: 0.390314 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 84.0%, avg loss: 0.452930 \n",
      "\n",
      "Epoch 79\n",
      "------------------\n",
      "loss: 0.286294 [   64/60000]\n",
      "loss: 0.455913 [ 6464/60000]\n",
      "loss: 0.282634 [12864/60000]\n",
      "loss: 0.469076 [19264/60000]\n",
      "loss: 0.393514 [25664/60000]\n",
      "loss: 0.426767 [32064/60000]\n",
      "loss: 0.418158 [38464/60000]\n",
      "loss: 0.605944 [44864/60000]\n",
      "loss: 0.541462 [51264/60000]\n",
      "loss: 0.389617 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 84.0%, avg loss: 0.451956 \n",
      "\n",
      "Epoch 80\n",
      "------------------\n",
      "loss: 0.284665 [   64/60000]\n",
      "loss: 0.454467 [ 6464/60000]\n",
      "loss: 0.281416 [12864/60000]\n",
      "loss: 0.467782 [19264/60000]\n",
      "loss: 0.391540 [25664/60000]\n",
      "loss: 0.425717 [32064/60000]\n",
      "loss: 0.417050 [38464/60000]\n",
      "loss: 0.604472 [44864/60000]\n",
      "loss: 0.540107 [51264/60000]\n",
      "loss: 0.388844 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 84.0%, avg loss: 0.451009 \n",
      "\n",
      "Epoch 81\n",
      "------------------\n",
      "loss: 0.283124 [   64/60000]\n",
      "loss: 0.453006 [ 6464/60000]\n",
      "loss: 0.280333 [12864/60000]\n",
      "loss: 0.466519 [19264/60000]\n",
      "loss: 0.389675 [25664/60000]\n",
      "loss: 0.424666 [32064/60000]\n",
      "loss: 0.415946 [38464/60000]\n",
      "loss: 0.603076 [44864/60000]\n",
      "loss: 0.538772 [51264/60000]\n",
      "loss: 0.388043 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 84.0%, avg loss: 0.450072 \n",
      "\n",
      "Epoch 82\n",
      "------------------\n",
      "loss: 0.281611 [   64/60000]\n",
      "loss: 0.451576 [ 6464/60000]\n",
      "loss: 0.279299 [12864/60000]\n",
      "loss: 0.465292 [19264/60000]\n",
      "loss: 0.387879 [25664/60000]\n",
      "loss: 0.423685 [32064/60000]\n",
      "loss: 0.414863 [38464/60000]\n",
      "loss: 0.601700 [44864/60000]\n",
      "loss: 0.537522 [51264/60000]\n",
      "loss: 0.387260 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 84.1%, avg loss: 0.449154 \n",
      "\n",
      "Epoch 83\n",
      "------------------\n",
      "loss: 0.280173 [   64/60000]\n",
      "loss: 0.450137 [ 6464/60000]\n",
      "loss: 0.278307 [12864/60000]\n",
      "loss: 0.464048 [19264/60000]\n",
      "loss: 0.386161 [25664/60000]\n",
      "loss: 0.422681 [32064/60000]\n",
      "loss: 0.413835 [38464/60000]\n",
      "loss: 0.600307 [44864/60000]\n",
      "loss: 0.536258 [51264/60000]\n",
      "loss: 0.386476 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 84.2%, avg loss: 0.448251 \n",
      "\n",
      "Epoch 84\n",
      "------------------\n",
      "loss: 0.278743 [   64/60000]\n",
      "loss: 0.448721 [ 6464/60000]\n",
      "loss: 0.277353 [12864/60000]\n",
      "loss: 0.462815 [19264/60000]\n",
      "loss: 0.384469 [25664/60000]\n",
      "loss: 0.421632 [32064/60000]\n",
      "loss: 0.412834 [38464/60000]\n",
      "loss: 0.598893 [44864/60000]\n",
      "loss: 0.534994 [51264/60000]\n",
      "loss: 0.385703 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 84.2%, avg loss: 0.447359 \n",
      "\n",
      "Epoch 85\n",
      "------------------\n",
      "loss: 0.277374 [   64/60000]\n",
      "loss: 0.447305 [ 6464/60000]\n",
      "loss: 0.276398 [12864/60000]\n",
      "loss: 0.461559 [19264/60000]\n",
      "loss: 0.382797 [25664/60000]\n",
      "loss: 0.420594 [32064/60000]\n",
      "loss: 0.411808 [38464/60000]\n",
      "loss: 0.597537 [44864/60000]\n",
      "loss: 0.533757 [51264/60000]\n",
      "loss: 0.384933 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 84.2%, avg loss: 0.446476 \n",
      "\n",
      "Epoch 86\n",
      "------------------\n",
      "loss: 0.276034 [   64/60000]\n",
      "loss: 0.445895 [ 6464/60000]\n",
      "loss: 0.275464 [12864/60000]\n",
      "loss: 0.460372 [19264/60000]\n",
      "loss: 0.381094 [25664/60000]\n",
      "loss: 0.419606 [32064/60000]\n",
      "loss: 0.410716 [38464/60000]\n",
      "loss: 0.596160 [44864/60000]\n",
      "loss: 0.532499 [51264/60000]\n",
      "loss: 0.384252 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 84.2%, avg loss: 0.445603 \n",
      "\n",
      "Epoch 87\n",
      "------------------\n",
      "loss: 0.274738 [   64/60000]\n",
      "loss: 0.444479 [ 6464/60000]\n",
      "loss: 0.274515 [12864/60000]\n",
      "loss: 0.459185 [19264/60000]\n",
      "loss: 0.379424 [25664/60000]\n",
      "loss: 0.418609 [32064/60000]\n",
      "loss: 0.409659 [38464/60000]\n",
      "loss: 0.594834 [44864/60000]\n",
      "loss: 0.531242 [51264/60000]\n",
      "loss: 0.383579 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 84.2%, avg loss: 0.444743 \n",
      "\n",
      "Epoch 88\n",
      "------------------\n",
      "loss: 0.273465 [   64/60000]\n",
      "loss: 0.443128 [ 6464/60000]\n",
      "loss: 0.273637 [12864/60000]\n",
      "loss: 0.457958 [19264/60000]\n",
      "loss: 0.377723 [25664/60000]\n",
      "loss: 0.417636 [32064/60000]\n",
      "loss: 0.408717 [38464/60000]\n",
      "loss: 0.593560 [44864/60000]\n",
      "loss: 0.530070 [51264/60000]\n",
      "loss: 0.382931 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 84.2%, avg loss: 0.443894 \n",
      "\n",
      "Epoch 89\n",
      "------------------\n",
      "loss: 0.272216 [   64/60000]\n",
      "loss: 0.441809 [ 6464/60000]\n",
      "loss: 0.272770 [12864/60000]\n",
      "loss: 0.456772 [19264/60000]\n",
      "loss: 0.376059 [25664/60000]\n",
      "loss: 0.416669 [32064/60000]\n",
      "loss: 0.407743 [38464/60000]\n",
      "loss: 0.592240 [44864/60000]\n",
      "loss: 0.528809 [51264/60000]\n",
      "loss: 0.382273 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 84.2%, avg loss: 0.443051 \n",
      "\n",
      "Epoch 90\n",
      "------------------\n",
      "loss: 0.271037 [   64/60000]\n",
      "loss: 0.440487 [ 6464/60000]\n",
      "loss: 0.271896 [12864/60000]\n",
      "loss: 0.455553 [19264/60000]\n",
      "loss: 0.374480 [25664/60000]\n",
      "loss: 0.415713 [32064/60000]\n",
      "loss: 0.406800 [38464/60000]\n",
      "loss: 0.590968 [44864/60000]\n",
      "loss: 0.527599 [51264/60000]\n",
      "loss: 0.381630 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 84.3%, avg loss: 0.442221 \n",
      "\n",
      "Epoch 91\n",
      "------------------\n",
      "loss: 0.269863 [   64/60000]\n",
      "loss: 0.439201 [ 6464/60000]\n",
      "loss: 0.271051 [12864/60000]\n",
      "loss: 0.454330 [19264/60000]\n",
      "loss: 0.372954 [25664/60000]\n",
      "loss: 0.414755 [32064/60000]\n",
      "loss: 0.405940 [38464/60000]\n",
      "loss: 0.589758 [44864/60000]\n",
      "loss: 0.526371 [51264/60000]\n",
      "loss: 0.380957 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 84.3%, avg loss: 0.441403 \n",
      "\n",
      "Epoch 92\n",
      "------------------\n",
      "loss: 0.268746 [   64/60000]\n",
      "loss: 0.437921 [ 6464/60000]\n",
      "loss: 0.270149 [12864/60000]\n",
      "loss: 0.453138 [19264/60000]\n",
      "loss: 0.371394 [25664/60000]\n",
      "loss: 0.413772 [32064/60000]\n",
      "loss: 0.405083 [38464/60000]\n",
      "loss: 0.588591 [44864/60000]\n",
      "loss: 0.525146 [51264/60000]\n",
      "loss: 0.380342 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 84.4%, avg loss: 0.440591 \n",
      "\n",
      "Epoch 93\n",
      "------------------\n",
      "loss: 0.267638 [   64/60000]\n",
      "loss: 0.436654 [ 6464/60000]\n",
      "loss: 0.269332 [12864/60000]\n",
      "loss: 0.451983 [19264/60000]\n",
      "loss: 0.369887 [25664/60000]\n",
      "loss: 0.412848 [32064/60000]\n",
      "loss: 0.404261 [38464/60000]\n",
      "loss: 0.587300 [44864/60000]\n",
      "loss: 0.523874 [51264/60000]\n",
      "loss: 0.379731 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 84.4%, avg loss: 0.439785 \n",
      "\n",
      "Epoch 94\n",
      "------------------\n",
      "loss: 0.266545 [   64/60000]\n",
      "loss: 0.435358 [ 6464/60000]\n",
      "loss: 0.268531 [12864/60000]\n",
      "loss: 0.450858 [19264/60000]\n",
      "loss: 0.368399 [25664/60000]\n",
      "loss: 0.411949 [32064/60000]\n",
      "loss: 0.403424 [38464/60000]\n",
      "loss: 0.586045 [44864/60000]\n",
      "loss: 0.522641 [51264/60000]\n",
      "loss: 0.379172 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 84.4%, avg loss: 0.438991 \n",
      "\n",
      "Epoch 95\n",
      "------------------\n",
      "loss: 0.265481 [   64/60000]\n",
      "loss: 0.434052 [ 6464/60000]\n",
      "loss: 0.267748 [12864/60000]\n",
      "loss: 0.449735 [19264/60000]\n",
      "loss: 0.366931 [25664/60000]\n",
      "loss: 0.411013 [32064/60000]\n",
      "loss: 0.402617 [38464/60000]\n",
      "loss: 0.584823 [44864/60000]\n",
      "loss: 0.521487 [51264/60000]\n",
      "loss: 0.378581 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 84.5%, avg loss: 0.438208 \n",
      "\n",
      "Epoch 96\n",
      "------------------\n",
      "loss: 0.264455 [   64/60000]\n",
      "loss: 0.432794 [ 6464/60000]\n",
      "loss: 0.267019 [12864/60000]\n",
      "loss: 0.448598 [19264/60000]\n",
      "loss: 0.365468 [25664/60000]\n",
      "loss: 0.410095 [32064/60000]\n",
      "loss: 0.401815 [38464/60000]\n",
      "loss: 0.583628 [44864/60000]\n",
      "loss: 0.520307 [51264/60000]\n",
      "loss: 0.378015 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 84.5%, avg loss: 0.437437 \n",
      "\n",
      "Epoch 97\n",
      "------------------\n",
      "loss: 0.263459 [   64/60000]\n",
      "loss: 0.431566 [ 6464/60000]\n",
      "loss: 0.266271 [12864/60000]\n",
      "loss: 0.447462 [19264/60000]\n",
      "loss: 0.364042 [25664/60000]\n",
      "loss: 0.409123 [32064/60000]\n",
      "loss: 0.401021 [38464/60000]\n",
      "loss: 0.582454 [44864/60000]\n",
      "loss: 0.519162 [51264/60000]\n",
      "loss: 0.377418 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 84.5%, avg loss: 0.436660 \n",
      "\n",
      "Epoch 98\n",
      "------------------\n",
      "loss: 0.262476 [   64/60000]\n",
      "loss: 0.430334 [ 6464/60000]\n",
      "loss: 0.265512 [12864/60000]\n",
      "loss: 0.446354 [19264/60000]\n",
      "loss: 0.362604 [25664/60000]\n",
      "loss: 0.408179 [32064/60000]\n",
      "loss: 0.400203 [38464/60000]\n",
      "loss: 0.581304 [44864/60000]\n",
      "loss: 0.517987 [51264/60000]\n",
      "loss: 0.376844 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 84.6%, avg loss: 0.435901 \n",
      "\n",
      "Epoch 99\n",
      "------------------\n",
      "loss: 0.261548 [   64/60000]\n",
      "loss: 0.429097 [ 6464/60000]\n",
      "loss: 0.264756 [12864/60000]\n",
      "loss: 0.445250 [19264/60000]\n",
      "loss: 0.361152 [25664/60000]\n",
      "loss: 0.407196 [32064/60000]\n",
      "loss: 0.399416 [38464/60000]\n",
      "loss: 0.580199 [44864/60000]\n",
      "loss: 0.516831 [51264/60000]\n",
      "loss: 0.376291 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 84.6%, avg loss: 0.435139 \n",
      "\n",
      "Epoch 100\n",
      "------------------\n",
      "loss: 0.260625 [   64/60000]\n",
      "loss: 0.427918 [ 6464/60000]\n",
      "loss: 0.263978 [12864/60000]\n",
      "loss: 0.444182 [19264/60000]\n",
      "loss: 0.359687 [25664/60000]\n",
      "loss: 0.406233 [32064/60000]\n",
      "loss: 0.398658 [38464/60000]\n",
      "loss: 0.579044 [44864/60000]\n",
      "loss: 0.515569 [51264/60000]\n",
      "loss: 0.375644 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 84.6%, avg loss: 0.434386 \n",
      "\n",
      "Done!\n",
      "Execution time: 213.947 seconds\n"
     ]
    }
   ],
   "source": [
    "# epochs = 5\n",
    "epochs = 100\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f'Epoch {t + 1}\\n------------------')\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print('Done!')\n",
    "\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "print(f'Execution time: {end_time - start_time:.3f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ee1c6a-bff2-40ae-96c7-cd3314410f22",
   "metadata": {},
   "source": [
    "Running 25 epochs on the 5080 gives final test accuracy 79.9%, and avg loss 0.577765. It took 53.7 seconds. Running the same number of epochs on the Ryzen 7 9800X3D took 72.9 seconds (36% faster, 19.2s), for the same 79.9% test accuracy with an effectively same average test loss of 0.575010. And - kudos to Apple's silicon, at least for this relatively small model - running the same 25 epochs on a Macbook Pro M3 w/ 18GB of RAM using the CPU build of pytorch 2.6 via mps, took 53.2 seconds - about the same as the 5080 (actually 0.5s faster, small sample size of 1); the accuracy was 80.1% and a test loss of 0.578824. (A second MPS run took 54.2s.) Ok, and as a likely final update, after I moved back to WSL to check that the uv config updates I made created an environment that works transparently on both MacOS and WSL/Linux - it did, by the way (I just git pulled and then ran jupyter and it brought down the right CUDA enabled version of torch for WSL... I think before I had a nightly of 2.8 and it brought down a nightly of 2.7 I think) - I ran the same code w/ the GPU and it took effectively the same time - here 52.3 seconds for a 79.8% accuracy. Ok, one more... just to see how it'd go w/ more epochs, I ran 100 (compared to 25 before) and after 214s got an accuracy of 84.6%... so the time per epoch stayed the same, as I'd expect. The accuracy was still increasing but clearly was plateauing, as I was only getting 0.1% if that per epoch by the end.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e4a4ef9-1655-4873-b95b-0155d8ca5cf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "669706"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many params?\n",
    "def count_parameters(model):\n",
    "    return torch.nn.utils.parameters_to_vector(model.parameters()).numel()\n",
    "\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3989ac5c-2cf5-4c64-8ce7-78363e3f5f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save weights\n",
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "553ca11d-1b70-4078-a155-e3f10bd032ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now I can load the weights (I need to execute the code above that defines the NeuralNetwork class, but of course don't need to do the training)\n",
    "model = NeuralNetwork().to(device)\n",
    "model.load_state_dict(torch.load('model.pth', weights_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10765cf2-7d5d-4351-a78d-a81666ac83dd",
   "metadata": {},
   "source": [
    "For future reference, just noting that from a quick chat w/ ChatGPT, it sounds like 30-40% increase is in the normal range for small models (without a ton of parameters) and/or with simpler models (with fewer layers), both of which I think apply here. Some top-of-ChatGPT-mind things I can do to see about increasing performance more include:\n",
    "\n",
    "- Try larger batch sizes, which can better leverage GPU parallelism, weighing against 'model convergence and generalization performance' considerations.\n",
    "- Consider more complex model architectures which if done right will give better model performance while showing a bigger difference between GPU and CPU performance (because there's more that can be parallelized).\n",
    "- Sometimes 'preloading datasets into GPU memory' can 'minimize CPU/GPU data transfer'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b909009-88b3-46b1-a086-37f2e1398221",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
