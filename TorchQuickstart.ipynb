{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd018cd0-773b-4f47-b7e2-0458928c7937",
   "metadata": {},
   "source": [
    "# Quickstart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537a96cb-f91f-4172-b346-cf883ffc7a73",
   "metadata": {},
   "source": [
    "With code from https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a345c48e-953d-448a-b748-89d1c45fdc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import sys\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0b97c4f-b8fa-441e-8bee-2845a0e6b753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.11.11 (main, Mar 11 2025, 17:28:32) [Clang 20.1.0 ]\n",
      "2.8.0.dev20250313+cu128\n"
     ]
    }
   ],
   "source": [
    "print(sys.version)\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d36d0a7e-01ac-4177-b307-45186f504b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root='data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "19f250fc-87d2-4416-8487-1c075f970295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f'Shape of X [N, C, H, W]: {X.shape}')\n",
    "    print(f'Shape of y: {y.shape} {y.dtype}')\n",
    "    break # exit after first batch - all batches are the same size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5e5dba2d-092d-4ea2-aebc-872aa8a5d093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "73f1f8c2-4598-4c55-8c03-7c658d258752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = 'cpu' # to run with CPU uncomment and then run the code below (could be reorganize so only the stuff that has to run after the device change, like the model creation, is after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0d18d654-7d71-432f-9a41-c874a92c3f30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "56d61d31-74b4-4a1d-be73-a207d39794ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "78b6eac9-e685-41cd-af66-8d4d9995bd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # backprop\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f'loss: {loss:>7f} [{current:>5d}/{size:>5d}]')\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f'Test error: \\n Accuracy: {(100 * correct):>0.1f}%, avg loss: {test_loss:>8f} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7d6c1b6d-9689-4e3e-be61-2dd3218913e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "------------------\n",
      "loss: 2.291341 [   64/60000]\n",
      "loss: 2.284515 [ 6464/60000]\n",
      "loss: 2.265926 [12864/60000]\n",
      "loss: 2.268321 [19264/60000]\n",
      "loss: 2.243991 [25664/60000]\n",
      "loss: 2.203390 [32064/60000]\n",
      "loss: 2.227686 [38464/60000]\n",
      "loss: 2.178933 [44864/60000]\n",
      "loss: 2.180185 [51264/60000]\n",
      "loss: 2.157468 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 39.5%, avg loss: 2.149694 \n",
      "\n",
      "Epoch 2\n",
      "------------------\n",
      "loss: 2.152032 [   64/60000]\n",
      "loss: 2.152758 [ 6464/60000]\n",
      "loss: 2.092944 [12864/60000]\n",
      "loss: 2.117953 [19264/60000]\n",
      "loss: 2.063873 [25664/60000]\n",
      "loss: 1.993758 [32064/60000]\n",
      "loss: 2.031211 [38464/60000]\n",
      "loss: 1.946473 [44864/60000]\n",
      "loss: 1.949056 [51264/60000]\n",
      "loss: 1.882597 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 60.2%, avg loss: 1.883467 \n",
      "\n",
      "Epoch 3\n",
      "------------------\n",
      "loss: 1.907246 [   64/60000]\n",
      "loss: 1.890307 [ 6464/60000]\n",
      "loss: 1.771404 [12864/60000]\n",
      "loss: 1.812066 [19264/60000]\n",
      "loss: 1.698568 [25664/60000]\n",
      "loss: 1.647546 [32064/60000]\n",
      "loss: 1.665434 [38464/60000]\n",
      "loss: 1.568923 [44864/60000]\n",
      "loss: 1.587239 [51264/60000]\n",
      "loss: 1.478286 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 62.1%, avg loss: 1.504658 \n",
      "\n",
      "Epoch 4\n",
      "------------------\n",
      "loss: 1.565532 [   64/60000]\n",
      "loss: 1.540390 [ 6464/60000]\n",
      "loss: 1.387952 [12864/60000]\n",
      "loss: 1.458525 [19264/60000]\n",
      "loss: 1.331606 [25664/60000]\n",
      "loss: 1.334585 [32064/60000]\n",
      "loss: 1.346049 [38464/60000]\n",
      "loss: 1.273061 [44864/60000]\n",
      "loss: 1.308158 [51264/60000]\n",
      "loss: 1.205748 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 63.3%, avg loss: 1.236373 \n",
      "\n",
      "Epoch 5\n",
      "------------------\n",
      "loss: 1.311160 [   64/60000]\n",
      "loss: 1.298908 [ 6464/60000]\n",
      "loss: 1.130383 [12864/60000]\n",
      "loss: 1.235073 [19264/60000]\n",
      "loss: 1.103231 [25664/60000]\n",
      "loss: 1.137320 [32064/60000]\n",
      "loss: 1.159386 [38464/60000]\n",
      "loss: 1.096406 [44864/60000]\n",
      "loss: 1.136823 [51264/60000]\n",
      "loss: 1.053156 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 64.6%, avg loss: 1.075092 \n",
      "\n",
      "Epoch 6\n",
      "------------------\n",
      "loss: 1.144625 [   64/60000]\n",
      "loss: 1.150955 [ 6464/60000]\n",
      "loss: 0.965685 [12864/60000]\n",
      "loss: 1.098480 [19264/60000]\n",
      "loss: 0.967628 [25664/60000]\n",
      "loss: 1.007002 [32064/60000]\n",
      "loss: 1.045880 [38464/60000]\n",
      "loss: 0.985772 [44864/60000]\n",
      "loss: 1.026417 [51264/60000]\n",
      "loss: 0.958721 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 65.8%, avg loss: 0.972335 \n",
      "\n",
      "Epoch 7\n",
      "------------------\n",
      "loss: 1.029704 [   64/60000]\n",
      "loss: 1.056004 [ 6464/60000]\n",
      "loss: 0.854126 [12864/60000]\n",
      "loss: 1.008826 [19264/60000]\n",
      "loss: 0.884346 [25664/60000]\n",
      "loss: 0.915422 [32064/60000]\n",
      "loss: 0.970896 [38464/60000]\n",
      "loss: 0.914048 [44864/60000]\n",
      "loss: 0.950545 [51264/60000]\n",
      "loss: 0.894799 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 67.0%, avg loss: 0.902413 \n",
      "\n",
      "Epoch 8\n",
      "------------------\n",
      "loss: 0.945006 [   64/60000]\n",
      "loss: 0.990371 [ 6464/60000]\n",
      "loss: 0.774294 [12864/60000]\n",
      "loss: 0.945995 [19264/60000]\n",
      "loss: 0.829112 [25664/60000]\n",
      "loss: 0.848171 [32064/60000]\n",
      "loss: 0.917409 [38464/60000]\n",
      "loss: 0.866006 [44864/60000]\n",
      "loss: 0.895735 [51264/60000]\n",
      "loss: 0.848166 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 68.4%, avg loss: 0.851956 \n",
      "\n",
      "Epoch 9\n",
      "------------------\n",
      "loss: 0.879570 [   64/60000]\n",
      "loss: 0.941445 [ 6464/60000]\n",
      "loss: 0.714361 [12864/60000]\n",
      "loss: 0.899565 [19264/60000]\n",
      "loss: 0.789464 [25664/60000]\n",
      "loss: 0.797751 [32064/60000]\n",
      "loss: 0.876708 [38464/60000]\n",
      "loss: 0.832391 [44864/60000]\n",
      "loss: 0.854769 [51264/60000]\n",
      "loss: 0.812038 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 69.7%, avg loss: 0.813737 \n",
      "\n",
      "Epoch 10\n",
      "------------------\n",
      "loss: 0.827273 [   64/60000]\n",
      "loss: 0.902030 [ 6464/60000]\n",
      "loss: 0.667519 [12864/60000]\n",
      "loss: 0.863686 [19264/60000]\n",
      "loss: 0.759180 [25664/60000]\n",
      "loss: 0.759043 [32064/60000]\n",
      "loss: 0.843967 [38464/60000]\n",
      "loss: 0.807465 [44864/60000]\n",
      "loss: 0.823139 [51264/60000]\n",
      "loss: 0.782790 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 70.9%, avg loss: 0.783353 \n",
      "\n",
      "Epoch 11\n",
      "------------------\n",
      "loss: 0.784115 [   64/60000]\n",
      "loss: 0.868590 [ 6464/60000]\n",
      "loss: 0.629794 [12864/60000]\n",
      "loss: 0.835358 [19264/60000]\n",
      "loss: 0.734697 [25664/60000]\n",
      "loss: 0.728763 [32064/60000]\n",
      "loss: 0.816400 [38464/60000]\n",
      "loss: 0.787680 [44864/60000]\n",
      "loss: 0.797760 [51264/60000]\n",
      "loss: 0.758502 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 72.0%, avg loss: 0.758305 \n",
      "\n",
      "Epoch 12\n",
      "------------------\n",
      "loss: 0.747541 [   64/60000]\n",
      "loss: 0.839402 [ 6464/60000]\n",
      "loss: 0.598708 [12864/60000]\n",
      "loss: 0.812250 [19264/60000]\n",
      "loss: 0.714261 [25664/60000]\n",
      "loss: 0.704460 [32064/60000]\n",
      "loss: 0.792248 [38464/60000]\n",
      "loss: 0.771163 [44864/60000]\n",
      "loss: 0.776480 [51264/60000]\n",
      "loss: 0.737527 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 73.1%, avg loss: 0.736859 \n",
      "\n",
      "Epoch 13\n",
      "------------------\n",
      "loss: 0.715962 [   64/60000]\n",
      "loss: 0.813206 [ 6464/60000]\n",
      "loss: 0.572275 [12864/60000]\n",
      "loss: 0.792790 [19264/60000]\n",
      "loss: 0.696512 [25664/60000]\n",
      "loss: 0.684402 [32064/60000]\n",
      "loss: 0.770435 [38464/60000]\n",
      "loss: 0.756884 [44864/60000]\n",
      "loss: 0.758272 [51264/60000]\n",
      "loss: 0.718974 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 73.9%, avg loss: 0.717981 \n",
      "\n",
      "Epoch 14\n",
      "------------------\n",
      "loss: 0.688247 [   64/60000]\n",
      "loss: 0.789171 [ 6464/60000]\n",
      "loss: 0.549375 [12864/60000]\n",
      "loss: 0.775925 [19264/60000]\n",
      "loss: 0.680955 [25664/60000]\n",
      "loss: 0.667640 [32064/60000]\n",
      "loss: 0.750420 [38464/60000]\n",
      "loss: 0.744065 [44864/60000]\n",
      "loss: 0.742477 [51264/60000]\n",
      "loss: 0.702165 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 74.7%, avg loss: 0.701026 \n",
      "\n",
      "Epoch 15\n",
      "------------------\n",
      "loss: 0.663654 [   64/60000]\n",
      "loss: 0.767042 [ 6464/60000]\n",
      "loss: 0.529219 [12864/60000]\n",
      "loss: 0.761015 [19264/60000]\n",
      "loss: 0.667191 [25664/60000]\n",
      "loss: 0.653381 [32064/60000]\n",
      "loss: 0.731871 [38464/60000]\n",
      "loss: 0.732308 [44864/60000]\n",
      "loss: 0.728646 [51264/60000]\n",
      "loss: 0.686930 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 75.5%, avg loss: 0.685588 \n",
      "\n",
      "Epoch 16\n",
      "------------------\n",
      "loss: 0.641534 [   64/60000]\n",
      "loss: 0.746625 [ 6464/60000]\n",
      "loss: 0.511374 [12864/60000]\n",
      "loss: 0.747558 [19264/60000]\n",
      "loss: 0.655014 [25664/60000]\n",
      "loss: 0.641115 [32064/60000]\n",
      "loss: 0.714621 [38464/60000]\n",
      "loss: 0.721588 [44864/60000]\n",
      "loss: 0.716387 [51264/60000]\n",
      "loss: 0.672999 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 76.1%, avg loss: 0.671437 \n",
      "\n",
      "Epoch 17\n",
      "------------------\n",
      "loss: 0.621620 [   64/60000]\n",
      "loss: 0.727813 [ 6464/60000]\n",
      "loss: 0.495337 [12864/60000]\n",
      "loss: 0.735193 [19264/60000]\n",
      "loss: 0.644275 [25664/60000]\n",
      "loss: 0.630320 [32064/60000]\n",
      "loss: 0.698534 [38464/60000]\n",
      "loss: 0.711911 [44864/60000]\n",
      "loss: 0.705567 [51264/60000]\n",
      "loss: 0.660131 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 77.0%, avg loss: 0.658399 \n",
      "\n",
      "Epoch 18\n",
      "------------------\n",
      "loss: 0.603585 [   64/60000]\n",
      "loss: 0.710543 [ 6464/60000]\n",
      "loss: 0.480893 [12864/60000]\n",
      "loss: 0.723746 [19264/60000]\n",
      "loss: 0.634744 [25664/60000]\n",
      "loss: 0.620798 [32064/60000]\n",
      "loss: 0.683596 [38464/60000]\n",
      "loss: 0.703041 [44864/60000]\n",
      "loss: 0.695987 [51264/60000]\n",
      "loss: 0.648249 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 77.5%, avg loss: 0.646362 \n",
      "\n",
      "Epoch 19\n",
      "------------------\n",
      "loss: 0.587316 [   64/60000]\n",
      "loss: 0.694681 [ 6464/60000]\n",
      "loss: 0.467859 [12864/60000]\n",
      "loss: 0.713098 [19264/60000]\n",
      "loss: 0.626316 [25664/60000]\n",
      "loss: 0.612362 [32064/60000]\n",
      "loss: 0.669778 [38464/60000]\n",
      "loss: 0.695058 [44864/60000]\n",
      "loss: 0.687573 [51264/60000]\n",
      "loss: 0.637200 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 77.9%, avg loss: 0.635241 \n",
      "\n",
      "Epoch 20\n",
      "------------------\n",
      "loss: 0.572505 [   64/60000]\n",
      "loss: 0.680032 [ 6464/60000]\n",
      "loss: 0.456019 [12864/60000]\n",
      "loss: 0.703114 [19264/60000]\n",
      "loss: 0.618617 [25664/60000]\n",
      "loss: 0.604889 [32064/60000]\n",
      "loss: 0.656979 [38464/60000]\n",
      "loss: 0.688213 [44864/60000]\n",
      "loss: 0.680262 [51264/60000]\n",
      "loss: 0.626868 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 78.2%, avg loss: 0.624960 \n",
      "\n",
      "Epoch 21\n",
      "------------------\n",
      "loss: 0.558897 [   64/60000]\n",
      "loss: 0.666476 [ 6464/60000]\n",
      "loss: 0.445150 [12864/60000]\n",
      "loss: 0.693783 [19264/60000]\n",
      "loss: 0.611483 [25664/60000]\n",
      "loss: 0.598221 [32064/60000]\n",
      "loss: 0.645078 [38464/60000]\n",
      "loss: 0.682366 [44864/60000]\n",
      "loss: 0.673958 [51264/60000]\n",
      "loss: 0.617156 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 78.5%, avg loss: 0.615446 \n",
      "\n",
      "Epoch 22\n",
      "------------------\n",
      "loss: 0.546360 [   64/60000]\n",
      "loss: 0.653887 [ 6464/60000]\n",
      "loss: 0.435149 [12864/60000]\n",
      "loss: 0.685039 [19264/60000]\n",
      "loss: 0.604928 [25664/60000]\n",
      "loss: 0.592123 [32064/60000]\n",
      "loss: 0.634050 [38464/60000]\n",
      "loss: 0.677452 [44864/60000]\n",
      "loss: 0.668459 [51264/60000]\n",
      "loss: 0.607944 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 78.8%, avg loss: 0.606622 \n",
      "\n",
      "Epoch 23\n",
      "------------------\n",
      "loss: 0.534763 [   64/60000]\n",
      "loss: 0.642213 [ 6464/60000]\n",
      "loss: 0.425897 [12864/60000]\n",
      "loss: 0.676793 [19264/60000]\n",
      "loss: 0.598700 [25664/60000]\n",
      "loss: 0.586496 [32064/60000]\n",
      "loss: 0.623886 [38464/60000]\n",
      "loss: 0.673413 [44864/60000]\n",
      "loss: 0.663658 [51264/60000]\n",
      "loss: 0.599144 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 79.0%, avg loss: 0.598423 \n",
      "\n",
      "Epoch 24\n",
      "------------------\n",
      "loss: 0.523952 [   64/60000]\n",
      "loss: 0.631320 [ 6464/60000]\n",
      "loss: 0.417286 [12864/60000]\n",
      "loss: 0.668997 [19264/60000]\n",
      "loss: 0.592807 [25664/60000]\n",
      "loss: 0.581258 [32064/60000]\n",
      "loss: 0.614541 [38464/60000]\n",
      "loss: 0.670139 [44864/60000]\n",
      "loss: 0.659508 [51264/60000]\n",
      "loss: 0.590707 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 79.3%, avg loss: 0.590783 \n",
      "\n",
      "Epoch 25\n",
      "------------------\n",
      "loss: 0.513835 [   64/60000]\n",
      "loss: 0.621209 [ 6464/60000]\n",
      "loss: 0.409293 [12864/60000]\n",
      "loss: 0.661575 [19264/60000]\n",
      "loss: 0.587067 [25664/60000]\n",
      "loss: 0.576358 [32064/60000]\n",
      "loss: 0.605918 [38464/60000]\n",
      "loss: 0.667561 [44864/60000]\n",
      "loss: 0.655869 [51264/60000]\n",
      "loss: 0.582579 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 79.8%, avg loss: 0.583662 \n",
      "\n",
      "Done!\n",
      "Execution time: 53.226 seconds\n"
     ]
    }
   ],
   "source": [
    "# epochs = 5\n",
    "epochs = 25\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f'Epoch {t + 1}\\n------------------')\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print('Done!')\n",
    "\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "print(f'Execution time: {end_time - start_time:.3f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ee1c6a-bff2-40ae-96c7-cd3314410f22",
   "metadata": {},
   "source": [
    "Running 25 epochs on the 5080 gives final test accuracy 79.9%, and avg loss 0.577765. It took 53.7 seconds. Running the same number of epochs on the Ryzen 7 9800X3D took 72.9 seconds (36% faster, 19.2s), for the same 79.9% test accuracy with an effectively same average test loss of 0.575010.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec38ba11-a0f0-4180-bc27-526897c0282c",
   "metadata": {},
   "source": [
    "**TODO** There's a bit more on the quickstart page for saving and loading model weights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10765cf2-7d5d-4351-a78d-a81666ac83dd",
   "metadata": {},
   "source": [
    "**TODO** From a quick chat w/ ChatGPT, it sounds like 30-40% increase is in the normal range for small models (without a ton of parameters) and/or with simpler models (with fewer layers), both of which I think apply here. Some top-of-ChatGPT-mind things I can do to see about increasing performance more include:\n",
    "\n",
    "- Try larger batch sizes, which can better leverage GPU parallelism, weighing against 'model convergence and generalization performance' considerations.\n",
    "- Consider more complex model architectures which if done right will give better model performance while showing a bigger difference between GPU and CPU performance (because there's more that can be parallelized).\n",
    "- Sometimes 'preloading datasets into GPU memory' can 'minimize CPU/GPU data transfer'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b909009-88b3-46b1-a086-37f2e1398221",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
